# FAQ: General Info & Concepts

Refer to this section for general information about BigDL-LLM.

## BigDL-LLM Support

### GGUF format usage with BigDL-LLM?

BigDL-LLM supports running GGUF/AWQ/GPTQ models on both [CPU](../../../../../../../python/llm/example/CPU/HF-Transformers-AutoModels/Advanced-Quantizations/) and [GPU](../../../../../../../python/llm/example/GPU/HF-Transformers-AutoModels/Advanced-Quantizations/).
Please also refer to [here](../../../../../../../README.md#latest-update-ðŸ”¥) for our latest support.
