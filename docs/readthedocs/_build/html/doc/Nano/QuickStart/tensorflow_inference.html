<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>BigDL-Nano TensorFlow Inference Overview &mdash; BigDL  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/design-tabs.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="AutoML Overview" href="hpo.html" />
    <link rel="prev" title="BigDL-Nano TensorFlow Training Overview" href="tensorflow_train.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> BigDL
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/QuickStart/orca-tf-quickstart.html">TensorFlow 1.15 Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/QuickStart/orca-keras-quickstart.html">Keras 2.3 Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/QuickStart/orca-tf2keras-quickstart.html">TensorFlow 2 Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/QuickStart/orca-pytorch-quickstart.html">PyTorch Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray/QuickStart/ray-quickstart.html">RayOnSpark Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/python.html">Python User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/scala.html">Scala User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/colab.html">Colab User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/docker.html">Docker User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/hadoop.html">Hadoop/YARN User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/k8s.html">K8s User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/databricks.html">Databricks User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/develop.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/known_issues.html">BigDL Known Issues</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Nano</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../Overview/nano.html">Nano User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Overview/windows_guide.html">Windows User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_train.html">BigDL-Nano PyTorch Training Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_inference.html">BigDL-Nano PyTorch Inference Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorflow_train.html">BigDL-Nano TensorFlow Training Overview</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">BigDL-Nano TensorFlow Inference Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#quantization">Quantization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#quantization-using-intel-neural-compressor">Quantization using Intel Neural Compressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quantization-with-accuracy-control">Quantization with Accuracy Control</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hpo.html">AutoML Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Overview/known_issues.html">Nano Known Issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html">Nano Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">DLlib</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../DLlib/Overview/dllib.html">DLlib User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../DLlib/Overview/keras-api.html">Keras-Like API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../DLlib/Overview/nnframes.html">Spark ML Pipeline Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Orca</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/Overview/orca.html">Orca User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/Overview/orca-context.html">Orca Context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/Overview/data-parallel-processing.html">Distributed Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/Overview/distributed-training-inference.html">Distributed Training and Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/Overview/distributed-tuning.html">Distributed Hyper-Parameter Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray/Overview/ray.html">RayOnSpark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/Overview/known_issues.html">Orca Known Issues</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chronos</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Chronos/Overview/chronos.html">Chronos User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Chronos/Overview/windows_guide.html">Windows User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Chronos/Overview/deep_dive.html">Chronos Deep Dive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Chronos/QuickStart/index.html">Chronos Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Chronos/Overview/chronos_known_issue.html">Chronos Known Issue</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PPML</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/Overview/ppml.html">Privacy Preserving Machine Learning (PPML) User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/Overview/trusted_big_data_analytics_and_ml.html">Trusted Big Data Analytics and ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/Overview/trusted_fl.html">Trusted FL (Federated Learning)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/QuickStart/secure_your_services.html">Secure Your Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/QuickStart/build_kernel_with_sgx.html">Building Linux Kernel from Source with SGX Enabled</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/QuickStart/deploy_intel_sgx_device_plugin_for_kubernetes.html">Deploy the Intel SGX Device Plugin for Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/QuickStart/trusted-serving-on-k8s-guide.html">Trusted Cluster Serving with Graphene on Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/QuickStart/tpc-h_with_sparksql_on_k8s.html">TPC-H with Trusted SparkSQL on Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/QuickStart/tpc-ds_with_sparksql_on_k8s.html">TPC-DS with Trusted SparkSQL on Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/Overview/azure_ppml.html">Privacy Preserving Machine Learning (PPML) on Azure User Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Serving</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/Overview/serving.html">Cluster Serving User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/QuickStart/serving-quickstart.html">Cluster Serving Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/ProgrammingGuide/serving-installation.html">Install Cluster Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/ProgrammingGuide/serving-start.html">Start Cluster Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/ProgrammingGuide/serving-inference.html">Inference by Cluster Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/Example/example.html">Cluster Serving Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/FAQ/faq.html">Cluster Serving FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/FAQ/contribute-guide.html">Contribute to Cluster Serving</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Common Use Case</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/QuickStart/orca-pytorch-distributed-quickstart.html">Use <code class="docutils literal notranslate"><span class="pre">torch.distributed</span></code> in Orca</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UseCase/spark-dataframe.html">Use Spark Dataframe for Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UseCase/xshards-pandas.html">Use Distributed Pandas for Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/QuickStart/orca-autoestimator-pytorch-quickstart.html">Enable AutoML for PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/QuickStart/orca-autoxgboost-quickstart.html">Use AutoXGBoost to auto-tune XGBoost parameters</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../PythonAPI/Orca/orca.html">Orca API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PythonAPI/Friesian/feature.html">Friesian Feature API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PythonAPI/Chronos/index.html">Chronos API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PythonAPI/Nano/index.html">Nano API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Real-World Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Application/presentations.html">Presentations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Application/blogs.html">Blogs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Application/powered-by.html">Powered By</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">BigDL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>BigDL-Nano TensorFlow Inference Overview</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/doc/Nano/QuickStart/tensorflow_inference.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="bigdl-nano-tensorflow-inference-overview">
<h1>BigDL-Nano TensorFlow Inference Overview<a class="headerlink" href="#bigdl-nano-tensorflow-inference-overview" title="Permalink to this headline">¶</a></h1>
<p>BigDL-Nano provides several APIs which can help users easily apply optimizations on inference pipelines to improve latency and throughput. Currently, performance accelerations are achieved by integrating extra runtimes as inference backend engines or using quantization methods on full-precision trained models to reduce computation during inference. Keras Model (<code class="docutils literal notranslate"><span class="pre">bigdl.nano.tf.keras.Model</span></code>) and Sequential (<code class="docutils literal notranslate"><span class="pre">bigdl.nano.tf.keras.Sequential</span></code>) provides the APIs for all optimizations you need for inference.</p>
<p>For quantization, BigDL-Nano provides only post-training quantization in <code class="docutils literal notranslate"><span class="pre">Model.quantize()</span></code> for users to infer with models of 8-bit precision. Quantization-Aware Training is not available for now. Model conversion to 16-bit like BF16, and FP16 will be coming soon.</p>
<p>Before you go ahead with these APIs, you have to make sure BigDL-Nano is correctly installed for Tensorflow. If not, please follow <a class="reference internal" href="../Overview/nano.html"><span class="doc">this</span></a> to set up your environment.</p>
<section id="quantization">
<h2>Quantization<a class="headerlink" href="#quantization" title="Permalink to this headline">¶</a></h2>
<p>Quantization is widely used to compress models to a lower precision, which not only reduces the model size but also accelerates inference. BigDL-Nano provides <code class="docutils literal notranslate"><span class="pre">Model.quantize()</span></code> API for users to quickly obtain a quantized model with accuracy control by specifying a few arguments. <code class="docutils literal notranslate"><span class="pre">Sequential</span></code> has similar usage, so we will only show how to use an instance of <code class="docutils literal notranslate"><span class="pre">Model</span></code> to enable quantization pipeline.</p>
<p>To use INC as your quantization engine, you can choose accelerator as None or ‘onnxruntime’. Otherwise, accelerator=’openvino’ means using OpenVINO POT to do quantization.</p>
<p>By default, <code class="docutils literal notranslate"><span class="pre">Model.quantize()</span></code> doesn’t search the tuning space and returns the fully-quantized model without considering the accuracy drop. If you need to search quantization tuning space for a model with accuracy control, you’ll have to specify a few arguments to define the tuning space. More instructions in <a class="reference external" href="#quantization-with-accuracy-control">Quantization with Accuracy control</a></p>
<section id="quantization-using-intel-neural-compressor">
<h3>Quantization using Intel Neural Compressor<a class="headerlink" href="#quantization-using-intel-neural-compressor" title="Permalink to this headline">¶</a></h3>
<p>By default, Intel Neural Compressor is not installed with BigDL-Nano. So if you determine to use it as your quantization backend, you’ll need to install it first:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># We have tested on neural-compressor&gt;=1.8.1,&lt;=1.11.0</span>
pip install <span class="s1">&#39;neural-compressor&gt;=1.8.1,&lt;=1.11.0&#39;</span>
</pre></div>
</div>
<p><strong>Quantization without extra accelerator</strong>Without extra accelerators, <code class="docutils literal notranslate"><span class="pre">Model.quantize()</span></code> returns a Keras module with desired precision and accuracy. Taking MobileNetV2 as an example, you can add quantization as below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.applications.mobilenet_v2</span> <span class="kn">import</span> <span class="n">MobileNetV2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.nano.tf.keras</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="c1"># step 1: create your model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MobileNetV2</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">outputs</span><span class="p">)</span>

<span class="c1"># step 2: prepare your data and dataloader</span>
<span class="n">train_examples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,))</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">train_examples</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">))</span>

<span class="c1"># (Optional) step 3: Something else, like training ...</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>

<span class="c1"># step 4: execute quantization</span>
<span class="n">q_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">quantize</span><span class="p">(</span><span class="n">calib_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">)</span>

<span class="c1"># run simple prediction</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">q_model</span><span class="p">(</span><span class="n">train_examples</span><span class="p">)</span>

<span class="c1"># evaluate, predict also support acceleration</span>
<span class="n">q_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
<span class="n">q_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
</pre></div>
</div>
<p>This is a most basic usage to quantize a model with defaults, INT8 precision, and without search tuning space to control accuracy drop.</p>
<p>To use quantization, you must use functional API to create a keras model. This is a known limitation
of INC.</p>
</section>
<section id="quantization-with-accuracy-control">
<h3>Quantization with Accuracy Control<a class="headerlink" href="#quantization-with-accuracy-control" title="Permalink to this headline">¶</a></h3>
<p>A set of arguments that helps to tune the results for both INC and POT quantization:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">calib_dataset</span></code>: A tf.data.Dataset object for calibration. Required for static quantization. It’s also used as a validation dataloader.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">metric</span></code>:  A <code class="docutils literal notranslate"><span class="pre">tensorflow.keras.metrics.Metric</span></code> object for evaluation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">accuracy_criterion</span></code>: A dictionary to specify the acceptable accuracy drop, e.g. <code class="docutils literal notranslate"><span class="pre">{'relative':</span> <span class="pre">0.01,</span> <span class="pre">'higher_is_better':</span> <span class="pre">True}</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">relative</span></code> / <code class="docutils literal notranslate"><span class="pre">absolute</span></code>: Drop type, the accuracy drop should be relative or absolute to baseline</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">higher_is_better</span></code>: Indicate if a larger value of metric means better accuracy</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_trials</span></code>: Maximum trails on the search, if the algorithm can’t find a satisfying model, it will exit and raise the error.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch</span></code>: Specify the batch size of the dataloader. This will only take effect on evaluation. If it’s not set, then we use <code class="docutils literal notranslate"><span class="pre">batch=1</span></code> for evaluation.</p></li>
</ul>
<p><strong>Accuracy Control with INC</strong>
There are a few arguments that require only by INC.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tuning_strategy</span></code>(optional): it specifies the algorithm to search the tuning space. In most cases, you don’t need to change it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">timeout</span></code>: Timeout of your tuning. Defaults 0 means endless time for tuning.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputs</span></code>:      A list of input names. Default: None, automatically get names from the graph.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">outputs</span></code>:     A list of output names. Default: None, automatically get names from the graph.
Here is an example to use INC with accuracy control as below. It will search for a model within 1% accuracy drop with 10 trials.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchmetrics.classification</span> <span class="kn">import</span> <span class="n">Accuracy</span>

<span class="n">q_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">quantize</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="s1">&#39;int8&#39;</span><span class="p">,</span>
                         <span class="n">accelerator</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                         <span class="n">calib_dataset</span><span class="o">=</span> <span class="n">train_dataset</span><span class="p">,</span>
                         <span class="n">metric</span><span class="o">=</span><span class="n">Accuracy</span><span class="p">(),</span>
                         <span class="n">accuracy_criterion</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;relative&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span> <span class="s1">&#39;higher_is_better&#39;</span><span class="p">:</span> <span class="bp">True</span><span class="p">},</span>
                         <span class="n">approach</span><span class="o">=</span><span class="s1">&#39;static&#39;</span><span class="p">,</span>
                         <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;bayesian&#39;</span><span class="p">,</span>
                         <span class="n">timeout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                         <span class="n">max_trials</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                         <span class="p">)</span>

<span class="c1"># run simple prediction</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">q_model</span><span class="p">(</span><span class="n">train_examples</span><span class="p">)</span>

<span class="c1"># evaluate, predict also support acceleration</span>
<span class="n">q_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
<span class="n">q_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="tensorflow_train.html" class="btn btn-neutral float-left" title="BigDL-Nano TensorFlow Training Overview" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="hpo.html" class="btn btn-neutral float-right" title="AutoML Overview" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, BigDL Authors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>