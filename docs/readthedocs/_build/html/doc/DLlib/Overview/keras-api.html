<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Keras-Like API &mdash; BigDL  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/design-tabs.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Spark ML Pipeline Support" href="nnframes.html" />
    <link rel="prev" title="DLlib User Guide" href="dllib.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> BigDL
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/QuickStart/orca-tf-quickstart.html">TensorFlow 1.15 Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/QuickStart/orca-keras-quickstart.html">Keras 2.3 Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/QuickStart/orca-tf2keras-quickstart.html">TensorFlow 2 Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/QuickStart/orca-pytorch-quickstart.html">PyTorch Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray/QuickStart/ray-quickstart.html">RayOnSpark Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/python.html">Python User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/scala.html">Scala User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/colab.html">Colab User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/docker.html">Docker User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/hadoop.html">Hadoop/YARN User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/k8s.html">K8s User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/databricks.html">Databricks User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/develop.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UserGuide/known_issues.html">BigDL Known Issues</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Nano</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Nano/Overview/nano.html">Nano User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Nano/Overview/windows_guide.html">Windows User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Nano/QuickStart/pytorch_train.html">BigDL-Nano PyTorch Training Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Nano/QuickStart/pytorch_inference.html">BigDL-Nano PyTorch Inference Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Nano/QuickStart/tensorflow_train.html">BigDL-Nano TensorFlow Training Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Nano/QuickStart/tensorflow_inference.html">BigDL-Nano TensorFlow Inference Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Nano/QuickStart/hpo.html">AutoML Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Nano/Overview/known_issues.html">Nano Known Issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Nano/QuickStart/index.html">Nano Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">DLlib</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="dllib.html">DLlib User Guide</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Keras-Like API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lenet-example">2. LeNet Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="#shape">3. Shape</a></li>
<li class="toctree-l2"><a class="reference internal" href="#define-a-model">4. Define a model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sequential-api">5. Sequential API</a></li>
<li class="toctree-l2"><a class="reference internal" href="#functional-api">6. Functional API</a></li>
<li class="toctree-l2"><a class="reference internal" href="#core-layers">7. Core Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#masking">7.1 Masking</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sparsedense">7.2 SparseDense</a></li>
<li class="toctree-l3"><a class="reference internal" href="#softshrink">7.3 SoftShrink</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reshape">7.4 Reshape</a></li>
<li class="toctree-l3"><a class="reference internal" href="#merge">7.5 Merge</a></li>
<li class="toctree-l3"><a class="reference internal" href="#maxoutdense">7.6 MaxoutDense</a></li>
<li class="toctree-l3"><a class="reference internal" href="#squeeze">7.7 Squeeze</a></li>
<li class="toctree-l3"><a class="reference internal" href="#binarythreshold">7.8 BinaryThreshold</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sqrt">7.9 Sqrt</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mul">7.10 Mul</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mulconstant">7.11 MulConstant</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scale">7.12 Scale</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log">7.13 Log</a></li>
<li class="toctree-l3"><a class="reference internal" href="#identity">7.14 Identity</a></li>
<li class="toctree-l3"><a class="reference internal" href="#select">7.15 Select</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dense">7.16 Dense</a></li>
<li class="toctree-l3"><a class="reference internal" href="#negative">7.17 Negative</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cadd">7.18 CAdd</a></li>
<li class="toctree-l3"><a class="reference internal" href="#repeatvector">7.19 RepeatVector</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gaussiansampler">7.20 GaussianSampler</a></li>
<li class="toctree-l3"><a class="reference internal" href="#exp">7.21 Exp</a></li>
<li class="toctree-l3"><a class="reference internal" href="#square">7.22 Square</a></li>
<li class="toctree-l3"><a class="reference internal" href="#power">7.23 Power</a></li>
<li class="toctree-l3"><a class="reference internal" href="#addconstant">7.24 AddConstant</a></li>
<li class="toctree-l3"><a class="reference internal" href="#narrow">7.25 Narrow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#permute">7.26 Permute</a></li>
<li class="toctree-l3"><a class="reference internal" href="#resizebilinear">7.27 ResizeBilinear</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#persistence">8. Persistence</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#save">8.1 save</a></li>
<li class="toctree-l3"><a class="reference internal" href="#load">8.2 load</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nnframes.html">Spark ML Pipeline Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Orca</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/Overview/orca.html">Orca User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/Overview/orca-context.html">Orca Context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/Overview/data-parallel-processing.html">Distributed Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/Overview/distributed-training-inference.html">Distributed Training and Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/Overview/distributed-tuning.html">Distributed Hyper-Parameter Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Ray/Overview/ray.html">RayOnSpark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/Overview/known_issues.html">Orca Known Issues</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chronos</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Chronos/Overview/chronos.html">Chronos User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Chronos/Overview/windows_guide.html">Windows User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Chronos/Overview/deep_dive.html">Chronos Deep Dive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Chronos/QuickStart/index.html">Chronos Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Chronos/Overview/chronos_known_issue.html">Chronos Known Issue</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PPML</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/Overview/ppml.html">Privacy Preserving Machine Learning (PPML) User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/Overview/trusted_big_data_analytics_and_ml.html">Trusted Big Data Analytics and ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/Overview/trusted_fl.html">Trusted FL (Federated Learning)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/QuickStart/secure_your_services.html">Secure Your Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/QuickStart/build_kernel_with_sgx.html">Building Linux Kernel from Source with SGX Enabled</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/QuickStart/deploy_intel_sgx_device_plugin_for_kubernetes.html">Deploy the Intel SGX Device Plugin for Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/QuickStart/trusted-serving-on-k8s-guide.html">Trusted Cluster Serving with Graphene on Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/QuickStart/tpc-h_with_sparksql_on_k8s.html">TPC-H with Trusted SparkSQL on Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/QuickStart/tpc-ds_with_sparksql_on_k8s.html">TPC-DS with Trusted SparkSQL on Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PPML/Overview/azure_ppml.html">Privacy Preserving Machine Learning (PPML) on Azure User Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Serving</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/Overview/serving.html">Cluster Serving User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/QuickStart/serving-quickstart.html">Cluster Serving Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/ProgrammingGuide/serving-installation.html">Install Cluster Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/ProgrammingGuide/serving-start.html">Start Cluster Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/ProgrammingGuide/serving-inference.html">Inference by Cluster Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/Example/example.html">Cluster Serving Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/FAQ/faq.html">Cluster Serving FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Serving/FAQ/contribute-guide.html">Contribute to Cluster Serving</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Common Use Case</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/QuickStart/orca-pytorch-distributed-quickstart.html">Use <code class="docutils literal notranslate"><span class="pre">torch.distributed</span></code> in Orca</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UseCase/spark-dataframe.html">Use Spark Dataframe for Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UseCase/xshards-pandas.html">Use Distributed Pandas for Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/QuickStart/orca-autoestimator-pytorch-quickstart.html">Enable AutoML for PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Orca/QuickStart/orca-autoxgboost-quickstart.html">Use AutoXGBoost to auto-tune XGBoost parameters</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../PythonAPI/Orca/orca.html">Orca API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PythonAPI/Friesian/feature.html">Friesian Feature API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PythonAPI/Chronos/index.html">Chronos API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../PythonAPI/Nano/index.html">Nano API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Real-World Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Application/presentations.html">Presentations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Application/blogs.html">Blogs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Application/powered-by.html">Powered By</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">BigDL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Keras-Like API</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/doc/DLlib/Overview/keras-api.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="keras-like-api">
<h1>Keras-Like API<a class="headerlink" href="#keras-like-api" title="Permalink to this headline">¶</a></h1>
<section id="introduction">
<h2>1. Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="dllib.html"><span class="doc">DLlib</span></a> provides <strong>Keras-like API</strong> based on <a class="reference external" href="https://faroit.github.io/keras-docs/1.2.2/"><strong>Keras 1.2.2</strong></a> for distributed deep learning on Apache Spark. Users can easily use the Keras-like API to create a neural network model, and train, evaluate or tune it in a distributed fashion on Spark.</p>
<p>To define a model in Scala using the Keras-like API, one just needs to import the following packages:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers._</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models._</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
</pre></div>
</div>
<p>One of the highlighted features with regard to the new API is <strong>shape inference</strong>. Users only need to specify the input shape (a <code class="docutils literal notranslate"><span class="pre">Shape</span></code> object <strong>excluding</strong> batch dimension, for example, <code class="docutils literal notranslate"><span class="pre">inputShape=Shape(3,</span> <span class="pre">4)</span></code> for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.</p>
</section>
<hr class="docutils" />
<section id="lenet-example">
<h2>2. LeNet Example<a class="headerlink" href="#lenet-example" title="Permalink to this headline">¶</a></h2>
<p>Here we use the Keras-like API to define a LeNet CNN model and train it on the MNIST dataset:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.numeric.NumericFloat</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers._</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models._</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Reshape</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">28</span><span class="o">,</span> <span class="mi">28</span><span class="o">),</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">28</span><span class="o">,</span> <span class="mi">28</span><span class="o">,</span> <span class="mi">1</span><span class="o">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Convolution2D</span><span class="o">(</span><span class="mi">6</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="n">activation</span> <span class="k">=</span> <span class="s">&quot;tanh&quot;</span><span class="o">).</span><span class="n">setName</span><span class="o">(</span><span class="s">&quot;conv1_5x5&quot;</span><span class="o">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">MaxPooling2D</span><span class="o">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Convolution2D</span><span class="o">(</span><span class="mi">12</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="n">activation</span> <span class="k">=</span> <span class="s">&quot;tanh&quot;</span><span class="o">).</span><span class="n">setName</span><span class="o">(</span><span class="s">&quot;conv2_5x5&quot;</span><span class="o">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">MaxPooling2D</span><span class="o">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Flatten</span><span class="o">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Dense</span><span class="o">(</span><span class="mi">100</span><span class="o">,</span> <span class="n">activation</span> <span class="k">=</span> <span class="s">&quot;tanh&quot;</span><span class="o">).</span><span class="n">setName</span><span class="o">(</span><span class="s">&quot;fc1&quot;</span><span class="o">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Dense</span><span class="o">(</span><span class="mi">10</span><span class="o">,</span> <span class="n">activation</span> <span class="k">=</span> <span class="s">&quot;softmax&quot;</span><span class="o">).</span><span class="n">setName</span><span class="o">(</span><span class="s">&quot;fc2&quot;</span><span class="o">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">getInputShape</span><span class="o">().</span><span class="n">toSingle</span><span class="o">().</span><span class="n">toArray</span> <span class="c1">// Array(-1, 28, 28, 1)</span>
<span class="n">model</span><span class="o">.</span><span class="n">getOutputShape</span><span class="o">().</span><span class="n">toSingle</span><span class="o">().</span><span class="n">toArray</span> <span class="c1">// Array(-1, 10)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="shape">
<h2>3. Shape<a class="headerlink" href="#shape" title="Permalink to this headline">¶</a></h2>
<p>Input and output shapes of a model in the Keras-like API are described by the <code class="docutils literal notranslate"><span class="pre">Shape</span></code> object in Scala, which can be classified into <code class="docutils literal notranslate"><span class="pre">SingleShape</span></code> and <code class="docutils literal notranslate"><span class="pre">MultiShape</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">SingleShape</span></code> is just a list of Int indicating shape dimensions while <code class="docutils literal notranslate"><span class="pre">MultiShape</span></code> is essentially a list of <code class="docutils literal notranslate"><span class="pre">Shape</span></code>.</p>
<p>Example code to create a shape:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// create a SingleShape</span>
<span class="k">val</span> <span class="n">shape1</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">)</span>
<span class="c1">// create a MultiShape consisting of two SingleShape</span>
<span class="k">val</span> <span class="n">shape2</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="nc">List</span><span class="o">(</span><span class="nc">Shape</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">),</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">6</span><span class="o">)))</span>
</pre></div>
</div>
<p>You can use method <code class="docutils literal notranslate"><span class="pre">toSingle()</span></code> to cast a <code class="docutils literal notranslate"><span class="pre">Shape</span></code> to a <code class="docutils literal notranslate"><span class="pre">SingleShape</span></code>. Similarly, use <code class="docutils literal notranslate"><span class="pre">toMulti()</span></code> to cast a <code class="docutils literal notranslate"><span class="pre">Shape</span></code> to a <code class="docutils literal notranslate"><span class="pre">MultiShape</span></code>.</p>
</section>
<hr class="docutils" />
<section id="define-a-model">
<h2>4. Define a model<a class="headerlink" href="#define-a-model" title="Permalink to this headline">¶</a></h2>
<p>You can define a model either using <a class="reference external" href="#sequential-api">Sequential API</a> or <a class="reference external" href="#functional-api">Functional API</a>. Remember to specify the input shape for the first layer.</p>
<p>After creating a model, you can call the following <strong>methods</strong>:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">getInputShape</span><span class="o">()</span>
</pre></div>
</div>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">getOutputShape</span><span class="o">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Return the input or output shape of a model, which is a <a class="reference external" href="#2-shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For <code class="docutils literal notranslate"><span class="pre">SingleShape</span></code>, the first entry is <code class="docutils literal notranslate"><span class="pre">-1</span></code> representing the batch dimension. For a model with multiple inputs or outputs, it will return a <code class="docutils literal notranslate"><span class="pre">MultiShape</span></code>.</p></li>
</ul>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">setName</span><span class="o">(</span><span class="n">name</span><span class="o">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Set the name of the model.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="sequential-api">
<h2>5. Sequential API<a class="headerlink" href="#sequential-api" title="Permalink to this headline">¶</a></h2>
<p>The model is described as a linear stack of layers in the Sequential API. Layers can be added into the <code class="docutils literal notranslate"><span class="pre">Sequential</span></code> container one by one and the order of the layers in the model will be the same as the insertion order.</p>
<p>To create a sequential container:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Sequential</span><span class="o">()</span>
</pre></div>
</div>
<p>Example code to create a sequential model:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.</span><span class="o">{</span><span class="nc">Dense</span><span class="o">,</span> <span class="nc">Activation</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Dense</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">32</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">128</span><span class="o">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Activation</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="s">&quot;relu&quot;</span><span class="o">))</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="functional-api">
<h2>6. Functional API<a class="headerlink" href="#functional-api" title="Permalink to this headline">¶</a></h2>
<p>The model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs).</p>
<p>To create an input node:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Input</span><span class="o">(</span><span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">name</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p>Parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: A <a class="reference external" href="#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object indicating the shape of the input node, not including batch.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: String to set the name of the input node. If not specified, its name will by default to be a generated string.</p></li>
</ul>
<p>To create a graph container:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Model</span><span class="o">(</span><span class="n">input</span><span class="o">,</span> <span class="n">output</span><span class="o">)</span>
</pre></div>
</div>
<p>Parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input</span></code>: An input node or an array of input nodes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">output</span></code>: An output node or an array of output nodes.</p></li>
</ul>
<p>To merge a list of input <strong>nodes</strong> (<strong>NOT</strong> layers), following some merge mode in the Functional API:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Merge.merge</span>

<span class="n">merge</span><span class="o">(</span><span class="n">inputs</span><span class="o">,</span> <span class="n">mode</span> <span class="k">=</span> <span class="s">&quot;sum&quot;</span><span class="o">,</span> <span class="n">concatAxis</span> <span class="k">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">)</span> <span class="c1">// This will return an output NODE.</span>
</pre></div>
</div>
<p>Parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">inputs</span></code>: A list of node instances. Must be more than one node.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mode</span></code>: Merge mode. String, must be one of: ‘sum’, ‘mul’, ‘concat’, ‘ave’, ‘cos’, ‘dot’, ‘max’. Default is ‘sum’.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">concatAxis</span></code>: Int, axis to use when concatenating nodes. Only specify this when merge mode is ‘concat’. Default is -1, meaning the last axis of the input.</p></li>
</ul>
<p>Example code to create a graph model:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.</span><span class="o">{</span><span class="nc">Dense</span><span class="o">,</span> <span class="nc">Input</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Merge.merge</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Model</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>

<span class="c1">// instantiate input nodes</span>
<span class="k">val</span> <span class="n">input1</span> <span class="k">=</span> <span class="nc">Input</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">8</span><span class="o">))</span>
<span class="k">val</span> <span class="n">input2</span> <span class="k">=</span> <span class="nc">Input</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">6</span><span class="o">))</span>
<span class="c1">// call inputs() with an input node and get an output node</span>
<span class="k">val</span> <span class="n">dense1</span> <span class="k">=</span> <span class="nc">Dense</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">10</span><span class="o">).</span><span class="n">inputs</span><span class="o">(</span><span class="n">input1</span><span class="o">)</span>
<span class="k">val</span> <span class="n">dense2</span> <span class="k">=</span> <span class="nc">Dense</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">10</span><span class="o">).</span><span class="n">inputs</span><span class="o">(</span><span class="n">input2</span><span class="o">)</span>
<span class="c1">// merge two nodes following some merge mode</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">merge</span><span class="o">(</span><span class="n">inputs</span> <span class="k">=</span> <span class="nc">List</span><span class="o">(</span><span class="n">dense1</span><span class="o">,</span> <span class="n">dense2</span><span class="o">),</span> <span class="n">mode</span> <span class="k">=</span> <span class="s">&quot;sum&quot;</span><span class="o">)</span>
<span class="c1">// create a graph container</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Model</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="nc">Array</span><span class="o">(</span><span class="n">input1</span><span class="o">,</span> <span class="n">input2</span><span class="o">),</span> <span class="n">output</span><span class="o">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="core-layers">
<h2>7. Core Layers<a class="headerlink" href="#core-layers" title="Permalink to this headline">¶</a></h2>
<p>This section describes all the available layers in the Keras-like API.</p>
<p>To set the name of a specific layer, you call the method <code class="docutils literal notranslate"><span class="pre">setName(name)</span></code> of that layer.</p>
<section id="masking">
<h3>7.1 Masking<a class="headerlink" href="#masking" title="Permalink to this headline">¶</a></h3>
<p>Use a mask value to skip timesteps for a sequence.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Masking</span><span class="o">(</span><span class="n">maskValue</span> <span class="k">=</span> <span class="mf">0.0</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Masking</span><span class="p">(</span><span class="n">mask_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">maskValue</span></code>: Mask value. For each timestep in the input (the second dimension), if all the values in the input at that timestep are equal to ‘maskValue’, then the timestep will be masked (skipped) in all downstream layers.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Masking</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Masking</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">3</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
1.4539868       1.5623108       -1.4101523
0.77073747      -0.18994702     2.2574463
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
1.4539868       1.5623108       -1.4101523
0.77073747      -0.18994702     2.2574463
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.nn.keras.topology</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">bigdl.nn.keras.layer</span> <span class="kn">import</span> <span class="n">Masking</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Masking</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mf">0.31542103</span> <span class="mf">0.20640659</span> <span class="mf">0.22282763</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.99352167</span> <span class="mf">0.90135718</span> <span class="mf">0.24504717</span><span class="p">]]</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mf">0.31542102</span> <span class="mf">0.2064066</span>  <span class="mf">0.22282763</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.9935217</span>  <span class="mf">0.9013572</span>  <span class="mf">0.24504717</span><span class="p">]]</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="sparsedense">
<h3>7.2 SparseDense<a class="headerlink" href="#sparsedense" title="Permalink to this headline">¶</a></h3>
<p>SparseDense is the sparse version of layer Dense. SparseDense has two different from Dense:
firstly, SparseDense’s input Tensor is a SparseTensor. Secondly, SparseDense doesn’t backward
gradient to next layer in the backpropagation by default, as the gradInput of SparseDense is
useless and very big in most cases.</p>
<p>But, considering model like Wide&amp;Deep, we provide backwardStart and backwardLength to backward
part of the gradient to next layer.</p>
<p>The most common input is 2D.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">SparseDense</span><span class="o">(</span><span class="n">outputDim</span><span class="o">,</span> <span class="n">init</span> <span class="k">=</span> <span class="s">&quot;glorot_uniform&quot;</span><span class="o">,</span> <span class="n">activation</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">wRegularizer</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">bRegularizer</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">backwardStart</span> <span class="k">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">,</span> <span class="n">backwardLength</span> <span class="k">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">,</span> <span class="n">initWeight</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">initBias</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">initGradWeight</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">initGradBias</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">bias</span> <span class="k">=</span> <span class="kc">true</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SparseDense</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;glorot_uniform&quot;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">W_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">backward_start</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">backward_length</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">init_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">init_bias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">init_grad_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">init_grad_bias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">outputDim</span></code>: The size of the output dimension.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">init</span></code>: String representation of the initialization method for the weights of the layer. Default is ‘glorot_uniform’.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">activation</span></code>: String representation of the activation function to use. Default is null.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">wRegularizer</span></code>: An instance of [Regularizer], applied to the input weights matrices. Default is null.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bRegularizer</span></code>: An instance of [Regularizer], applied to the bias. Default is null.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bias</span></code>: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">backwardStart</span></code>: Backward start index, counting from 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">backwardLength</span></code>: Backward length.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <code class="docutils literal notranslate"><span class="pre">Shape</span></code> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: String to set the name of the layer. If not specified, its name will by default to be a generated string.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.SparseDense</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">layer</span> <span class="k">=</span> <span class="nc">SparseDense</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">outputDim</span> <span class="k">=</span> <span class="mi">5</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">))</span>
<span class="n">layer</span><span class="o">.</span><span class="n">build</span><span class="o">(</span><span class="nc">Shape</span><span class="o">(-</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="nc">Array</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">)).</span><span class="n">rand</span><span class="o">()</span>
<span class="n">input</span><span class="o">.</span><span class="n">setValue</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="n">f</span><span class="o">)</span>
<span class="n">input</span><span class="o">.</span><span class="n">setValue</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">3</span><span class="n">f</span><span class="o">)</span>
<span class="k">val</span> <span class="n">sparseInput</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">.</span><span class="n">sparse</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">sparseInput</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: 
(0, 0) : 1.0
(0, 1) : 0.2992794
(0, 2) : 0.11227019
(0, 3) : 0.722947
(1, 0) : 0.6147614
(1, 1) : 0.4288646
(1, 2) : 3.0
(1, 3) : 0.7749917
[com.intel.analytics.bigdl.tensor.SparseTensor of size 2x4]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: 
0.053516	0.33429605	0.22587383	-0.8998945	0.24308181	
0.76745665	-1.614114	0.5381658	-2.2226436	-0.15573677	
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.utils.common</span> <span class="kn">import</span> <span class="n">JTensor</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">SparseDense</span><span class="p">(</span><span class="n">output_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">JTensor</span><span class="o">.</span><span class="n">sparse</span><span class="p">(</span>
    <span class="n">a_ndarray</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span>
    <span class="n">i_ndarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">JTensor</span><span class="p">:</span> <span class="n">storage</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.</span> <span class="mf">3.</span> <span class="mf">2.</span> <span class="mf">4.</span><span class="p">],</span> <span class="n">shape</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span><span class="p">]</span> <span class="p">,</span><span class="n">indices</span> <span class="p">[[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">0</span> <span class="mi">3</span> <span class="mi">2</span> <span class="mi">1</span><span class="p">]],</span> <span class="nb">float</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span> <span class="mf">1.57136</span>     <span class="mf">2.29596</span>   <span class="p">]</span>
 <span class="p">[</span> <span class="mf">0.5791738</span>  <span class="o">-</span><span class="mf">1.6598101</span> <span class="p">]</span>
 <span class="p">[</span> <span class="mf">2.331141</span>   <span class="o">-</span><span class="mf">0.84687066</span><span class="p">]]</span>
</pre></div>
</div>
</section>
<section id="softshrink">
<h3>7.3 SoftShrink<a class="headerlink" href="#softshrink" title="Permalink to this headline">¶</a></h3>
<p>Applies the soft shrinkage function element-wise to the input.</p>
<p>When you use this layer as the first layer of a model, you need to provide
the argument inputShape (a Single Shape, does not include the batch dimension).</p>
<p>Remark: This layer is from Torch and wrapped in Keras style.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">SoftShrink</span><span class="o">(</span><span class="n">value</span> <span class="k">=</span> <span class="mf">0.5</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SoftShrink</span><span class="p">(</span><span class="n">value</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">value</span></code>: value The threshold value. Default is 0.5.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <code class="docutils literal notranslate"><span class="pre">Shape</span></code> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: String to set the name of the layer. If not specified, its name will by default to be a generated string.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.SoftShrink</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">SoftShrink</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mf">0.6</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,1,.,.) =
-0.36938807	0.023556225	-1.1655436	-0.34449077
0.9444338	-0.086538695	-1.0425501	1.364976
-1.2563878	-0.1842559	0.43428117	1.0756494

(1,2,.,.) =
-0.19888283	1.251872	0.114836805	-0.6208773
0.0051822234	-0.8998633	0.06937465	-0.3929931
-0.1058129	0.6945743	-0.40083578	-0.6252444

(2,1,.,.) =
-0.9899709	-0.77926594	-0.15497442	-0.15031165
-0.6028622	0.86623466	-2.1543107	0.41970536
-0.8215522	0.3014275	-0.32184362	0.14445356

(2,2,.,.) =
0.74701905	0.10044397	-0.40519297	0.03822808
0.30726334	0.27862388	1.731753	0.032177072
-1.3476961	-0.2294767	0.99794704	0.7398458

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,1,.,.) =
0.0	0.0	-0.56554353	0.0
0.34443378	0.0	-0.44255006	0.764976
-0.6563878	0.0	0.0	0.47564936

(1,2,.,.) =
0.0	0.6518719	0.0	-0.020877302
0.0	-0.29986328	0.0	0.0
0.0	0.09457427	0.0	-0.025244355

(2,1,.,.) =
-0.3899709	-0.17926592	0.0	0.0
-0.0028621554	0.26623464	-1.5543107	0.0
-0.2215522	0.0	0.0	0.0

(2,2,.,.) =
0.14701903	0.0	0.0	0.0
0.0	0.0	1.131753	0.0
-0.74769604	0.0	0.397947	0.13984579

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">SoftShrink</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[[</span> <span class="mf">0.43421006</span><span class="p">,</span>  <span class="mf">0.28394451</span><span class="p">,</span>  <span class="mf">0.15221226</span><span class="p">,</span>  <span class="mf">0.47268966</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.22426224</span><span class="p">,</span>  <span class="mf">0.24855662</span><span class="p">,</span>  <span class="mf">0.790498</span>  <span class="p">,</span>  <span class="mf">0.67767582</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.14879562</span><span class="p">,</span>  <span class="mf">0.56077882</span><span class="p">,</span>  <span class="mf">0.61470262</span><span class="p">,</span>  <span class="mf">0.94875862</span><span class="p">]],</span>

        <span class="p">[[</span> <span class="mf">0.72404932</span><span class="p">,</span>  <span class="mf">0.89780875</span><span class="p">,</span>  <span class="mf">0.08456734</span><span class="p">,</span>  <span class="mf">0.01303937</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.25023568</span><span class="p">,</span>  <span class="mf">0.45392504</span><span class="p">,</span>  <span class="mf">0.587254</span>  <span class="p">,</span>  <span class="mf">0.51164461</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.12277567</span><span class="p">,</span>  <span class="mf">0.05571182</span><span class="p">,</span>  <span class="mf">0.17076456</span><span class="p">,</span>  <span class="mf">0.71660884</span><span class="p">]]],</span>


       <span class="p">[[[</span> <span class="mf">0.06369975</span><span class="p">,</span>  <span class="mf">0.85395557</span><span class="p">,</span>  <span class="mf">0.35752425</span><span class="p">,</span>  <span class="mf">0.606633</span>  <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.67640252</span><span class="p">,</span>  <span class="mf">0.86861737</span><span class="p">,</span>  <span class="mf">0.18040722</span><span class="p">,</span>  <span class="mf">0.55467108</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.24102058</span><span class="p">,</span>  <span class="mf">0.37580645</span><span class="p">,</span>  <span class="mf">0.81601612</span><span class="p">,</span>  <span class="mf">0.56513788</span><span class="p">]],</span>

        <span class="p">[[</span> <span class="mf">0.8461435</span> <span class="p">,</span>  <span class="mf">0.65668365</span><span class="p">,</span>  <span class="mf">0.17969807</span><span class="p">,</span>  <span class="mf">0.51602926</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.86191073</span><span class="p">,</span>  <span class="mf">0.34245714</span><span class="p">,</span>  <span class="mf">0.62795207</span><span class="p">,</span>  <span class="mf">0.36706125</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.80344028</span><span class="p">,</span>  <span class="mf">0.81056003</span><span class="p">,</span>  <span class="mf">0.80959083</span><span class="p">,</span>  <span class="mf">0.15366483</span><span class="p">]]]])</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.19049799</span><span class="p">,</span>  <span class="mf">0.07767582</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.01470262</span><span class="p">,</span>  <span class="mf">0.34875858</span><span class="p">]],</span>

        <span class="p">[[</span> <span class="mf">0.12404931</span><span class="p">,</span>  <span class="mf">0.29780871</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.1166088</span> <span class="p">]]],</span>


       <span class="p">[[[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.25395554</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.00663298</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.07640249</span><span class="p">,</span>  <span class="mf">0.26861733</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.21601611</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">]],</span>

        <span class="p">[[</span> <span class="mf">0.24614346</span><span class="p">,</span>  <span class="mf">0.05668366</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.26191074</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.02795208</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.20344025</span><span class="p">,</span>  <span class="mf">0.21056002</span><span class="p">,</span>  <span class="mf">0.20959079</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">]]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="reshape">
<h3>7.4 Reshape<a class="headerlink" href="#reshape" title="Permalink to this headline">¶</a></h3>
<p>Reshapes an output to a certain shape.</p>
<p>Supports shape inference by allowing one -1 in the target shape. For example, if input shape is (2, 3, 4), target shape is (3, -1), then output shape will be (3, 8).</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Reshape</span><span class="o">(</span><span class="n">targetShape</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Reshape</span><span class="p">(</span><span class="n">target_shape</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">targetShape</span></code>: The target shape that you desire to have. Batch dimension should be excluded.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Reshape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Reshape</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mi">8</span><span class="o">),</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,1,.,.) =
-1.7092276	-1.3941092	-0.6348466	0.71309644
0.3605411	0.025597548	0.4287048	-0.548675
0.4623341	-2.3912702	0.22030865	-0.058272455

(1,2,.,.) =
-1.5049093	-1.8828062	0.8230564	-0.020209199
-0.3415721	1.1219939	1.1089007	-0.74697906
-1.503861	-1.616539	0.048006497	1.1613717

(2,1,.,.) =
0.21216023	1.0107462	0.8586909	-0.05644316
-0.31436008	1.6892323	-0.9961186	-0.08169463
0.3559391	0.010261055	-0.70408463	-1.2480727

(2,2,.,.) =
1.7663039	0.07122444	0.073556066	-0.7847014
0.17604464	-0.99110585	-1.0302067	-0.39024687
-0.0260166	-0.43142694	0.28443158	0.72679126

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
-1.7092276	-1.3941092	-0.6348466	0.71309644	    0.3605411	0.025597548	0.4287048	-0.548675
0.4623341	-2.3912702	0.22030865	-0.058272455	-1.5049093	-1.8828062	0.8230564	-0.020209199
-0.3415721	1.1219939	1.1089007	-0.74697906	    -1.503861	-1.616539	0.048006497	1.1613717

(2,.,.) =
0.21216023	1.0107462	0.8586909	-0.05644316	    -0.31436008	1.6892323	-0.9961186	-0.08169463
0.3559391	0.010261055	-0.70408463	-1.2480727	    1.7663039	0.07122444	0.073556066	-0.7847014
0.17604464	-0.99110585	-1.0302067	-0.39024687	    -0.0260166	-0.43142694	0.28443158	0.72679126

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x8]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Reshape</span><span class="p">(</span><span class="n">target_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[[</span><span class="mf">0.39260304</span> <span class="mf">0.10383185</span> <span class="mf">0.87490319</span> <span class="mf">0.89167328</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.61649117</span> <span class="mf">0.43285247</span> <span class="mf">0.86851582</span> <span class="mf">0.97743004</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.90018969</span> <span class="mf">0.04303951</span> <span class="mf">0.74263493</span> <span class="mf">0.14208656</span><span class="p">]]</span>
  <span class="p">[[</span><span class="mf">0.66193405</span> <span class="mf">0.93432157</span> <span class="mf">0.76160537</span> <span class="mf">0.70437459</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.99953431</span> <span class="mf">0.23016734</span> <span class="mf">0.42293405</span> <span class="mf">0.66078049</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.03357645</span> <span class="mf">0.9695145</span>  <span class="mf">0.30111138</span> <span class="mf">0.67109948</span><span class="p">]]]</span>

 <span class="p">[[[</span><span class="mf">0.39640201</span> <span class="mf">0.92930203</span> <span class="mf">0.86027666</span> <span class="mf">0.13958544</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.34584767</span> <span class="mf">0.14743425</span> <span class="mf">0.93804016</span> <span class="mf">0.38053062</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.55068792</span> <span class="mf">0.77375329</span> <span class="mf">0.84161166</span> <span class="mf">0.48131356</span><span class="p">]]</span>
  <span class="p">[[</span><span class="mf">0.90116368</span> <span class="mf">0.53253689</span> <span class="mf">0.03332962</span> <span class="mf">0.58278686</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.34935685</span> <span class="mf">0.32599554</span> <span class="mf">0.97641892</span> <span class="mf">0.57696434</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.53974677</span> <span class="mf">0.90682861</span> <span class="mf">0.20027319</span> <span class="mf">0.05962118</span><span class="p">]]]]</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[</span><span class="mf">0.39260304</span> <span class="mf">0.10383185</span> <span class="mf">0.8749032</span>  <span class="mf">0.89167327</span> <span class="mf">0.6164912</span>  <span class="mf">0.43285248</span> <span class="mf">0.86851585</span> <span class="mf">0.97743005</span><span class="p">]</span>
  <span class="p">[</span><span class="mf">0.9001897</span>  <span class="mf">0.04303951</span> <span class="mf">0.74263495</span> <span class="mf">0.14208655</span> <span class="mf">0.661934</span>   <span class="mf">0.9343216</span>  <span class="mf">0.7616054</span>  <span class="mf">0.7043746</span> <span class="p">]</span>
  <span class="p">[</span><span class="mf">0.9995343</span>  <span class="mf">0.23016734</span> <span class="mf">0.42293406</span> <span class="mf">0.6607805</span>  <span class="mf">0.03357645</span> <span class="mf">0.9695145</span>  <span class="mf">0.30111137</span> <span class="mf">0.6710995</span> <span class="p">]]</span>

 <span class="p">[[</span><span class="mf">0.396402</span>   <span class="mf">0.92930204</span> <span class="mf">0.86027664</span> <span class="mf">0.13958544</span> <span class="mf">0.34584767</span> <span class="mf">0.14743425</span> <span class="mf">0.93804014</span> <span class="mf">0.38053063</span><span class="p">]</span>
  <span class="p">[</span><span class="mf">0.5506879</span>  <span class="mf">0.7737533</span>  <span class="mf">0.8416117</span>  <span class="mf">0.48131356</span> <span class="mf">0.9011637</span>  <span class="mf">0.53253686</span> <span class="mf">0.03332962</span> <span class="mf">0.58278686</span><span class="p">]</span>
  <span class="p">[</span><span class="mf">0.34935686</span> <span class="mf">0.32599553</span> <span class="mf">0.9764189</span>  <span class="mf">0.5769643</span>  <span class="mf">0.53974676</span> <span class="mf">0.9068286</span>  <span class="mf">0.20027319</span> <span class="mf">0.05962119</span><span class="p">]]]</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="merge">
<h3>7.5 Merge<a class="headerlink" href="#merge" title="Permalink to this headline">¶</a></h3>
<p>Used to merge a list of inputs into a single output, following some merge mode.</p>
<p>Merge must have at least two input layers.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Merge</span><span class="o">(</span><span class="n">layers</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">mode</span> <span class="k">=</span> <span class="s">&quot;sum&quot;</span><span class="o">,</span> <span class="n">concatAxis</span> <span class="k">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Merge</span><span class="p">(</span><span class="n">layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span> <span class="n">concat_axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">layers</span></code>: A list of layer instances. Must be more than one layer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mode</span></code>: Merge mode. String, must be one of: ‘sum’, ‘mul’, ‘concat’, ‘ave’, ‘cos’, ‘dot’, ‘max’. Default is ‘sum’.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">concatAxis</span></code>: Integer, axis to use when concatenating layers. Only specify this when merge mode is ‘concat’. Default is -1, meaning the last axis of the input.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">MultiShape</span></code></a> object. For Python API, it should be a list of shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.InputLayer</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Merge</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.utils.</span><span class="o">{</span><span class="nc">Shape</span><span class="o">,</span> <span class="n">T</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="k">val</span> <span class="n">l1</span> <span class="k">=</span> <span class="nc">InputLayer</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">))</span>
<span class="k">val</span> <span class="n">l2</span> <span class="k">=</span> <span class="nc">InputLayer</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">))</span>
<span class="k">val</span> <span class="n">layer</span> <span class="k">=</span> <span class="nc">Merge</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">layers</span> <span class="k">=</span> <span class="nc">List</span><span class="o">(</span><span class="n">l1</span><span class="o">,</span> <span class="n">l2</span><span class="o">),</span> <span class="n">mode</span> <span class="k">=</span> <span class="s">&quot;sum&quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="n">layer</span><span class="o">)</span>
<span class="k">val</span> <span class="n">input1</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">rand</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span>
<span class="k">val</span> <span class="n">input2</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">rand</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="n">T</span><span class="o">(</span><span class="mi">1</span> <span class="o">-&gt;</span> <span class="n">input1</span><span class="o">,</span> <span class="mi">2</span> <span class="o">-&gt;</span> <span class="n">input2</span><span class="o">)</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.utils.Table =
 {
	2: (1,.,.) =
	   0.87815475	0.15025006	0.34412447
	   0.07909282	0.008027249	0.111715704

	   (2,.,.) =
	   0.52245367	0.2547527	0.35857987
	   0.7718501	0.26783863	0.8642062

	   [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]
	1: (1,.,.) =
	   0.5377018	0.28364193	0.3424284
	   0.0075349305	0.9018168	0.9435114

	   (2,.,.) =
	   0.09112563	0.88585275	0.3100201
	   0.7910178	0.57497376	0.39764535

	   [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]
 }
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
1.4158566	0.433892	0.6865529
0.08662775	0.90984404	1.0552272

(2,.,.) =
0.6135793	1.1406054	0.66859996
1.5628679	0.8428124	1.2618515

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">l1</span> <span class="o">=</span> <span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">l2</span> <span class="o">=</span> <span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Merge</span><span class="p">(</span><span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="n">l1</span><span class="p">,</span> <span class="n">l2</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])]</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[[</span><span class="mf">0.28764351</span><span class="p">,</span> <span class="mf">0.0236015</span> <span class="p">,</span> <span class="mf">0.78927442</span><span class="p">,</span> <span class="mf">0.52646492</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.63922826</span><span class="p">,</span> <span class="mf">0.45101604</span><span class="p">,</span> <span class="mf">0.4555552</span> <span class="p">,</span> <span class="mf">0.70105653</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.75790798</span><span class="p">,</span> <span class="mf">0.78551523</span><span class="p">,</span> <span class="mf">0.00686686</span><span class="p">,</span> <span class="mf">0.61290369</span><span class="p">]],</span>

  <span class="p">[[</span><span class="mf">0.00430865</span><span class="p">,</span> <span class="mf">0.3303661</span> <span class="p">,</span> <span class="mf">0.59915782</span><span class="p">,</span> <span class="mf">0.90362298</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.26230717</span><span class="p">,</span> <span class="mf">0.99383052</span><span class="p">,</span> <span class="mf">0.50630521</span><span class="p">,</span> <span class="mf">0.99119486</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.56138318</span><span class="p">,</span> <span class="mf">0.68165639</span><span class="p">,</span> <span class="mf">0.10644523</span><span class="p">,</span> <span class="mf">0.51860127</span><span class="p">]]],</span>

 <span class="p">[[[</span><span class="mf">0.84365767</span><span class="p">,</span> <span class="mf">0.8854741</span> <span class="p">,</span> <span class="mf">0.84183673</span><span class="p">,</span> <span class="mf">0.96322321</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.49354248</span><span class="p">,</span> <span class="mf">0.97936826</span><span class="p">,</span> <span class="mf">0.2266097</span> <span class="p">,</span> <span class="mf">0.88083622</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.11011776</span><span class="p">,</span> <span class="mf">0.65762034</span><span class="p">,</span> <span class="mf">0.17446099</span><span class="p">,</span> <span class="mf">0.76658969</span><span class="p">]],</span>

  <span class="p">[[</span><span class="mf">0.58266689</span><span class="p">,</span> <span class="mf">0.86322199</span><span class="p">,</span> <span class="mf">0.87122999</span><span class="p">,</span> <span class="mf">0.19031255</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.42275118</span><span class="p">,</span> <span class="mf">0.76379413</span><span class="p">,</span> <span class="mf">0.21355413</span><span class="p">,</span> <span class="mf">0.81132937</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.97294728</span><span class="p">,</span> <span class="mf">0.68601731</span><span class="p">,</span> <span class="mf">0.39871792</span><span class="p">,</span> <span class="mf">0.63172344</span><span class="p">]]]]</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[</span><span class="mf">1.1313012</span>  <span class="mf">0.90907556</span> <span class="mf">1.6311111</span>  <span class="mf">1.4896882</span> <span class="p">]</span>
  <span class="p">[</span><span class="mf">1.1327708</span>  <span class="mf">1.4303843</span>  <span class="mf">0.6821649</span>  <span class="mf">1.5818927</span> <span class="p">]</span>
  <span class="p">[</span><span class="mf">0.8680257</span>  <span class="mf">1.4431355</span>  <span class="mf">0.18132785</span> <span class="mf">1.3794935</span> <span class="p">]]</span>

 <span class="p">[[</span><span class="mf">0.5869755</span>  <span class="mf">1.1935881</span>  <span class="mf">1.4703878</span>  <span class="mf">1.0939355</span> <span class="p">]</span>
  <span class="p">[</span><span class="mf">0.68505836</span> <span class="mf">1.7576246</span>  <span class="mf">0.71985936</span> <span class="mf">1.8025242</span> <span class="p">]</span>
  <span class="p">[</span><span class="mf">1.5343305</span>  <span class="mf">1.3676738</span>  <span class="mf">0.50516313</span> <span class="mf">1.1503248</span> <span class="p">]]]</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="maxoutdense">
<h3>7.6 MaxoutDense<a class="headerlink" href="#maxoutdense" title="Permalink to this headline">¶</a></h3>
<p>A dense maxout layer that takes the element-wise maximum of linear layers.</p>
<p>This allows the layer to learn a convex, piecewise linear activation function over the inputs.</p>
<p>The input of this layer should be 2D.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">MaxoutDense</span><span class="o">(</span><span class="n">outputDim</span><span class="o">,</span> <span class="n">nbFeature</span> <span class="k">=</span> <span class="mi">4</span><span class="o">,</span> <span class="n">wRegularizer</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">bRegularizer</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">bias</span> <span class="k">=</span> <span class="kc">true</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">MaxoutDense</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">nb_feature</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">W_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">outputDim</span></code>: The size of output dimension.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nbFeature</span></code>: Number of Dense layers to use internally. Integer. Default is 4.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">wRegularizer</span></code>: An instance of <a class="reference external" href="https://bigdl-project.github.io/master/#APIGuide/Regularizers/">Regularizer</a>, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bRegularizer</span></code>: An instance of <a class="reference external" href="https://bigdl-project.github.io/master/#APIGuide/Regularizers/">Regularizer</a>, applied to the bias. Default is null.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bias</span></code>: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.MaxoutDense</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">MaxoutDense</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">3</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
-1.3550005	-1.1668127	-1.2882779
0.83600295	-1.94683	1.323666
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
0.71675766	1.2987505
0.9871184	0.6634239
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxoutDense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mf">0.15996114</span> <span class="mf">0.8391686</span>  <span class="mf">0.81922903</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.52929427</span> <span class="mf">0.35061754</span> <span class="mf">0.88167693</span><span class="p">]]</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mf">0.4479192</span>  <span class="mf">0.4842512</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.16833156</span> <span class="mf">0.521764</span> <span class="p">]]</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="squeeze">
<h3>7.7 Squeeze<a class="headerlink" href="#squeeze" title="Permalink to this headline">¶</a></h3>
<p>Delete the singleton dimension(s). The batch dimension needs to be unchanged.</p>
<p>For example, if input has size (2, 1, 3, 4, 1):</p>
<p>Squeeze(1) will give output size (2, 3, 4, 1),</p>
<p>Squeeze() will give output size (2, 3, 4)</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Squeeze</span><span class="o">(</span><span class="n">dims</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dims</span></code>: The dimension(s) to squeeze. 0-based index. Cannot squeeze the batch dimension. The selected dimensions must be singleton, i.e. having size 1. Default is null, and in this case all the non-batch singleton dimensions will be deleted.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Squeeze</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Squeeze</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">1</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">32</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">32</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,1,.,.) =
0.5521966       -1.2199087      0.365958        1.3845297       0.115254946     -0.20352958     2.4912808       0.987046        -0.2115477      3.0530396      -1.0043625      1.4688021       -1.2412603      -0.25383064     0.49164283      -0.40329486     0.26323202      0.7979045       0.025444122   0.47221214       1.3995043       0.48498031      -0.86961967     -0.058370713    -0.85965866     -1.2727696      0.45570874      0.73393697      0.2567143      1.4261572       -0.37773672     -0.7339463

[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x32]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
0.5521966       -1.2199087      0.365958        1.3845297       0.115254946     -0.20352958     2.4912808       0.987046        -0.2115477      3.0530396      -1.0043625      1.4688021       -1.2412603      -0.25383064     0.49164283      -0.40329486     0.26323202      0.7979045       0.025444122   0.47221214       1.3995043       0.48498031      -0.86961967     -0.058370713    -0.85965866     -1.2727696      0.45570874      0.73393697      0.2567143      1.4261572       -0.37773672     -0.7339463

[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x32]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[[</span><span class="mf">0.20585343</span><span class="p">,</span> <span class="mf">0.47011701</span><span class="p">,</span> <span class="mf">0.14553177</span><span class="p">,</span> <span class="mf">0.93915599</span><span class="p">,</span> <span class="mf">0.57234281</span><span class="p">,</span>
    <span class="mf">0.91631229</span><span class="p">,</span> <span class="mf">0.32244256</span><span class="p">,</span> <span class="mf">0.94243351</span><span class="p">,</span> <span class="mf">0.86595631</span><span class="p">,</span> <span class="mf">0.73916763</span><span class="p">,</span>
    <span class="mf">0.35898731</span><span class="p">,</span> <span class="mf">0.65208275</span><span class="p">,</span> <span class="mf">0.07935983</span><span class="p">,</span> <span class="mf">0.89313423</span><span class="p">,</span> <span class="mf">0.68601269</span><span class="p">,</span>
    <span class="mf">0.48919672</span><span class="p">,</span> <span class="mf">0.28406399</span><span class="p">,</span> <span class="mf">0.20962799</span><span class="p">,</span> <span class="mf">0.88071757</span><span class="p">,</span> <span class="mf">0.45501821</span><span class="p">,</span>
    <span class="mf">0.60931183</span><span class="p">,</span> <span class="mf">0.46709718</span><span class="p">,</span> <span class="mf">0.14218838</span><span class="p">,</span> <span class="mf">0.42517758</span><span class="p">,</span> <span class="mf">0.9149958</span> <span class="p">,</span>
    <span class="mf">0.0843243</span> <span class="p">,</span> <span class="mf">0.27302307</span><span class="p">,</span> <span class="mf">0.75281922</span><span class="p">,</span> <span class="mf">0.3688931</span> <span class="p">,</span> <span class="mf">0.86913729</span><span class="p">,</span>
    <span class="mf">0.89774196</span><span class="p">,</span> <span class="mf">0.77838838</span><span class="p">]]]]</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[</span><span class="mf">0.20585343</span><span class="p">,</span> <span class="mf">0.470117</span>  <span class="p">,</span> <span class="mf">0.14553176</span><span class="p">,</span> <span class="mf">0.939156</span>  <span class="p">,</span> <span class="mf">0.5723428</span> <span class="p">,</span>
   <span class="mf">0.9163123</span> <span class="p">,</span> <span class="mf">0.32244256</span><span class="p">,</span> <span class="mf">0.94243354</span><span class="p">,</span> <span class="mf">0.8659563</span> <span class="p">,</span> <span class="mf">0.73916763</span><span class="p">,</span>
   <span class="mf">0.3589873</span> <span class="p">,</span> <span class="mf">0.65208274</span><span class="p">,</span> <span class="mf">0.07935983</span><span class="p">,</span> <span class="mf">0.89313424</span><span class="p">,</span> <span class="mf">0.6860127</span> <span class="p">,</span>
   <span class="mf">0.48919672</span><span class="p">,</span> <span class="mf">0.284064</span>  <span class="p">,</span> <span class="mf">0.20962799</span><span class="p">,</span> <span class="mf">0.8807176</span> <span class="p">,</span> <span class="mf">0.45501822</span><span class="p">,</span>
   <span class="mf">0.6093118</span> <span class="p">,</span> <span class="mf">0.46709716</span><span class="p">,</span> <span class="mf">0.14218839</span><span class="p">,</span> <span class="mf">0.42517757</span><span class="p">,</span> <span class="mf">0.9149958</span> <span class="p">,</span>
   <span class="mf">0.0843243</span> <span class="p">,</span> <span class="mf">0.27302307</span><span class="p">,</span> <span class="mf">0.75281924</span><span class="p">,</span> <span class="mf">0.36889312</span><span class="p">,</span> <span class="mf">0.8691373</span> <span class="p">,</span>
   <span class="mf">0.897742</span>  <span class="p">,</span> <span class="mf">0.7783884</span> <span class="p">]]]</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="binarythreshold">
<h3>7.8 BinaryThreshold<a class="headerlink" href="#binarythreshold" title="Permalink to this headline">¶</a></h3>
<p>Threshold the input.</p>
<p>If an input element is smaller than the threshold value, it will be replaced by 0; otherwise, it will be replaced by 1.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">BinaryThreshold</span><span class="o">(</span><span class="n">value</span> <span class="k">=</span> <span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">6</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">BinaryThreshold</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">value</span></code>: The threshold value to compare with. Default is 1e-6.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.BinaryThreshold</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">BinaryThreshold</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,1,.,.) =
-1.1907398      -0.18995096     -2.0344417      -1.3789974
-1.8801064      -0.74757665     -0.4339697      0.0058485097
0.7012256       -0.6363152      2.0156987       -0.5512639

(1,2,.,.) =
-0.5251603      0.082127444     0.29550993      1.6357868
-1.3828015      -0.11842779     0.3316966       -0.14360528
0.21216457      -0.117370956    -0.12934707     -0.35854268

(2,1,.,.) =
-0.9071151      -2.8566089      -0.4796377      -0.915065
-0.8439908      -0.25404388     -0.39926198     -0.15191565
-1.0496653      -0.403675       -1.3591816      0.5311797

(2,2,.,.) =
0.53509855      -0.08892822     1.2196561       -0.62759316
-0.47476718     -0.43337926     -0.10406987     1.4035174
-1.7120812      1.1328355       0.9219375       1.3813454

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,1,.,.) =
0.0     0.0     0.0     0.0
0.0     0.0     0.0     1.0
1.0     0.0     1.0     0.0

(1,2,.,.) =
0.0     1.0     1.0     1.0
0.0     0.0     1.0     0.0
1.0     0.0     0.0     0.0

(2,1,.,.) =
0.0     0.0     0.0     0.0
0.0     0.0     0.0     0.0
0.0     0.0     0.0     1.0

(2,2,.,.) =
1.0     0.0     1.0     0.0
0.0     0.0     0.0     1.0
0.0     1.0     1.0     1.0

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">BinaryThreshold</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[[</span><span class="mf">0.30421481</span><span class="p">,</span> <span class="mf">0.47800487</span><span class="p">,</span> <span class="mf">0.54249411</span><span class="p">,</span> <span class="mf">0.90109767</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.72650405</span><span class="p">,</span> <span class="mf">0.53096719</span><span class="p">,</span> <span class="mf">0.66346109</span><span class="p">,</span> <span class="mf">0.0589329</span> <span class="p">],</span>
         <span class="p">[</span><span class="mf">0.12994731</span><span class="p">,</span> <span class="mf">0.92181174</span><span class="p">,</span> <span class="mf">0.43129874</span><span class="p">,</span> <span class="mf">0.97306968</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mf">0.3031087</span> <span class="p">,</span> <span class="mf">0.20339982</span><span class="p">,</span> <span class="mf">0.69034712</span><span class="p">,</span> <span class="mf">0.40191</span>   <span class="p">],</span>
         <span class="p">[</span><span class="mf">0.57517034</span><span class="p">,</span> <span class="mf">0.30159448</span><span class="p">,</span> <span class="mf">0.4801747</span> <span class="p">,</span> <span class="mf">0.75175084</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.8599362</span> <span class="p">,</span> <span class="mf">0.93523811</span><span class="p">,</span> <span class="mf">0.34768628</span><span class="p">,</span> <span class="mf">0.10840162</span><span class="p">]]],</span>


       <span class="p">[[[</span><span class="mf">0.46102959</span><span class="p">,</span> <span class="mf">0.33029002</span><span class="p">,</span> <span class="mf">0.69340103</span><span class="p">,</span> <span class="mf">0.32885719</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.84405147</span><span class="p">,</span> <span class="mf">0.03421879</span><span class="p">,</span> <span class="mf">0.68242578</span><span class="p">,</span> <span class="mf">0.03560338</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.12244515</span><span class="p">,</span> <span class="mf">0.3610654</span> <span class="p">,</span> <span class="mf">0.01312785</span><span class="p">,</span> <span class="mf">0.84485178</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mf">0.73472287</span><span class="p">,</span> <span class="mf">0.75707757</span><span class="p">,</span> <span class="mf">0.77070527</span><span class="p">,</span> <span class="mf">0.40863145</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.01137898</span><span class="p">,</span> <span class="mf">0.82896826</span><span class="p">,</span> <span class="mf">0.1498069</span> <span class="p">,</span> <span class="mf">0.22309423</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.92737483</span><span class="p">,</span> <span class="mf">0.36217222</span><span class="p">,</span> <span class="mf">0.06679799</span><span class="p">,</span> <span class="mf">0.33304362</span><span class="p">]]]])</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]],</span>


       <span class="p">[[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="sqrt">
<h3>7.9 Sqrt<a class="headerlink" href="#sqrt" title="Permalink to this headline">¶</a></h3>
<p>Applies an element-wise square root operation to the input.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Sqrt</span><span class="o">(</span><span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Sqrt</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Sqrt</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Sqrt</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">3</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
0.6950394       0.5234307       1.7375475
0.25833175      0.02685826      -0.6046901
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
0.8336902       0.7234851       1.3181607
0.50826347      0.16388491      NaN
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Sqrt</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mf">0.2484558</span> <span class="p">,</span> <span class="mf">0.65280218</span><span class="p">,</span> <span class="mf">0.35286984</span><span class="p">],</span>
 <span class="p">[</span><span class="mf">0.19616094</span><span class="p">,</span> <span class="mf">0.30966802</span><span class="p">,</span> <span class="mf">0.82148169</span><span class="p">]]</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mf">0.4984534</span> <span class="p">,</span> <span class="mf">0.80796176</span><span class="p">,</span> <span class="mf">0.5940285</span> <span class="p">],</span>
 <span class="p">[</span><span class="mf">0.4429006</span> <span class="p">,</span> <span class="mf">0.55647826</span><span class="p">,</span> <span class="mf">0.9063563</span> <span class="p">]]</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="mul">
<h3>7.10 Mul<a class="headerlink" href="#mul" title="Permalink to this headline">¶</a></h3>
<p>Multiply a single scalar factor to the incoming data</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Mul</span><span class="o">(</span><span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Mul</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: String to set the name of the layer. If not specified, its name will by default to be a generated string.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Mul</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Mul</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,.,.) =
-1.2316265  -2.008802 -1.3908259  -0.61135375
-0.48992255 0.1786112 0.18872596  0.49621895
-0.6931602  -0.919745 -0.09019699 -0.41218707

(2,.,.) =
-0.3135355  -0.4385771  -0.3317269  1.0412029
-0.8859662  0.17758773  -0.73779273 -0.4445366
0.3921595 1.6923207 0.014470488 0.4044164

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
-0.59036994 -0.9629025  -0.6666808  -0.29304734
-0.2348403  0.0856158 0.09046422  0.23785843
-0.33226058 -0.44087213 -0.043235175  -0.19757845

(2,.,.) =
-0.15029064 -0.21022828 -0.15901053 0.49909195
-0.42468053 0.0851252 -0.3536548  -0.21308492
0.18797839  0.81119984  0.006936308 0.19385365

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Mul</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[</span> <span class="mf">0.22607292</span><span class="p">,</span>  <span class="mf">0.59806062</span><span class="p">,</span>  <span class="mf">0.19428923</span><span class="p">,</span>  <span class="mf">0.22928606</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.13804536</span><span class="p">,</span>  <span class="mf">0.1615547</span> <span class="p">,</span>  <span class="mf">0.52824658</span><span class="p">,</span>  <span class="mf">0.52794904</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.4049169</span> <span class="p">,</span>  <span class="mf">0.94109084</span><span class="p">,</span>  <span class="mf">0.58158453</span><span class="p">,</span>  <span class="mf">0.78368633</span><span class="p">]],</span>

       <span class="p">[[</span> <span class="mf">0.86233305</span><span class="p">,</span>  <span class="mf">0.47995805</span><span class="p">,</span>  <span class="mf">0.80430949</span><span class="p">,</span>  <span class="mf">0.9931171</span> <span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.35179631</span><span class="p">,</span>  <span class="mf">0.33615276</span><span class="p">,</span>  <span class="mf">0.87756877</span><span class="p">,</span>  <span class="mf">0.73560288</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.29775703</span><span class="p">,</span>  <span class="mf">0.11404466</span><span class="p">,</span>  <span class="mf">0.77695536</span><span class="p">,</span>  <span class="mf">0.97580018</span><span class="p">]]])</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.22486402</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.59486258</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1932503</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.22805998</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.13730718</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1606908</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.52542186</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.52512592</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.40275168</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.93605846</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.57847458</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.77949566</span><span class="p">]],</span>

       <span class="p">[[</span><span class="o">-</span><span class="mf">0.85772187</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.47739154</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.80000854</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9878065</span> <span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.34991512</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.33435524</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.87287611</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.73166931</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.29616481</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.11343482</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.77280068</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.97058219</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="mulconstant">
<h3>7.11 MulConstant<a class="headerlink" href="#mulconstant" title="Permalink to this headline">¶</a></h3>
<p>Multiply the input by a (non-learnable) scalar constant.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">MulConstant</span><span class="o">(</span><span class="n">constant</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">MulConstant</span><span class="p">(</span><span class="n">constant</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">constant</span></code>: The scalar constant to be multiplied.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.MulConstant</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">MulConstant</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mf">2.2</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,.,.) =
-0.16873977     1.0812985       1.0942211       -0.67091423
1.0086882       0.5915831       0.26184535      -1.361431
1.5616825       -0.037591368    1.2794676       1.0692137

(2,.,.) =
0.29868057      -0.23266982     -0.7679556      -2.209848
-0.13954644     -0.1368473      -0.54510623     1.8397199
-0.58691734     -0.56410027     -1.5567777      0.050648995

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
-0.3712275      2.3788567       2.4072864       -1.4760114
2.219114        1.3014828       0.57605976      -2.9951482
3.4357016       -0.08270101     2.8148286       2.3522704

(2,.,.) =
0.6570973       -0.5118736      -1.6895024      -4.8616657
-0.3070022      -0.30106407     -1.1992338      4.047384
-1.2912182      -1.2410206      -3.424911       0.11142779

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MulConstant</span><span class="p">(</span><span class="mf">2.2</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[</span><span class="mf">0.39874191</span><span class="p">,</span> <span class="mf">0.66634984</span><span class="p">,</span> <span class="mf">0.23907766</span><span class="p">,</span> <span class="mf">0.31587494</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.78842014</span><span class="p">,</span> <span class="mf">0.93057835</span><span class="p">,</span> <span class="mf">0.80739529</span><span class="p">,</span> <span class="mf">0.71541279</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.2231424</span> <span class="p">,</span> <span class="mf">0.3372844</span> <span class="p">,</span> <span class="mf">0.94678072</span><span class="p">,</span> <span class="mf">0.52928034</span><span class="p">]],</span>

 <span class="p">[[</span><span class="mf">0.60142458</span><span class="p">,</span> <span class="mf">0.41221671</span><span class="p">,</span> <span class="mf">0.00890549</span><span class="p">,</span> <span class="mf">0.32069845</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.51122554</span><span class="p">,</span> <span class="mf">0.76280426</span><span class="p">,</span> <span class="mf">0.87579418</span><span class="p">,</span> <span class="mf">0.17182832</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.54133184</span><span class="p">,</span> <span class="mf">0.19814384</span><span class="p">,</span> <span class="mf">0.92529327</span><span class="p">,</span> <span class="mf">0.5616615</span> <span class="p">]]]</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[</span><span class="mf">0.8772322</span> <span class="p">,</span> <span class="mf">1.4659697</span> <span class="p">,</span> <span class="mf">0.5259709</span> <span class="p">,</span> <span class="mf">0.6949249</span> <span class="p">],</span>
  <span class="p">[</span><span class="mf">1.7345244</span> <span class="p">,</span> <span class="mf">2.0472724</span> <span class="p">,</span> <span class="mf">1.7762697</span> <span class="p">,</span> <span class="mf">1.5739082</span> <span class="p">],</span>
  <span class="p">[</span><span class="mf">0.4909133</span> <span class="p">,</span> <span class="mf">0.7420257</span> <span class="p">,</span> <span class="mf">2.0829177</span> <span class="p">,</span> <span class="mf">1.1644168</span> <span class="p">]],</span>

 <span class="p">[[</span><span class="mf">1.3231341</span> <span class="p">,</span> <span class="mf">0.9068768</span> <span class="p">,</span> <span class="mf">0.01959208</span><span class="p">,</span> <span class="mf">0.7055366</span> <span class="p">],</span>
  <span class="p">[</span><span class="mf">1.1246961</span> <span class="p">,</span> <span class="mf">1.6781695</span> <span class="p">,</span> <span class="mf">1.9267472</span> <span class="p">,</span> <span class="mf">0.37802234</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">1.19093</span>   <span class="p">,</span> <span class="mf">0.43591645</span><span class="p">,</span> <span class="mf">2.0356452</span> <span class="p">,</span> <span class="mf">1.2356553</span> <span class="p">]]]</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="scale">
<h3>7.12 Scale<a class="headerlink" href="#scale" title="Permalink to this headline">¶</a></h3>
<p>Scale is the combination of CMul and CAdd.</p>
<p>Computes the element-wise product of the input and weight, with the shape of the weight “expand” to match the shape of the input.</p>
<p>Similarly, perform an expanded bias and perform an element-wise add.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Scale</span><span class="o">(</span><span class="n">size</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Scale</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">size</span></code>: Size of the weight and bias.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Scale</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="k">var</span> <span class="n">array</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Scale</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">array</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">3</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
-0.006399727    -0.06412822     -0.2334789
0.31029955      1.6557469       1.9614618
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
0.09936619      0.57585865      0.20324506
0.38537437      -0.8598822      -1.0186496
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">Scale</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Scale</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mf">0.7242994</span> <span class="p">,</span> <span class="mf">0.77888884</span><span class="p">,</span> <span class="mf">0.71470432</span><span class="p">],</span>
 <span class="p">[</span><span class="mf">0.03058471</span><span class="p">,</span> <span class="mf">0.00602764</span><span class="p">,</span> <span class="mf">0.57513629</span><span class="p">]]</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span><span class="mf">1.0946966</span> <span class="p">,</span> <span class="mf">1.1255064</span> <span class="p">,</span> <span class="mf">1.0892813</span> <span class="p">],</span>
 <span class="p">[</span><span class="mf">0.58151895</span><span class="p">,</span> <span class="mf">0.5909191</span> <span class="p">,</span> <span class="mf">0.37307182</span><span class="p">]]</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="log">
<h3>7.13 Log<a class="headerlink" href="#log" title="Permalink to this headline">¶</a></h3>
<p>Applies a log transformation to the input.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Log</span><span class="o">(</span><span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Log</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Log</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Log</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">4</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,1,.,.) =
0.38405678      -0.5502389      -0.383079       -0.988537
-0.6294056      -0.7838047      0.8747865       -1.0659786
-2.2445498      -0.5488076      -0.42898977     0.6916364
1.6542299       -0.9966279      -0.38244298     1.6954672

(1,2,.,.) =
0.43478605      -0.6678534      1.9530942       -0.5209587
0.12899925      0.20572199      2.0359943       0.55223215
0.65247816      0.8792108       -0.38860792     0.48663738
-1.0084358      0.31141177      0.69208467      0.48385203

[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,1,.,.) =
-0.95696485     NaN     NaN     NaN
NaN     NaN     -0.13377543     NaN
NaN     NaN     NaN     -0.36869493
0.5033356       NaN     NaN     0.5279584

(1,2,.,.) =
-0.83290124     NaN     0.6694149       NaN
-2.0479486      -1.5812296      0.7109843       -0.5937868
-0.4269776      -0.12873057     NaN     -0.720236
NaN     -1.1666392      -0.36804697     -0.72597617

[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">Log</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Log</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[[</span><span class="mf">0.90127539</span><span class="p">,</span> <span class="mf">0.9861594</span> <span class="p">,</span> <span class="mf">0.04722941</span><span class="p">,</span> <span class="mf">0.63719453</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.46529477</span><span class="p">,</span> <span class="mf">0.81511804</span><span class="p">,</span> <span class="mf">0.24435558</span><span class="p">,</span> <span class="mf">0.45003562</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.15170845</span><span class="p">,</span> <span class="mf">0.35157662</span><span class="p">,</span> <span class="mf">0.0925214</span> <span class="p">,</span> <span class="mf">0.63852947</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.27817508</span><span class="p">,</span> <span class="mf">0.42572846</span><span class="p">,</span> <span class="mf">0.44363004</span><span class="p">,</span> <span class="mf">0.03536394</span><span class="p">]],</span>

  <span class="p">[[</span><span class="mf">0.65027784</span><span class="p">,</span> <span class="mf">0.00429838</span><span class="p">,</span> <span class="mf">0.07434429</span><span class="p">,</span> <span class="mf">0.18653305</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.19659183</span><span class="p">,</span> <span class="mf">0.66647529</span><span class="p">,</span> <span class="mf">0.77821197</span><span class="p">,</span> <span class="mf">0.65894478</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.28212032</span><span class="p">,</span> <span class="mf">0.52307663</span><span class="p">,</span> <span class="mf">0.09589939</span><span class="p">,</span> <span class="mf">0.71547588</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.84344158</span><span class="p">,</span> <span class="mf">0.25291738</span><span class="p">,</span> <span class="mf">0.52145649</span><span class="p">,</span> <span class="mf">0.82982377</span><span class="p">]]]]</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[[</span><span class="o">-</span><span class="mf">0.10394441</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.01393729</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.0527387</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.45068032</span><span class="p">],</span>
   <span class="p">[</span><span class="o">-</span><span class="mf">0.76508415</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.20442237</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4091308</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.79842854</span><span class="p">],</span>
   <span class="p">[</span><span class="o">-</span><span class="mf">1.8857948</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.0453277</span> <span class="p">,</span> <span class="o">-</span><span class="mf">2.3803153</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.44858742</span><span class="p">],</span>
   <span class="p">[</span><span class="o">-</span><span class="mf">1.2795045</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.85395354</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.8127643</span> <span class="p">,</span> <span class="o">-</span><span class="mf">3.3420627</span> <span class="p">]],</span>

  <span class="p">[[</span><span class="o">-</span><span class="mf">0.43035555</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.4495163</span> <span class="p">,</span> <span class="o">-</span><span class="mf">2.5990484</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.6791469</span> <span class="p">],</span>
   <span class="p">[</span><span class="o">-</span><span class="mf">1.6266255</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.4057522</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.25075635</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.41711554</span><span class="p">],</span>
   <span class="p">[</span><span class="o">-</span><span class="mf">1.2654216</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.64802724</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.3444557</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.33480743</span><span class="p">],</span>
   <span class="p">[</span><span class="o">-</span><span class="mf">0.1702646</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.3746924</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.6511295</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.1865419</span> <span class="p">]]]]</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="identity">
<h3>7.14 Identity<a class="headerlink" href="#identity" title="Permalink to this headline">¶</a></h3>
<p>Identity just return the input to output.</p>
<p>It’s useful in same parallel container to get an origin input.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Identity</span><span class="o">(</span><span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Identity</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Identity</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Identity</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">4</span><span class="o">,</span> <span class="mi">4</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,.,.) =
1.9601166       -0.86010313     0.0023731247    -0.81219757
1.1469674       -1.5375912      -1.5348053      -0.34829113
-1.236773       -0.7183283      -0.89256984     0.8605067
0.7937664       0.52992857      -1.6157389      0.36134166

(2,.,.) =
-0.44434744     -0.23848957     -0.01632014     -0.58109635
-0.19856784     -2.3421717      -0.5868049      -0.76775354
0.80254126      1.78778 -1.1835604      1.4489703
0.8731402       0.8906672       0.2800079       -0.6715317

(3,.,.) =
1.4093032       2.358169        -1.4620789      1.1904576
-0.18263042     -0.31869793     2.01061 1.2159953
-0.5801479      1.2949371       -0.7510707      -1.0707517
0.30815956      -1.161963       -0.26964024     -0.4759499

[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x4]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
1.9601166       -0.86010313     0.0023731247    -0.81219757
1.1469674       -1.5375912      -1.5348053      -0.34829113
-1.236773       -0.7183283      -0.89256984     0.8605067
0.7937664       0.52992857      -1.6157389      0.36134166

(2,.,.) =
-0.44434744     -0.23848957     -0.01632014     -0.58109635
-0.19856784     -2.3421717      -0.5868049      -0.76775354
0.80254126      1.78778 -1.1835604      1.4489703
0.8731402       0.8906672       0.2800079       -0.6715317

(3,.,.) =
1.4093032       2.358169        -1.4620789      1.1904576
-0.18263042     -0.31869793     2.01061 1.2159953
-0.5801479      1.2949371       -0.7510707      -1.0707517
0.30815956      -1.161963       -0.26964024     -0.4759499

[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x4]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">Identity</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Identity</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[</span><span class="mf">0.36751123</span><span class="p">,</span> <span class="mf">0.92287101</span><span class="p">,</span> <span class="mf">0.73894405</span><span class="p">,</span> <span class="mf">0.33699379</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.69405782</span><span class="p">,</span> <span class="mf">0.9653215</span> <span class="p">,</span> <span class="mf">0.2617223</span> <span class="p">,</span> <span class="mf">0.68205229</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.71455325</span><span class="p">,</span> <span class="mf">0.99419333</span><span class="p">,</span> <span class="mf">0.90886495</span><span class="p">,</span> <span class="mf">0.10232991</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.1644055</span> <span class="p">,</span> <span class="mf">0.30013138</span><span class="p">,</span> <span class="mf">0.98921154</span><span class="p">,</span> <span class="mf">0.26803146</span><span class="p">]],</span>

  <span class="p">[[</span><span class="mf">0.35898357</span><span class="p">,</span> <span class="mf">0.72067882</span><span class="p">,</span> <span class="mf">0.13236563</span><span class="p">,</span> <span class="mf">0.71935521</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.30865626</span><span class="p">,</span> <span class="mf">0.71098844</span><span class="p">,</span> <span class="mf">0.86718946</span><span class="p">,</span> <span class="mf">0.12531168</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.84916882</span><span class="p">,</span> <span class="mf">0.84221518</span><span class="p">,</span> <span class="mf">0.52186664</span><span class="p">,</span> <span class="mf">0.87239729</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.50637899</span><span class="p">,</span> <span class="mf">0.10890469</span><span class="p">,</span> <span class="mf">0.86832705</span><span class="p">,</span> <span class="mf">0.93581179</span><span class="p">]],</span>

  <span class="p">[[</span><span class="mf">0.19640105</span><span class="p">,</span> <span class="mf">0.09341008</span><span class="p">,</span> <span class="mf">0.12043328</span><span class="p">,</span> <span class="mf">0.09261859</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.66019486</span><span class="p">,</span> <span class="mf">0.07251262</span><span class="p">,</span> <span class="mf">0.80929761</span><span class="p">,</span> <span class="mf">0.39094486</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.63027391</span><span class="p">,</span> <span class="mf">0.39537796</span><span class="p">,</span> <span class="mf">0.55578905</span><span class="p">,</span> <span class="mf">0.53933265</span><span class="p">],</span>
   <span class="p">[</span><span class="mf">0.13885559</span><span class="p">,</span> <span class="mf">0.56695373</span><span class="p">,</span> <span class="mf">0.17036027</span><span class="p">,</span> <span class="mf">0.4577097</span> <span class="p">]]]</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[</span><span class="mf">0.36751124</span><span class="p">,</span> <span class="mf">0.922871</span>  <span class="p">,</span> <span class="mf">0.73894405</span><span class="p">,</span> <span class="mf">0.33699378</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.6940578</span> <span class="p">,</span> <span class="mf">0.9653215</span> <span class="p">,</span> <span class="mf">0.2617223</span> <span class="p">,</span> <span class="mf">0.6820523</span> <span class="p">],</span>
  <span class="p">[</span><span class="mf">0.71455324</span><span class="p">,</span> <span class="mf">0.9941933</span> <span class="p">,</span> <span class="mf">0.908865</span>  <span class="p">,</span> <span class="mf">0.10232991</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.1644055</span> <span class="p">,</span> <span class="mf">0.30013138</span><span class="p">,</span> <span class="mf">0.98921156</span><span class="p">,</span> <span class="mf">0.26803148</span><span class="p">]],</span>

 <span class="p">[[</span><span class="mf">0.35898358</span><span class="p">,</span> <span class="mf">0.7206788</span> <span class="p">,</span> <span class="mf">0.13236563</span><span class="p">,</span> <span class="mf">0.7193552</span> <span class="p">],</span>
  <span class="p">[</span><span class="mf">0.30865628</span><span class="p">,</span> <span class="mf">0.71098846</span><span class="p">,</span> <span class="mf">0.86718947</span><span class="p">,</span> <span class="mf">0.12531169</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.84916884</span><span class="p">,</span> <span class="mf">0.8422152</span> <span class="p">,</span> <span class="mf">0.5218666</span> <span class="p">,</span> <span class="mf">0.8723973</span> <span class="p">],</span>
  <span class="p">[</span><span class="mf">0.506379</span>  <span class="p">,</span> <span class="mf">0.10890469</span><span class="p">,</span> <span class="mf">0.868327</span>  <span class="p">,</span> <span class="mf">0.9358118</span> <span class="p">]],</span>

 <span class="p">[[</span><span class="mf">0.19640104</span><span class="p">,</span> <span class="mf">0.09341008</span><span class="p">,</span> <span class="mf">0.12043328</span><span class="p">,</span> <span class="mf">0.09261858</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.6601949</span> <span class="p">,</span> <span class="mf">0.07251262</span><span class="p">,</span> <span class="mf">0.8092976</span> <span class="p">,</span> <span class="mf">0.39094487</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.63027394</span><span class="p">,</span> <span class="mf">0.39537796</span><span class="p">,</span> <span class="mf">0.55578905</span><span class="p">,</span> <span class="mf">0.5393326</span> <span class="p">],</span>
  <span class="p">[</span><span class="mf">0.13885559</span><span class="p">,</span> <span class="mf">0.5669537</span> <span class="p">,</span> <span class="mf">0.17036027</span><span class="p">,</span> <span class="mf">0.4577097</span> <span class="p">]]]</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="select">
<h3>7.15 Select<a class="headerlink" href="#select" title="Permalink to this headline">¶</a></h3>
<p>Select an index of the input in the given dim and return the subset part.</p>
<p>The batch dimension needs to be unchanged.</p>
<p>For example, if input is:</p>
<p>[[1, 2, 3],
[4, 5, 6]]</p>
<p>Select(1, 1) will give output [2 5]</p>
<p>Select(1, -1) will give output [3 6]</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Select</span><span class="o">(</span><span class="n">dim</span><span class="o">,</span> <span class="n">index</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Select</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dim</span></code>: The dimension to select. 0-based index. Cannot select the batch dimension. -1 means the last dimension of the input.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">index</span></code>: The index of the dimension to be selected. 0-based index. -1 means the last dimension of the input.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Select</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Select</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">3</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">1</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,1,.,.) =
-0.67646945     -0.5485965      -0.11103154
(1,2,.,.) =
-0.13488655     0.43843046      -0.04482145
(1,3,.,.) =
-0.18094881     0.19431554      -1.7624844
[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x1x3]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
-0.18094881     0.19431554      -1.7624844
[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">Select</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Select</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[[</span><span class="mf">0.53306099</span><span class="p">,</span> <span class="mf">0.95147881</span><span class="p">,</span> <span class="mf">0.15222129</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mf">0.89604861</span><span class="p">,</span> <span class="mf">0.90160974</span><span class="p">,</span> <span class="mf">0.5230576</span> <span class="p">]],</span>
        <span class="p">[[</span><span class="mf">0.70779386</span><span class="p">,</span> <span class="mf">0.14438568</span><span class="p">,</span> <span class="mf">0.37601195</span><span class="p">]]]])</span>
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[</span><span class="mf">0.7077939</span> <span class="p">,</span> <span class="mf">0.14438568</span><span class="p">,</span> <span class="mf">0.37601194</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="dense">
<h3>7.16 Dense<a class="headerlink" href="#dense" title="Permalink to this headline">¶</a></h3>
<p>A densely-connected NN layer.</p>
<p>The most common input is 2D.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Dense</span><span class="o">(</span><span class="n">outputDim</span><span class="o">,</span> <span class="n">init</span> <span class="k">=</span> <span class="s">&quot;glorot_uniform&quot;</span><span class="o">,</span> <span class="n">activation</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">wRegularizer</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">bRegularizer</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">bias</span> <span class="k">=</span> <span class="kc">true</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Dense</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;glorot_uniform&quot;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">W_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">outputDim</span></code>: The size of the output dimension.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">init</span></code>: Initialization method for the weights of the layer. Default is Xavier.You can also pass in corresponding string representations such as ‘glorot_uniform’ or ‘normal’, etc. for simple init methods in the factory method.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">activation</span></code>: Activation function to use. Default is null.You can also pass in corresponding string representations such as ‘relu’or ‘sigmoid’, etc. for simple activations in the factory method.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">wRegularizer</span></code>: An instance of <a class="reference external" href="https://bigdl-project.github.io/master/#APIGuide/Regularizers/">Regularizer</a>, applied to the input weights matrices. Default is null.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bRegularizer</span></code>: An instance of <a class="reference external" href="https://bigdl-project.github.io/master/#APIGuide/Regularizers/">Regularizer</a>, applied to the bias. Default is null.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bias</span></code>: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Dense</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Dense</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">5</span><span class="o">,</span> <span class="n">activation</span> <span class="k">=</span> <span class="s">&quot;relu&quot;</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">4</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
1.4289935       -1.7659454      -0.08306135     -1.0153456
1.0191492       0.37392816      1.3076705       -0.19495767
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
0.5421522       0.49008092      0.0     0.0     0.0
0.07940009      0.0     0.12953377      0.0     0.0
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span><span class="mf">0.64593485</span><span class="p">,</span> <span class="mf">0.67393322</span><span class="p">,</span> <span class="mf">0.72505368</span><span class="p">,</span> <span class="mf">0.04654095</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.19430753</span><span class="p">,</span> <span class="mf">0.47800889</span><span class="p">,</span> <span class="mf">0.00743648</span><span class="p">,</span> <span class="mf">0.6412403</span> <span class="p">]])</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">1.2698183</span> <span class="p">,</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.10656227</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.6236721</span> <span class="p">,</span> <span class="mf">0.00299606</span><span class="p">,</span> <span class="mf">0.29664695</span><span class="p">]],</span>
      <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="negative">
<h3>7.17 Negative<a class="headerlink" href="#negative" title="Permalink to this headline">¶</a></h3>
<p>Computes the negative value of each element of the input.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Negative</span><span class="o">(</span><span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Negative</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Negative</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Negative</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,.,.) =
1.031705        -0.5723963      1.998631
-0.32908052     2.4069138       -2.4111257
(2,.,.) =
0.5355049       -1.4404331      -0.38116863
-0.45641592     -1.1485358      0.94766915
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
-1.031705       0.5723963       -1.998631
0.32908052      -2.4069138      2.4111257
(2,.,.) =
-0.5355049      1.4404331       0.38116863
0.45641592      1.1485358       -0.94766915
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">Negative</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Negative</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[</span><span class="mf">0.39261261</span><span class="p">,</span> <span class="mf">0.03164615</span><span class="p">,</span> <span class="mf">0.32179116</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.11969367</span><span class="p">,</span> <span class="mf">0.61610712</span><span class="p">,</span> <span class="mf">0.42573733</span><span class="p">]],</span>
       <span class="p">[[</span><span class="mf">0.36794656</span><span class="p">,</span> <span class="mf">0.90912174</span><span class="p">,</span> <span class="mf">0.540356</span>  <span class="p">],</span>
        <span class="p">[</span><span class="mf">0.42667627</span><span class="p">,</span> <span class="mf">0.04154093</span><span class="p">,</span> <span class="mf">0.84692964</span><span class="p">]]])</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.3926126</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.03164615</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.32179114</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.11969367</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6161071</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.42573732</span><span class="p">]],</span>
       <span class="p">[[</span><span class="o">-</span><span class="mf">0.36794657</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.90912175</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.540356</span>  <span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.42667627</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.04154094</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.84692967</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="cadd">
<h3>7.18 CAdd<a class="headerlink" href="#cadd" title="Permalink to this headline">¶</a></h3>
<p>This layer has a bias with given size.</p>
<p>The bias will be added element-wise to the input.</p>
<p>If the element number of the bias matches the input, a simple element-wise addition will be done.</p>
<p>Or the bias will be expanded to the same size of the input.</p>
<p>The expand means repeat on unmatched singleton dimension (if some unmatched dimension isn’t a singleton dimension, an error will be raised).</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">CAdd</span><span class="o">(</span><span class="n">size</span><span class="o">,</span> <span class="n">bRegularizer</span> <span class="k">=</span> <span class="kc">null</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">CAdd</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">size</span></code>: the size of the bias</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bRegularizer</span></code>: An instance of <a class="reference external" href="https://bigdl-project.github.io/master/#APIGuide/Regularizers/">Regularizer</a>, applied to the bias. Default is null.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.CAdd</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">CAdd</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="nc">Array</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">),</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">rand</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,.,.) =
0.2183351       0.32434112      0.89350265
0.3348259       0.78677046      0.24054797
(2,.,.) =
0.9945844       0.72363794      0.7737936
0.05522544      0.3517818       0.7417069
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
0.1358028       0.6956667       1.0837181
0.6767027       0.7955346       0.5063505
(2,.,.) =
0.9120521       1.0949634       0.96400905
0.3971022       0.36054593      1.0075095
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">CAdd</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">CAdd</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[</span><span class="mf">0.4122004</span> <span class="p">,</span> <span class="mf">0.73289359</span><span class="p">,</span> <span class="mf">0.11500016</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.26974491</span><span class="p">,</span> <span class="mf">0.32166632</span><span class="p">,</span> <span class="mf">0.91408442</span><span class="p">]],</span>
       <span class="p">[[</span><span class="mf">0.66824327</span><span class="p">,</span> <span class="mf">0.80271314</span><span class="p">,</span> <span class="mf">0.75981145</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.39271431</span><span class="p">,</span> <span class="mf">0.07312566</span><span class="p">,</span> <span class="mf">0.4966805</span> <span class="p">]]])</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[</span> <span class="mf">0.06560206</span><span class="p">,</span>  <span class="mf">0.38629526</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.23159817</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.44287407</span><span class="p">,</span>  <span class="mf">0.4947955</span> <span class="p">,</span>  <span class="mf">1.0872136</span> <span class="p">]],</span>
       <span class="p">[[</span> <span class="mf">0.32164496</span><span class="p">,</span>  <span class="mf">0.45611483</span><span class="p">,</span>  <span class="mf">0.41321313</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.56584346</span><span class="p">,</span>  <span class="mf">0.24625483</span><span class="p">,</span>  <span class="mf">0.6698097</span> <span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="repeatvector">
<h3>7.19 RepeatVector<a class="headerlink" href="#repeatvector" title="Permalink to this headline">¶</a></h3>
<p>Repeats the input n times.</p>
<p>The input of this layer should be 2D, i.e. (num_samples, features).
The output of thi layer should be 3D, i.e. (num_samples, n, features).</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">RepeatVector</span><span class="o">(</span><span class="n">n</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">RepeatVector</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n</span></code>: Repetition factor. Integer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: String to set the name of the layer. If not specified, its name will by default to be a generated string.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.RepeatVector</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">RepeatVector</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">4</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">3</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
-0.31839952 -0.3495366  0.542486
-0.54981124 -0.8428188  0.8225184
[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
-0.31839952 -0.3495366  0.542486
-0.31839952 -0.3495366  0.542486
-0.31839952 -0.3495366  0.542486
-0.31839952 -0.3495366  0.542486

(2,.,.) =
-0.54981124 -0.8428188  0.8225184
-0.54981124 -0.8428188  0.8225184
-0.54981124 -0.8428188  0.8225184
-0.54981124 -0.8428188  0.8225184

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x3]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">RepeatVector</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">RepeatVector</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span> <span class="mf">0.90715922</span><span class="p">,</span>  <span class="mf">0.54594769</span><span class="p">,</span>  <span class="mf">0.53952404</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">0.08989831</span><span class="p">,</span>  <span class="mf">0.07265549</span><span class="p">,</span>  <span class="mf">0.45830114</span><span class="p">]])</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[</span> <span class="mf">0.90715921</span><span class="p">,</span>  <span class="mf">0.54594767</span><span class="p">,</span>  <span class="mf">0.53952402</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.90715921</span><span class="p">,</span>  <span class="mf">0.54594767</span><span class="p">,</span>  <span class="mf">0.53952402</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.90715921</span><span class="p">,</span>  <span class="mf">0.54594767</span><span class="p">,</span>  <span class="mf">0.53952402</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.90715921</span><span class="p">,</span>  <span class="mf">0.54594767</span><span class="p">,</span>  <span class="mf">0.53952402</span><span class="p">]],</span>

       <span class="p">[[</span> <span class="mf">0.08989831</span><span class="p">,</span>  <span class="mf">0.07265549</span><span class="p">,</span>  <span class="mf">0.45830116</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.08989831</span><span class="p">,</span>  <span class="mf">0.07265549</span><span class="p">,</span>  <span class="mf">0.45830116</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.08989831</span><span class="p">,</span>  <span class="mf">0.07265549</span><span class="p">,</span>  <span class="mf">0.45830116</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.08989831</span><span class="p">,</span>  <span class="mf">0.07265549</span><span class="p">,</span>  <span class="mf">0.45830116</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="gaussiansampler">
<h3>7.20 GaussianSampler<a class="headerlink" href="#gaussiansampler" title="Permalink to this headline">¶</a></h3>
<p>Takes {mean, log_variance} as input and samples from the Gaussian distribution.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">GaussianSampler</span><span class="o">(</span><span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">GaussianSampler</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">MultiShape</span></code></a> object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.GaussianSampler</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.utils.</span><span class="o">{</span><span class="nc">Shape</span><span class="o">,</span> <span class="nc">MultiShape</span><span class="o">,</span> <span class="n">T</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="k">val</span> <span class="n">shape1</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">)</span>
<span class="k">val</span> <span class="n">shape2</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">GaussianSampler</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">inputShape</span> <span class="k">=</span> <span class="nc">MultiShape</span><span class="o">(</span><span class="nc">List</span><span class="o">(</span><span class="n">shape1</span><span class="o">,</span><span class="n">shape2</span><span class="o">))))</span>
<span class="k">val</span> <span class="n">input1</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">rand</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span>
<span class="k">val</span> <span class="n">input2</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">rand</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="n">T</span><span class="o">(</span><span class="mi">1</span> <span class="o">-&gt;</span> <span class="n">input1</span><span class="o">,</span> <span class="mi">2</span> <span class="o">-&gt;</span> <span class="n">input2</span><span class="o">)</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.utils.Table =
 {
        2: (1,.,.) =
           0.9996127    0.8964211       0.7424038
           0.40628982   0.37035564      0.20108517

           (2,.,.) =
           0.6974727    0.60202897      0.1535999
           0.012422224  0.5993025       0.96206

           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]
        1: (1,.,.) =
           0.21060324   0.576583        0.21633287
           0.1484059    0.2730577       0.25317845

           (2,.,.) =
           0.58513683   0.58095694      0.18811373
           0.7029449    0.41235915      0.44636542

           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]
 }
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
1.5258198       1.9536011       -1.8591263
-1.0618867      -0.751225       0.35412917

(2,.,.) =
1.3334517       -0.60312974     0.7324476
0.09502721      0.8094909       0.44807082

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">GaussianSampler</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">GaussianSampler</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[(</span><span class="mi">3</span><span class="p">,),(</span><span class="mi">3</span><span class="p">,)]))</span>
<span class="n">input1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">input2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="nb">input</span> <span class="o">=</span> <span class="p">[</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">]</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[</span><span class="mf">0.79941342</span><span class="p">,</span> <span class="mf">0.87462822</span><span class="p">,</span> <span class="mf">0.9516901</span> <span class="p">],</span>
  <span class="p">[</span><span class="mf">0.20111287</span><span class="p">,</span> <span class="mf">0.54634077</span><span class="p">,</span> <span class="mf">0.83614511</span><span class="p">]],</span> 
  
 <span class="p">[[</span><span class="mf">0.31886989</span><span class="p">,</span> <span class="mf">0.22829382</span><span class="p">,</span> <span class="mf">0.84355419</span><span class="p">],</span>
  <span class="p">[</span><span class="mf">0.51186641</span><span class="p">,</span> <span class="mf">0.28043938</span><span class="p">,</span> <span class="mf">0.29440057</span><span class="p">]]]</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span> <span class="mf">0.71405387</span>  <span class="mf">2.2944303</span>  <span class="o">-</span><span class="mf">0.41778684</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">0.84234</span>     <span class="mf">2.3337283</span>  <span class="o">-</span><span class="mf">0.18952972</span><span class="p">]]</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="exp">
<h3>7.21 Exp<a class="headerlink" href="#exp" title="Permalink to this headline">¶</a></h3>
<p>Applies element-wise exp to the input.</p>
<p>When you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension).</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Exp</span><span class="o">(</span><span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Exp</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">MultiShape</span></code></a> object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Exp</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Exp</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,1,.,.) =
-1.5841372      -0.13795324     -2.144475       0.09272669
1.055668        -1.2310301      1.2145554       -0.6073714
0.9296467       0.2923885       1.3364213       0.1652137

(1,2,.,.) =
0.2099718       -0.3856573      -0.92586        -0.5317779
0.6618383       -0.9677452      -1.5014665      -0.35464883
2.045924        -0.317644       -1.812726       0.95438373

(2,1,.,.) =
-0.4536791      -0.34785584     1.6424289       -0.07981159
-0.8022624      -0.4211059      0.3461831       1.9598864
-0.84695745     -0.6115283      0.7729755       2.3077402

(2,2,.,.) =
-0.08438411     -0.908458       0.6688936       -0.7292123
-0.26337254     0.55425745      -0.14925817     -0.010179609
-0.62562865     -1.0517743      -0.23839666     -1.144982

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,1,.,.) =
0.20512469      0.8711394       0.11712951      1.0971619
2.8738942       0.29199165      3.3687959       0.544781
2.533614        1.3396233       3.8054006       1.1796452

(1,2,.,.) =
1.2336433       0.6800035       0.39619055      0.5875594
1.9383523       0.37993878      0.22280318      0.7014197
7.7363033       0.7278619       0.16320862      2.5970695

(2,1,.,.) =
0.63528657      0.70620066      5.167706        0.92329025
0.44831353      0.6563206       1.4136615       7.0985208
0.42871734      0.5425211       2.1662023       10.051684

(2,2,.,.) =
0.9190782       0.4031454       1.9520763       0.48228875
0.76845556      1.740648        0.8613467       0.98987204
0.53492504      0.34931743      0.7878901       0.31822965

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">Exp</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Exp</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[[</span><span class="mf">0.93104587</span> <span class="mf">0.94000338</span> <span class="mf">0.84870765</span> <span class="mf">0.98645553</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.83708846</span> <span class="mf">0.33375541</span> <span class="mf">0.50119834</span> <span class="mf">0.24879265</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.51966475</span> <span class="mf">0.84514791</span> <span class="mf">0.15496452</span> <span class="mf">0.61538968</span><span class="p">]]</span>

  <span class="p">[[</span><span class="mf">0.57250337</span> <span class="mf">0.42520832</span> <span class="mf">0.94850757</span> <span class="mf">0.54317573</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.64228691</span> <span class="mf">0.9904079</span>  <span class="mf">0.01008592</span> <span class="mf">0.51365217</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.78640595</span> <span class="mf">0.7717037</span>  <span class="mf">0.51277595</span> <span class="mf">0.24245034</span><span class="p">]]]</span>


 <span class="p">[[[</span><span class="mf">0.82184752</span> <span class="mf">0.92537331</span> <span class="mf">0.20632728</span> <span class="mf">0.47539445</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.44604637</span> <span class="mf">0.1507692</span>  <span class="mf">0.5437313</span>  <span class="mf">0.2074501</span> <span class="p">]</span>
   <span class="p">[</span><span class="mf">0.93661363</span> <span class="mf">0.93962609</span> <span class="mf">0.29230559</span> <span class="mf">0.74850958</span><span class="p">]]</span>

  <span class="p">[[</span><span class="mf">0.11659768</span> <span class="mf">0.76177132</span> <span class="mf">0.33194573</span> <span class="mf">0.20695088</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.49636212</span> <span class="mf">0.85987328</span> <span class="mf">0.49767861</span> <span class="mf">0.96774006</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.67669121</span> <span class="mf">0.15542122</span> <span class="mf">0.69981032</span> <span class="mf">0.3349874</span> <span class="p">]]]]</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[[</span><span class="mf">2.5371614</span> <span class="mf">2.5599902</span> <span class="mf">2.3366253</span> <span class="mf">2.6817122</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">2.3096325</span> <span class="mf">1.3962016</span> <span class="mf">1.6506982</span> <span class="mf">1.2824761</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">1.6814638</span> <span class="mf">2.3283222</span> <span class="mf">1.1676165</span> <span class="mf">1.8503776</span><span class="p">]]</span>

  <span class="p">[[</span><span class="mf">1.7726992</span> <span class="mf">1.5299091</span> <span class="mf">2.5818534</span> <span class="mf">1.721465</span> <span class="p">]</span>
   <span class="p">[</span><span class="mf">1.9008229</span> <span class="mf">2.6923325</span> <span class="mf">1.010137</span>  <span class="mf">1.6713842</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">2.1954916</span> <span class="mf">2.163449</span>  <span class="mf">1.6699204</span> <span class="mf">1.2743679</span><span class="p">]]]</span>


 <span class="p">[[[</span><span class="mf">2.2746985</span> <span class="mf">2.52281</span>   <span class="mf">1.2291554</span> <span class="mf">1.6086487</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">1.5621239</span> <span class="mf">1.1627283</span> <span class="mf">1.7224218</span> <span class="mf">1.2305363</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">2.551327</span>  <span class="mf">2.5590243</span> <span class="mf">1.3395122</span> <span class="mf">2.1138473</span><span class="p">]]</span>

  <span class="p">[[</span><span class="mf">1.1236672</span> <span class="mf">2.1420672</span> <span class="mf">1.3936772</span> <span class="mf">1.2299222</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">1.6427343</span> <span class="mf">2.3628614</span> <span class="mf">1.6448984</span> <span class="mf">2.6319895</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">1.9673574</span> <span class="mf">1.16815</span>   <span class="mf">2.0133708</span> <span class="mf">1.3979228</span><span class="p">]]]]</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="square">
<h3>7.22 Square<a class="headerlink" href="#square" title="Permalink to this headline">¶</a></h3>
<p>Applies an element-wise square operation to the input.</p>
<p>When you use this layer as the first layer of a model, you need to provide the argument inputShape (a Single Shape, does not include the batch dimension).</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Square</span><span class="o">(</span><span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Square</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">MultiShape</span></code></a> object that consists of two identical Single Shape. For Python API, it should be a list of two identical shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Square</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Square</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">randn</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,1,.,.) =
-0.108013034    1.8879265       1.2232096       -1.5076439
1.4895755       -0.37966672     -0.34892964     0.15224025
-0.9296686      -1.1523775      0.14153497      -0.26954007

(1,2,.,.) =
-1.0875931      2.190617        -0.6903083      1.0039362
-0.1275677      -1.1096588      0.37359753      -0.17367937
0.23349741      0.14639114      -0.2330162      0.5343827

(2,1,.,.) =
0.3222191       0.21463287      -1.0157064      -0.22627507
1.1714277       0.43371263      1.069315        0.5122436
0.1958086       -1.4601041      2.5394423       -0.470833

(2,2,.,.) =
-0.38708544     -0.951611       -0.37234613     0.26813275
1.9477026       0.32779223      -1.2308712      -2.2376378
0.19652915      0.3304719       -1.7674786      -0.86961496

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,1,.,.) =
0.011666816     3.5642662       1.4962418       2.2729902
2.218835        0.14414681      0.1217519       0.023177093
0.86428374      1.3279738       0.020032147     0.07265185

(1,2,.,.) =
1.1828587       4.7988033       0.47652552      1.0078878
0.016273517     1.2313428       0.13957511      0.030164523
0.05452104      0.021430366     0.054296546     0.28556487

(2,1,.,.) =
0.10382515      0.046067268     1.0316595       0.05120041
1.3722429       0.18810664      1.1434345       0.26239353
0.038341008     2.131904        6.448767        0.22168371

(2,2,.,.) =
0.14983514      0.9055635       0.13864164      0.07189517
3.7935455       0.10744774      1.5150439       5.007023
0.038623706     0.109211676     3.1239805       0.7562302

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">Square</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Square</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[[</span><span class="mf">0.8708819</span>  <span class="mf">0.2698243</span>  <span class="mf">0.55854849</span> <span class="mf">0.71699472</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.66647234</span> <span class="mf">0.72310216</span> <span class="mf">0.8082119</span>  <span class="mf">0.66566951</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.6714764</span>  <span class="mf">0.61394108</span> <span class="mf">0.35063125</span> <span class="mf">0.60473593</span><span class="p">]]</span>

  <span class="p">[[</span><span class="mf">0.37993365</span> <span class="mf">0.64222557</span> <span class="mf">0.96762005</span> <span class="mf">0.18931697</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.00529722</span> <span class="mf">0.99133455</span> <span class="mf">0.09786619</span> <span class="mf">0.28988077</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.60052911</span> <span class="mf">0.83712995</span> <span class="mf">0.59847519</span> <span class="mf">0.54361243</span><span class="p">]]]</span>


 <span class="p">[[[</span><span class="mf">0.32832672</span> <span class="mf">0.83316023</span> <span class="mf">0.41272485</span> <span class="mf">0.01963383</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.89593955</span> <span class="mf">0.73433713</span> <span class="mf">0.67529323</span> <span class="mf">0.69711912</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.81251711</span> <span class="mf">0.56755577</span> <span class="mf">0.31958151</span> <span class="mf">0.09795917</span><span class="p">]]</span>

  <span class="p">[[</span><span class="mf">0.46465895</span> <span class="mf">0.22818875</span> <span class="mf">0.31505317</span> <span class="mf">0.41912166</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.87865447</span> <span class="mf">0.3799063</span>  <span class="mf">0.091204</span>   <span class="mf">0.68144165</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">0.88274284</span> <span class="mf">0.70479132</span> <span class="mf">0.32074672</span> <span class="mf">0.71771481</span><span class="p">]]]]</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[[[[</span><span class="mf">7.5843531e-01</span> <span class="mf">7.2805151e-02</span> <span class="mf">3.1197643e-01</span> <span class="mf">5.1408142e-01</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">4.4418535e-01</span> <span class="mf">5.2287674e-01</span> <span class="mf">6.5320653e-01</span> <span class="mf">4.4311589e-01</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">4.5088059e-01</span> <span class="mf">3.7692365e-01</span> <span class="mf">1.2294226e-01</span> <span class="mf">3.6570552e-01</span><span class="p">]]</span>

  <span class="p">[[</span><span class="mf">1.4434958e-01</span> <span class="mf">4.1245368e-01</span> <span class="mf">9.3628860e-01</span> <span class="mf">3.5840917e-02</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">2.8060573e-05</span> <span class="mf">9.8274422e-01</span> <span class="mf">9.5777912e-03</span> <span class="mf">8.4030852e-02</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">3.6063525e-01</span> <span class="mf">7.0078653e-01</span> <span class="mf">3.5817260e-01</span> <span class="mf">2.9551446e-01</span><span class="p">]]]</span>


 <span class="p">[[[</span><span class="mf">1.0779844e-01</span> <span class="mf">6.9415593e-01</span> <span class="mf">1.7034180e-01</span> <span class="mf">3.8548734e-04</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">8.0270761e-01</span> <span class="mf">5.3925103e-01</span> <span class="mf">4.5602092e-01</span> <span class="mf">4.8597506e-01</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">6.6018403e-01</span> <span class="mf">3.2211956e-01</span> <span class="mf">1.0213234e-01</span> <span class="mf">9.5959986e-03</span><span class="p">]]</span>

  <span class="p">[[</span><span class="mf">2.1590793e-01</span> <span class="mf">5.2070107e-02</span> <span class="mf">9.9258497e-02</span> <span class="mf">1.7566296e-01</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">7.7203369e-01</span> <span class="mf">1.4432879e-01</span> <span class="mf">8.3181690e-03</span> <span class="mf">4.6436274e-01</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">7.7923489e-01</span> <span class="mf">4.9673077e-01</span> <span class="mf">1.0287846e-01</span> <span class="mf">5.1511449e-01</span><span class="p">]]]]</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="power">
<h3>7.23 Power<a class="headerlink" href="#power" title="Permalink to this headline">¶</a></h3>
<p>Applies an element-wise power operation with scale and shift to the input.</p>
<p>f(x) = (shift + scale * x)^power^</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Power</span><span class="o">(</span><span class="n">power</span><span class="o">,</span> <span class="n">scale</span> <span class="k">=</span> <span class="mi">1</span><span class="o">,</span> <span class="n">shift</span> <span class="k">=</span> <span class="mi">0</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Power</span><span class="p">(</span><span class="n">power</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">power</span></code>: The exponent</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scale</span></code>: The scale parameter. Default is 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shift</span></code>: The shift parameter. Default is 0.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Power</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Power</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">rand</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,.,.) =
0.24691099      0.7588585       0.5785183
0.10356348      0.2252714       0.3129436

(2,.,.) =
0.6277785       0.75136995      0.044648796
0.46396527      0.9793776       0.92727077

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
0.060965035     0.5758662       0.3346834
0.010725395     0.050747205     0.0979337

(2,.,.) =
0.39410582      0.5645568       0.001993515
0.21526377      0.95918053      0.8598311

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">Power</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Power</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[</span><span class="mf">0.5300817</span> <span class="p">,</span> <span class="mf">0.18128031</span><span class="p">,</span> <span class="mf">0.19534253</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.28380639</span><span class="p">,</span> <span class="mf">0.78365165</span><span class="p">,</span> <span class="mf">0.6893</span>    <span class="p">]],</span>

       <span class="p">[[</span><span class="mf">0.05574091</span><span class="p">,</span> <span class="mf">0.400077</span>  <span class="p">,</span> <span class="mf">0.77051193</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.033559</span>  <span class="p">,</span> <span class="mf">0.61051396</span><span class="p">,</span> <span class="mf">0.13970227</span><span class="p">]]])</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[</span><span class="mf">0.2809866</span> <span class="p">,</span> <span class="mf">0.03286255</span><span class="p">,</span> <span class="mf">0.03815871</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.08054607</span><span class="p">,</span> <span class="mf">0.61410993</span><span class="p">,</span> <span class="mf">0.4751345</span> <span class="p">]],</span>

       <span class="p">[[</span><span class="mf">0.00310705</span><span class="p">,</span> <span class="mf">0.16006161</span><span class="p">,</span> <span class="mf">0.5936886</span> <span class="p">],</span>
        <span class="p">[</span><span class="mf">0.00112621</span><span class="p">,</span> <span class="mf">0.37272733</span><span class="p">,</span> <span class="mf">0.01951673</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="addconstant">
<h3>7.24 AddConstant<a class="headerlink" href="#addconstant" title="Permalink to this headline">¶</a></h3>
<p>Add a (non-learnable) scalar constant to the input.</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">AddConstant</span><span class="o">(</span><span class="n">constant</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">AddConstant</span><span class="p">(</span><span class="n">constant</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">constant</span></code>: The scalar constant to be added.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.AddConstant</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">AddConstant</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">1</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">rand</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,.,.) =
0.5658301       0.3508225       0.4012322
0.1941942       0.18934165      0.6909284

(2,.,.) =
0.5985211       0.5485885       0.778548
0.16745302      0.10363362      0.92185616

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,.,.) =
1.5658301       1.3508224       1.4012322
1.1941942       1.1893417       1.6909285

(2,.,.) =
1.5985211       1.5485885       1.778548
1.167453        1.1036336       1.9218562

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">AddConstant</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">AddConstant</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[</span><span class="mf">0.71730919</span><span class="p">,</span> <span class="mf">0.07752598</span><span class="p">,</span> <span class="mf">0.10448237</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.52319608</span><span class="p">,</span> <span class="mf">0.38668494</span><span class="p">,</span> <span class="mf">0.19588814</span><span class="p">]],</span>

       <span class="p">[[</span><span class="mf">0.15496092</span><span class="p">,</span> <span class="mf">0.48405899</span><span class="p">,</span> <span class="mf">0.41441248</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.13792111</span><span class="p">,</span> <span class="mf">0.7523953</span> <span class="p">,</span> <span class="mf">0.55991187</span><span class="p">]]])</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[</span><span class="mf">1.7173092</span><span class="p">,</span> <span class="mf">1.077526</span> <span class="p">,</span> <span class="mf">1.1044824</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.5231961</span><span class="p">,</span> <span class="mf">1.3866849</span><span class="p">,</span> <span class="mf">1.1958882</span><span class="p">]],</span>

       <span class="p">[[</span><span class="mf">1.1549609</span><span class="p">,</span> <span class="mf">1.484059</span> <span class="p">,</span> <span class="mf">1.4144125</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.1379211</span><span class="p">,</span> <span class="mf">1.7523953</span><span class="p">,</span> <span class="mf">1.5599118</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="narrow">
<h3>7.25 Narrow<a class="headerlink" href="#narrow" title="Permalink to this headline">¶</a></h3>
<p>Narrow the input with the number of dimensions not being reduced.</p>
<p>The batch dimension needs to be unchanged.</p>
<p>For example, if input is:</p>
<p>[[1 2 3],
[4 5 6]]</p>
<p>Narrow(1, 1, 2) will give output</p>
<p>[[2 3],
[5 6]]</p>
<p>Narrow(1, 2, -1) will give output</p>
<p>[3,
6]</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Narrow</span><span class="o">(</span><span class="n">dim</span><span class="o">,</span> <span class="n">offset</span><span class="o">,</span> <span class="n">length</span> <span class="k">=</span> <span class="mi">1</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Narrow</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dim</span></code>: The dimension to narrow. 0-based index. Cannot narrow the batch dimension.
-1 means the last dimension of the input.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">offset</span></code>: Non-negative integer. The start index on the given dimension. 0-based index.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">length</span></code>: The length to narrow. Default is 1.
Can use a negative length such as -1 in the case where input size is unknown.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Narrow</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Narrow</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">rand</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,1,.,.) =
0.13770224      0.63719153      0.7776689       0.46612367
0.9026256       0.11982094      0.8282868       0.05095969
0.889799        0.6386537       0.35438475      0.298043

(1,2,.,.) =
0.5029727       0.20103335      0.20150806      0.06437344
0.2255908       0.5388977       0.59737855      0.5210477
0.4055072       0.11848069      0.7118382       0.9796308

(2,1,.,.) =
0.63957494      0.1921936       0.7749439       0.19744827
0.91683346      0.16140814      0.9753973       0.8161283
0.8481694       0.8802563       0.1233245       0.5732614

(2,2,.,.) =
0.275001        0.35905758      0.15939762      0.09233412
0.16610192      0.032060683     0.37298614      0.48936844
0.031097537     0.82767457      0.10246291      0.9951448

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,1,.,.) =
0.5029727       0.20103335      0.20150806      0.06437344
0.2255908       0.5388977       0.59737855      0.5210477
0.4055072       0.11848069      0.7118382       0.9796308

(2,1,.,.) =
0.275001        0.35905758      0.15939762      0.09233412
0.16610192      0.032060683     0.37298614      0.48936844
0.031097537     0.82767457      0.10246291      0.9951448

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x3x4]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">Narrow</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Narrow</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[[</span><span class="mf">0.74305305</span><span class="p">,</span> <span class="mf">0.33925069</span><span class="p">,</span> <span class="mf">0.31289333</span><span class="p">,</span> <span class="mf">0.43703923</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.28316902</span><span class="p">,</span> <span class="mf">0.3004414</span> <span class="p">,</span> <span class="mf">0.40298034</span><span class="p">,</span> <span class="mf">0.37476436</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.18825825</span><span class="p">,</span> <span class="mf">0.38979411</span><span class="p">,</span> <span class="mf">0.32963262</span><span class="p">,</span> <span class="mf">0.37783457</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mf">0.14824117</span><span class="p">,</span> <span class="mf">0.43532988</span><span class="p">,</span> <span class="mf">0.57077087</span><span class="p">,</span> <span class="mf">0.91535978</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.46375725</span><span class="p">,</span> <span class="mf">0.90511296</span><span class="p">,</span> <span class="mf">0.18859044</span><span class="p">,</span> <span class="mf">0.92820822</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.13675737</span><span class="p">,</span> <span class="mf">0.48270908</span><span class="p">,</span> <span class="mf">0.04260755</span><span class="p">,</span> <span class="mf">0.97255687</span><span class="p">]]],</span>
       <span class="p">[[[</span><span class="mf">0.4836805</span> <span class="p">,</span> <span class="mf">0.45262542</span><span class="p">,</span> <span class="mf">0.7233705</span> <span class="p">,</span> <span class="mf">0.63486529</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.07472717</span><span class="p">,</span> <span class="mf">0.5715716</span> <span class="p">,</span> <span class="mf">0.57029986</span><span class="p">,</span> <span class="mf">0.26475783</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.56757079</span><span class="p">,</span> <span class="mf">0.27602746</span><span class="p">,</span> <span class="mf">0.45799196</span><span class="p">,</span> <span class="mf">0.74420842</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mf">0.89048761</span><span class="p">,</span> <span class="mf">0.08280716</span><span class="p">,</span> <span class="mf">0.99030481</span><span class="p">,</span> <span class="mf">0.35956427</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.70802689</span><span class="p">,</span> <span class="mf">0.14425212</span><span class="p">,</span> <span class="mf">0.08320864</span><span class="p">,</span> <span class="mf">0.82271697</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.6915224</span> <span class="p">,</span> <span class="mf">0.70490768</span><span class="p">,</span> <span class="mf">0.41218963</span><span class="p">,</span> <span class="mf">0.37024863</span><span class="p">]]]])</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[[</span><span class="mf">0.14824118</span><span class="p">,</span> <span class="mf">0.43532988</span><span class="p">,</span> <span class="mf">0.57077086</span><span class="p">,</span> <span class="mf">0.9153598</span> <span class="p">],</span>
         <span class="p">[</span><span class="mf">0.46375725</span><span class="p">,</span> <span class="mf">0.905113</span>  <span class="p">,</span> <span class="mf">0.18859044</span><span class="p">,</span> <span class="mf">0.92820823</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.13675737</span><span class="p">,</span> <span class="mf">0.48270908</span><span class="p">,</span> <span class="mf">0.04260755</span><span class="p">,</span> <span class="mf">0.9725569</span> <span class="p">]]],</span>

       <span class="p">[[[</span><span class="mf">0.8904876</span> <span class="p">,</span> <span class="mf">0.08280716</span><span class="p">,</span> <span class="mf">0.9903048</span> <span class="p">,</span> <span class="mf">0.35956427</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.7080269</span> <span class="p">,</span> <span class="mf">0.14425212</span><span class="p">,</span> <span class="mf">0.08320864</span><span class="p">,</span> <span class="mf">0.82271695</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.6915224</span> <span class="p">,</span> <span class="mf">0.70490766</span><span class="p">,</span> <span class="mf">0.41218963</span><span class="p">,</span> <span class="mf">0.37024862</span><span class="p">]]]],</span>
      <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="permute">
<h3>7.26 Permute<a class="headerlink" href="#permute" title="Permalink to this headline">¶</a></h3>
<p>Permutes the dimensions of the input according to a given pattern.</p>
<p>Useful for connecting RNNs and convnets together.</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">Permute</span><span class="o">(</span><span class="n">dims</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Permute</span><span class="p">(</span><span class="n">dims</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dims</span></code>: Int array. Permutation pattern, does not include the batch dimension.
Indexing starts at 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.Permute</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Permute</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="nc">Array</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">3</span><span class="o">),</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">rand</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>input: com.intel.analytics.bigdl.tensor.Tensor[Float] =
(1,1,.,.) =
0.8451549       0.06361471      0.7324815
0.31086245      0.21210302      0.35112163

(1,2,.,.) =
0.61466074      0.50173014      0.8759959
0.19090249      0.671227        0.73089105
(2,1,.,.) =
0.47867084      0.9341955       0.063592255
0.24063066      0.502274        0.9114748
(2,2,.,.) =
0.93335986      0.25173688      0.88615775
0.5394321       0.330763        0.89036304

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,1,.,.) =
0.8451549       0.06361471      0.7324815
0.61466074      0.50173014      0.8759959

(1,2,.,.) =
0.31086245      0.21210302      0.35112163
0.19090249      0.671227        0.73089105
(2,1,.,.) =
0.47867084      0.9341955       0.063592255
0.93335986      0.25173688      0.88615775
(2,2,.,.) =
0.24063066      0.502274        0.9114748
0.5394321       0.330763        0.89036304

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">Permute</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Permute</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[[</span><span class="mf">0.14016896</span><span class="p">,</span> <span class="mf">0.7275626</span> <span class="p">,</span> <span class="mf">0.79087092</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.57259566</span><span class="p">,</span> <span class="mf">0.97387138</span><span class="p">,</span> <span class="mf">0.70001999</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mf">0.9232002</span> <span class="p">,</span> <span class="mf">0.07644555</span><span class="p">,</span> <span class="mf">0.24705828</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.17257354</span><span class="p">,</span> <span class="mf">0.93951155</span><span class="p">,</span> <span class="mf">0.46183983</span><span class="p">]]],</span>
       <span class="p">[[[</span><span class="mf">0.79432476</span><span class="p">,</span> <span class="mf">0.64299062</span><span class="p">,</span> <span class="mf">0.33959594</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.58608318</span><span class="p">,</span> <span class="mf">0.338014</span>  <span class="p">,</span> <span class="mf">0.92602687</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mf">0.32638575</span><span class="p">,</span> <span class="mf">0.69032582</span><span class="p">,</span> <span class="mf">0.25168083</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.46813027</span><span class="p">,</span> <span class="mf">0.95118373</span><span class="p">,</span> <span class="mf">0.13145026</span><span class="p">]]]])</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[[</span><span class="mf">0.14016896</span><span class="p">,</span> <span class="mf">0.7275626</span> <span class="p">,</span> <span class="mf">0.7908709</span> <span class="p">],</span>
         <span class="p">[</span><span class="mf">0.9232002</span> <span class="p">,</span> <span class="mf">0.07644555</span><span class="p">,</span> <span class="mf">0.24705827</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mf">0.57259566</span><span class="p">,</span> <span class="mf">0.97387135</span><span class="p">,</span> <span class="mf">0.70002</span>   <span class="p">],</span>
         <span class="p">[</span><span class="mf">0.17257354</span><span class="p">,</span> <span class="mf">0.93951154</span><span class="p">,</span> <span class="mf">0.46183982</span><span class="p">]]],</span>
       <span class="p">[[[</span><span class="mf">0.79432476</span><span class="p">,</span> <span class="mf">0.64299065</span><span class="p">,</span> <span class="mf">0.33959594</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.32638577</span><span class="p">,</span> <span class="mf">0.6903258</span> <span class="p">,</span> <span class="mf">0.25168082</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mf">0.5860832</span> <span class="p">,</span> <span class="mf">0.338014</span>  <span class="p">,</span> <span class="mf">0.9260269</span> <span class="p">],</span>
         <span class="p">[</span><span class="mf">0.46813026</span><span class="p">,</span> <span class="mf">0.95118374</span><span class="p">,</span> <span class="mf">0.13145027</span><span class="p">]]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="resizebilinear">
<h3>7.27 ResizeBilinear<a class="headerlink" href="#resizebilinear" title="Permalink to this headline">¶</a></h3>
<p>Resize the input image with bilinear interpolation. The input image must be a float tensor with NHWC or NCHW layout.</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="nc">ResizeBilinear</span><span class="o">(</span><span class="n">outputHeight</span><span class="o">,</span> <span class="n">outputWidth</span><span class="o">,</span> <span class="n">alignCorners</span> <span class="k">=</span> <span class="kc">false</span><span class="o">,</span> <span class="n">dimOrdering</span> <span class="k">=</span> <span class="s">&quot;th&quot;</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="kc">null</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ResizeBilinear</span><span class="p">(</span><span class="n">output_height</span><span class="p">,</span> <span class="n">output_width</span><span class="p">,</span> <span class="n">align_corner</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Parameters:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">outputHeight</span></code>: output height</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">outputWidth</span></code>: output width</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">alignCorners</span></code>: align corner or not</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dimOrdering</span></code>: Format of input data. Either DataFormat.NCHW (dimOrdering=’th’) or DataFormat.NHWC (dimOrdering=’tf’). Default is NCHW.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputShape</span></code>: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a <a class="reference external" href="../keras-api-scala/#shape"><code class="docutils literal notranslate"><span class="pre">Shape</span></code></a> object. For Python API, it should be a shape tuple. Batch dimension should be excluded.</p></li>
</ul>
<p><strong>Scala example:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.ResizeBilinear</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.utils.Shape</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.tensor.Tensor</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">ResizeBilinear</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">5</span><span class="o">)))</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="nc">Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">5</span><span class="o">).</span><span class="n">rand</span><span class="o">()</span>
<span class="k">val</span> <span class="n">output</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="o">(</span><span class="n">input</span><span class="o">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">input</span><span class="k">:</span> <span class="kt">com.intel.analytics.bigdl.tensor.Tensor</span><span class="o">[</span><span class="kt">Float</span><span class="o">]</span> <span class="k">=</span>
<span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">1</span><span class="o">,.,.)</span> <span class="k">=</span>
<span class="mf">0.6991891</span>       <span class="mf">0.007127314</span>     <span class="mf">0.73871046</span>      <span class="mf">0.95916307</span>      <span class="mf">0.9433856</span>
<span class="mf">0.41275907</span>      <span class="mf">0.37573513</span>      <span class="mf">0.99193203</span>      <span class="mf">0.06930728</span>      <span class="mf">0.5922364</span>
<span class="mf">0.024281504</span>     <span class="mf">0.2592453</span>       <span class="mf">0.3898136</span>       <span class="mf">0.6635241</span>       <span class="mf">0.85888565</span>

<span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">,.,.)</span> <span class="k">=</span>
<span class="mf">0.38028112</span>      <span class="mf">0.43709648</span>      <span class="mf">0.62538666</span>      <span class="mf">0.8468501</span>       <span class="mf">0.6445014</span>
<span class="mf">0.45252413</span>      <span class="mf">0.48801896</span>      <span class="mf">0.59471387</span>      <span class="mf">0.013207023</span>     <span class="mf">0.3567462</span>
<span class="mf">0.85187584</span>      <span class="mf">0.49279585</span>      <span class="mf">0.7973665</span>       <span class="mf">0.81287366</span>      <span class="mf">0.07852263</span>

<span class="o">(</span><span class="mi">2</span><span class="o">,</span><span class="mi">1</span><span class="o">,.,.)</span> <span class="k">=</span>
<span class="mf">0.1452374</span>       <span class="mf">0.6140467</span>       <span class="mf">0.36384684</span>      <span class="mf">0.066476084</span>     <span class="mf">0.96101314</span>
<span class="mf">0.54862195</span>      <span class="mf">0.66091377</span>      <span class="mf">0.86857307</span>      <span class="mf">0.6844842</span>       <span class="mf">0.7368217</span>
<span class="mf">0.25342992</span>      <span class="mf">0.71737933</span>      <span class="mf">0.12789607</span>      <span class="mf">0.21691357</span>      <span class="mf">0.7543404</span>

<span class="o">(</span><span class="mi">2</span><span class="o">,</span><span class="mi">2</span><span class="o">,.,.)</span> <span class="k">=</span>
<span class="mf">0.79176855</span>      <span class="mf">0.1204049</span>       <span class="mf">0.58971256</span>      <span class="mf">0.115073755</span>     <span class="mf">0.10459962</span>
<span class="mf">0.5225398</span>       <span class="mf">0.742363</span>        <span class="mf">0.7612815</span>       <span class="mf">0.9881919</span>       <span class="mf">0.13359445</span>
<span class="mf">0.9026869</span>       <span class="mf">0.13972941</span>      <span class="mf">0.92064524</span>      <span class="mf">0.9435532</span>       <span class="mf">0.5502235</span>

<span class="o">[</span><span class="kt">com.intel.analytics.bigdl.tensor.DenseTensor</span> <span class="kt">of...</span>
</pre></div>
</div>
<p>Output is:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span>output: com.intel.analytics.bigdl.nn.abstractnn.Activity =
(1,1,.,.) =
0.6991891       0.4948494       0.9539039
0.21852028      0.5664119       0.48613077

(1,2,.,.) =
0.38028112      0.56262326      0.7794005
0.6522  0.6274959       0.34790504

(2,1,.,.) =
0.1452374       0.4472468       0.36465502
0.40102595      0.5618719       0.54899293

(2,2,.,.) =
0.79176855      0.43327665      0.111582376
0.71261334      0.70765764      0.75788474

[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]
</pre></div>
</div>
<p><strong>Python example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layers</span> <span class="kn">import</span> <span class="n">ResizeBilinear</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ResizeBilinear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)))</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Input is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[[</span><span class="mf">0.43790358</span><span class="p">,</span> <span class="mf">0.41882914</span><span class="p">,</span> <span class="mf">0.71929122</span><span class="p">,</span> <span class="mf">0.19673119</span><span class="p">,</span> <span class="mf">0.36950189</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.38808651</span><span class="p">,</span> <span class="mf">0.34287751</span><span class="p">,</span> <span class="mf">0.34076998</span><span class="p">,</span> <span class="mf">0.02581254</span><span class="p">,</span> <span class="mf">0.42406155</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.84648848</span><span class="p">,</span> <span class="mf">0.18411068</span><span class="p">,</span> <span class="mf">0.97545126</span><span class="p">,</span> <span class="mf">0.5468195</span> <span class="p">,</span> <span class="mf">0.32136674</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mf">0.32965599</span><span class="p">,</span> <span class="mf">0.06883324</span><span class="p">,</span> <span class="mf">0.17350748</span><span class="p">,</span> <span class="mf">0.01181338</span><span class="p">,</span> <span class="mf">0.59180775</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.24667588</span><span class="p">,</span> <span class="mf">0.36422516</span><span class="p">,</span> <span class="mf">0.59648387</span><span class="p">,</span> <span class="mf">0.48699443</span><span class="p">,</span> <span class="mf">0.32323264</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.67661373</span><span class="p">,</span> <span class="mf">0.58779956</span><span class="p">,</span> <span class="mf">0.55286771</span><span class="p">,</span> <span class="mf">0.59629101</span><span class="p">,</span> <span class="mf">0.69727522</span><span class="p">]]],</span>


       <span class="p">[[[</span><span class="mf">0.09462238</span><span class="p">,</span> <span class="mf">0.35658325</span><span class="p">,</span> <span class="mf">0.6787812</span> <span class="p">,</span> <span class="mf">0.78676645</span><span class="p">,</span> <span class="mf">0.99019452</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.81501527</span><span class="p">,</span> <span class="mf">0.13348641</span><span class="p">,</span> <span class="mf">0.71749101</span><span class="p">,</span> <span class="mf">0.40543351</span><span class="p">,</span> <span class="mf">0.3959018</span> <span class="p">],</span>
         <span class="p">[</span><span class="mf">0.608378</span>  <span class="p">,</span> <span class="mf">0.10531177</span><span class="p">,</span> <span class="mf">0.78000335</span><span class="p">,</span> <span class="mf">0.51679768</span><span class="p">,</span> <span class="mf">0.65067605</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mf">0.12074634</span><span class="p">,</span> <span class="mf">0.92682843</span><span class="p">,</span> <span class="mf">0.52227042</span><span class="p">,</span> <span class="mf">0.98856558</span><span class="p">,</span> <span class="mf">0.28105255</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.78411841</span><span class="p">,</span> <span class="mf">0.19625097</span><span class="p">,</span> <span class="mf">0.83108171</span><span class="p">,</span> <span class="mf">0.03777509</span><span class="p">,</span> <span class="mf">0.15700493</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.95528158</span><span class="p">,</span> <span class="mf">0.94003855</span><span class="p">,</span> <span class="mf">0.61092905</span><span class="p">,</span> <span class="mf">0.68651048</span><span class="p">,</span> <span class="mf">0.57563719</span><span class="p">]]]])</span>
</pre></div>
</div>
<p>Output is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[[[</span><span class="mf">0.43790358</span><span class="p">,</span> <span class="mf">0.61913717</span><span class="p">,</span> <span class="mf">0.2543214</span> <span class="p">],</span>
         <span class="p">[</span><span class="mf">0.6172875</span> <span class="p">,</span> <span class="mf">0.52657175</span><span class="p">,</span> <span class="mf">0.3151154</span> <span class="p">]],</span>

        <span class="p">[[</span><span class="mf">0.329656</span>  <span class="p">,</span> <span class="mf">0.13861606</span><span class="p">,</span> <span class="mf">0.20514478</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">0.46164483</span><span class="p">,</span> <span class="mf">0.541788</span>  <span class="p">,</span> <span class="mf">0.5311798</span> <span class="p">]]],</span>


       <span class="p">[[[</span><span class="mf">0.09462238</span><span class="p">,</span> <span class="mf">0.57138187</span><span class="p">,</span> <span class="mf">0.8545758</span> <span class="p">],</span>
         <span class="p">[</span><span class="mf">0.7116966</span> <span class="p">,</span> <span class="mf">0.5389645</span> <span class="p">,</span> <span class="mf">0.48184</span>   <span class="p">]],</span>

        <span class="p">[[</span><span class="mf">0.12074634</span><span class="p">,</span> <span class="mf">0.6571231</span> <span class="p">,</span> <span class="mf">0.752728</span>  <span class="p">],</span>
         <span class="p">[</span><span class="mf">0.86969995</span><span class="p">,</span> <span class="mf">0.6700518</span> <span class="p">,</span> <span class="mf">0.36353552</span><span class="p">]]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="persistence">
<h2>8. Persistence<a class="headerlink" href="#persistence" title="Permalink to this headline">¶</a></h2>
<p>This section describes how to save and load the Keras-like API.</p>
<section id="save">
<h3>8.1 save<a class="headerlink" href="#save" title="Permalink to this headline">¶</a></h3>
<p>To save a Keras model, you call the method <code class="docutils literal notranslate"><span class="pre">saveModel(path)</span></code>.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.layers.</span><span class="o">{</span><span class="nc">Dense</span><span class="o">,</span> <span class="nc">Activation</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.models.Sequential</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Sequential</span><span class="o">[</span><span class="kt">Float</span><span class="o">]()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Dense</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="mi">32</span><span class="o">,</span> <span class="n">inputShape</span> <span class="k">=</span> <span class="nc">Shape</span><span class="o">(</span><span class="mi">128</span><span class="o">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="o">(</span><span class="nc">Activation</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="s">&quot;relu&quot;</span><span class="o">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">saveModel</span><span class="o">(</span><span class="s">&quot;/tmp/seq.model&quot;</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">bigdl.dllib.keras.Sequential</span>
<span class="kn">from</span> <span class="nn">bigdl.dllib.keras.layer</span> <span class="kn">import</span> <span class="n">Dense</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">saveModel</span><span class="p">(</span><span class="s2">&quot;/tmp/seq.model&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="load">
<h3>8.2 load<a class="headerlink" href="#load" title="Permalink to this headline">¶</a></h3>
<p>To load a saved Keras model, you call the method <code class="docutils literal notranslate"><span class="pre">load_model(path)</span></code>.</p>
<p><strong>Scala:</strong></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">com.intel.analytics.bigdl.dllib.keras.Models</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="nc">Models</span><span class="o">.</span><span class="n">loadModel</span><span class="o">[</span><span class="kt">Float</span><span class="o">](</span><span class="s">&quot;/tmp/seq.model&quot;</span><span class="o">)</span>
</pre></div>
</div>
<p><strong>Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bigdl.dllib.keras.models</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;/tmp/seq.model&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="dllib.html" class="btn btn-neutral float-left" title="DLlib User Guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="nnframes.html" class="btn btn-neutral float-right" title="Spark ML Pipeline Support" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, BigDL Authors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>