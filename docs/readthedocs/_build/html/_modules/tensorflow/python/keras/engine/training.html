<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>tensorflow.python.keras.engine.training &mdash; BigDL  documentation</title>
      <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
        <script src="../../../../../_static/clipboard.min.js"></script>
        <script src="../../../../../_static/copybutton.js"></script>
        <script src="../../../../../_static/tabs.js"></script>
        <script src="../../../../../_static/design-tabs.js"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../../index.html" class="icon icon-home"> BigDL
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Orca/QuickStart/orca-tf-quickstart.html">TensorFlow 1.15 Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Orca/QuickStart/orca-keras-quickstart.html">Keras 2.3 Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Orca/QuickStart/orca-tf2keras-quickstart.html">TensorFlow 2 Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Orca/QuickStart/orca-pytorch-quickstart.html">PyTorch Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Ray/QuickStart/ray-quickstart.html">RayOnSpark Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/UserGuide/python.html">Python User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/UserGuide/scala.html">Scala User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/UserGuide/colab.html">Colab User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/UserGuide/docker.html">Docker User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/UserGuide/hadoop.html">Hadoop/YARN User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/UserGuide/k8s.html">K8s User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/UserGuide/databricks.html">Databricks User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/UserGuide/develop.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/UserGuide/known_issues.html">BigDL Known Issues</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Nano</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Nano/Overview/nano.html">Nano User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Nano/Overview/windows_guide.html">Windows User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Nano/QuickStart/pytorch_train.html">BigDL-Nano PyTorch Training Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Nano/QuickStart/pytorch_inference.html">BigDL-Nano PyTorch Inference Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Nano/QuickStart/tensorflow_train.html">BigDL-Nano TensorFlow Training Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Nano/QuickStart/tensorflow_inference.html">BigDL-Nano TensorFlow Inference Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Nano/QuickStart/hpo.html">AutoML Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Nano/Overview/known_issues.html">Nano Known Issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Nano/QuickStart/index.html">Nano Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">DLlib</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/DLlib/Overview/dllib.html">DLlib User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/DLlib/Overview/keras-api.html">Keras-Like API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/DLlib/Overview/nnframes.html">Spark ML Pipeline Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Orca</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Orca/Overview/orca.html">Orca User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Orca/Overview/orca-context.html">Orca Context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Orca/Overview/data-parallel-processing.html">Distributed Data Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Orca/Overview/distributed-training-inference.html">Distributed Training and Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Orca/Overview/distributed-tuning.html">Distributed Hyper-Parameter Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Ray/Overview/ray.html">RayOnSpark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Orca/Overview/known_issues.html">Orca Known Issues</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chronos</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Chronos/Overview/chronos.html">Chronos User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Chronos/Overview/windows_guide.html">Windows User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Chronos/Overview/deep_dive.html">Chronos Deep Dive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Chronos/QuickStart/index.html">Chronos Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Chronos/Overview/chronos_known_issue.html">Chronos Known Issue</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PPML</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/PPML/Overview/ppml.html">Privacy Preserving Machine Learning (PPML) User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/PPML/Overview/trusted_big_data_analytics_and_ml.html">Trusted Big Data Analytics and ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/PPML/Overview/trusted_fl.html">Trusted FL (Federated Learning)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/PPML/QuickStart/secure_your_services.html">Secure Your Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/PPML/QuickStart/build_kernel_with_sgx.html">Building Linux Kernel from Source with SGX Enabled</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/PPML/QuickStart/deploy_intel_sgx_device_plugin_for_kubernetes.html">Deploy the Intel SGX Device Plugin for Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/PPML/QuickStart/trusted-serving-on-k8s-guide.html">Trusted Cluster Serving with Graphene on Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/PPML/QuickStart/tpc-h_with_sparksql_on_k8s.html">TPC-H with Trusted SparkSQL on Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/PPML/QuickStart/tpc-ds_with_sparksql_on_k8s.html">TPC-DS with Trusted SparkSQL on Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/PPML/Overview/azure_ppml.html">Privacy Preserving Machine Learning (PPML) on Azure User Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Serving</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Serving/Overview/serving.html">Cluster Serving User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Serving/QuickStart/serving-quickstart.html">Cluster Serving Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Serving/ProgrammingGuide/serving-installation.html">Install Cluster Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Serving/ProgrammingGuide/serving-start.html">Start Cluster Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Serving/ProgrammingGuide/serving-inference.html">Inference by Cluster Serving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Serving/Example/example.html">Cluster Serving Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Serving/FAQ/faq.html">Cluster Serving FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Serving/FAQ/contribute-guide.html">Contribute to Cluster Serving</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Common Use Case</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Orca/QuickStart/orca-pytorch-distributed-quickstart.html">Use <code class="docutils literal notranslate"><span class="pre">torch.distributed</span></code> in Orca</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/UseCase/spark-dataframe.html">Use Spark Dataframe for Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/UseCase/xshards-pandas.html">Use Distributed Pandas for Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Orca/QuickStart/orca-autoestimator-pytorch-quickstart.html">Enable AutoML for PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Orca/QuickStart/orca-autoxgboost-quickstart.html">Use AutoXGBoost to auto-tune XGBoost parameters</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/PythonAPI/Orca/orca.html">Orca API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/PythonAPI/Friesian/feature.html">Friesian Feature API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/PythonAPI/Chronos/index.html">Chronos API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/PythonAPI/Nano/index.html">Nano API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Real-World Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Application/presentations.html">Presentations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Application/blogs.html">Blogs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../doc/Application/powered-by.html">Powered By</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">BigDL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../../index.html">Module code</a> &raquo;</li>
      <li>tensorflow.python.keras.engine.training</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for tensorflow.python.keras.engine.training</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;Training-related part of the Keras engine.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">tensorflow.python</span> <span class="k">import</span> <span class="n">tf2</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.data.ops</span> <span class="k">import</span> <span class="n">dataset_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.data.ops</span> <span class="k">import</span> <span class="n">iterator_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.distribute</span> <span class="k">import</span> <span class="n">distribution_strategy_context</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager</span> <span class="k">import</span> <span class="n">context</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager</span> <span class="k">import</span> <span class="n">def_function</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager</span> <span class="k">import</span> <span class="n">monitoring</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">composite_tensor_utils</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">constant_op</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">sparse_tensor</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">tensor_shape</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">tensor_spec</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">tensor_util</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">type_spec</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras</span> <span class="k">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras</span> <span class="k">import</span> <span class="n">losses</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras</span> <span class="k">import</span> <span class="n">metrics</span> <span class="k">as</span> <span class="n">metrics_module</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras</span> <span class="k">import</span> <span class="n">optimizers</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.distribute</span> <span class="k">import</span> <span class="n">distributed_training_utils</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine</span> <span class="k">import</span> <span class="n">data_adapter</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine</span> <span class="k">import</span> <span class="n">network</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine</span> <span class="k">import</span> <span class="n">training_arrays</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine</span> <span class="k">import</span> <span class="n">training_distributed</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine</span> <span class="k">import</span> <span class="n">training_eager</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine</span> <span class="k">import</span> <span class="n">training_generator</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine</span> <span class="k">import</span> <span class="n">training_utils</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine</span> <span class="k">import</span> <span class="n">training_v2</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine</span> <span class="k">import</span> <span class="n">training_v2_utils</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.mixed_precision.experimental</span> <span class="k">import</span> <span class="n">loss_scale_optimizer</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.optimizer_v2</span> <span class="k">import</span> <span class="n">optimizer_v2</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.saving</span> <span class="k">import</span> <span class="n">saving_utils</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.utils</span> <span class="k">import</span> <span class="n">data_utils</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.utils</span> <span class="k">import</span> <span class="n">losses_utils</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.keras.utils.mode_keys</span> <span class="k">import</span> <span class="n">ModeKeys</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">array_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">math_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops.losses</span> <span class="k">import</span> <span class="n">util</span> <span class="k">as</span> <span class="n">tf_losses_utils</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.platform</span> <span class="k">import</span> <span class="n">tf_logging</span> <span class="k">as</span> <span class="n">logging</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.training.tracking</span> <span class="k">import</span> <span class="n">base</span> <span class="k">as</span> <span class="n">trackable</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.training.tracking</span> <span class="k">import</span> <span class="n">layer_utils</span> <span class="k">as</span> <span class="n">trackable_layer_utils</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util</span> <span class="k">import</span> <span class="n">nest</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util</span> <span class="k">import</span> <span class="n">serialization</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util</span> <span class="k">import</span> <span class="n">tf_inspect</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util.compat</span> <span class="k">import</span> <span class="n">collections_abc</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util.tf_export</span> <span class="k">import</span> <span class="n">keras_export</span>

<span class="k">try</span><span class="p">:</span>
  <span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="k">import</span> <span class="n">issparse</span>  <span class="c1"># pylint: disable=g-import-not-at-top</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
  <span class="n">issparse</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">_keras_api_gauge</span> <span class="o">=</span> <span class="n">monitoring</span><span class="o">.</span><span class="n">BoolGauge</span><span class="p">(</span><span class="s1">&#39;/tensorflow/api/keras&#39;</span><span class="p">,</span>
                                        <span class="s1">&#39;keras api usage&#39;</span><span class="p">,</span> <span class="s1">&#39;method&#39;</span><span class="p">)</span>


<div class="viewcode-block" id="Model"><a class="viewcode-back" href="../../../../../doc/PythonAPI/Nano/tensorflow.html#bigdl.nano.tf.keras.Model">[docs]</a><span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.models.Model&#39;</span><span class="p">,</span> <span class="s1">&#39;keras.Model&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;`Model` groups layers into an object with training and inference features.</span>

<span class="sd">  There are two ways to instantiate a `Model`:</span>

<span class="sd">  1 - With the &quot;functional API&quot;, where you start from `Input`,</span>
<span class="sd">  you chain layer calls to specify the model&#39;s forward pass,</span>
<span class="sd">  and finally you create your model from inputs and outputs:</span>

<span class="sd">  ```python</span>
<span class="sd">  import tensorflow as tf</span>

<span class="sd">  inputs = tf.keras.Input(shape=(3,))</span>
<span class="sd">  x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)</span>
<span class="sd">  outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)</span>
<span class="sd">  model = tf.keras.Model(inputs=inputs, outputs=outputs)</span>
<span class="sd">  ```</span>

<span class="sd">  2 - By subclassing the `Model` class: in that case, you should define your</span>
<span class="sd">  layers in `__init__` and you should implement the model&#39;s forward pass</span>
<span class="sd">  in `call`.</span>

<span class="sd">  ```python</span>
<span class="sd">  import tensorflow as tf</span>

<span class="sd">  class MyModel(tf.keras.Model):</span>

<span class="sd">    def __init__(self):</span>
<span class="sd">      super(MyModel, self).__init__()</span>
<span class="sd">      self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)</span>
<span class="sd">      self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)</span>

<span class="sd">    def call(self, inputs):</span>
<span class="sd">      x = self.dense1(inputs)</span>
<span class="sd">      return self.dense2(x)</span>

<span class="sd">  model = MyModel()</span>
<span class="sd">  ```</span>

<span class="sd">  If you subclass `Model`, you can optionally have</span>
<span class="sd">  a `training` argument (boolean) in `call`, which you can use to specify</span>
<span class="sd">  a different behavior in training and inference:</span>

<span class="sd">  ```python</span>
<span class="sd">  import tensorflow as tf</span>

<span class="sd">  class MyModel(tf.keras.Model):</span>

<span class="sd">    def __init__(self):</span>
<span class="sd">      super(MyModel, self).__init__()</span>
<span class="sd">      self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)</span>
<span class="sd">      self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)</span>
<span class="sd">      self.dropout = tf.keras.layers.Dropout(0.5)</span>

<span class="sd">    def call(self, inputs, training=False):</span>
<span class="sd">      x = self.dense1(inputs)</span>
<span class="sd">      if training:</span>
<span class="sd">        x = self.dropout(x, training=training)</span>
<span class="sd">      return self.dense2(x)</span>

<span class="sd">  model = MyModel()</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">_keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># initializing _distribution_strategy here since it is possible to call</span>
    <span class="c1"># predict on a model without compiling it.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_compile_time_distribution_strategy</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># This flag is used to track if the user is using the deprecated path of</span>
    <span class="c1"># passing distribution strategy to compile rather than creating the model</span>
    <span class="c1"># under distribution strategy scope.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_compile_distribution</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_run_eagerly</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_experimental_run_tf_function</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Retrieves the weights of the model.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A flat list of Numpy arrays.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">strategy</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span> <span class="ow">or</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_compile_time_distribution_strategy</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">strategy</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
    <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">by_name</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Loads all layer weights, either from a TensorFlow or an HDF5 file.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">distributed_training_utils</span><span class="o">.</span><span class="n">is_tpu_strategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">):</span>
      <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">steps_per_run</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span>
          <span class="p">(</span><span class="ow">not</span> <span class="n">network</span><span class="o">.</span><span class="n">_is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">))):</span>  <span class="c1"># pylint: disable=protected-access</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Load weights is not yet supported with TPUStrategy &#39;</span>
                         <span class="s1">&#39;with steps_per_run greater than 1.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">by_name</span><span class="p">)</span>

  <span class="nd">@trackable</span><span class="o">.</span><span class="n">no_automatic_dependency_tracking</span>
  <span class="k">def</span> <span class="nf">compile</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">loss_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">sample_weight_mode</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">weighted_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">target_tensors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">distribute</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Configures the model for training.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        optimizer: String (name of optimizer) or optimizer instance.</span>
<span class="sd">            See `tf.keras.optimizers`.</span>
<span class="sd">        loss: String (name of objective function), objective function or</span>
<span class="sd">            `tf.losses.Loss` instance. See `tf.losses`. If the model has</span>
<span class="sd">            multiple outputs, you can use a different loss on each output by</span>
<span class="sd">            passing a dictionary or a list of losses. The loss value that will</span>
<span class="sd">            be minimized by the model will then be the sum of all individual</span>
<span class="sd">            losses.</span>
<span class="sd">        metrics: List of metrics to be evaluated by the model during training</span>
<span class="sd">            and testing. Typically you will use `metrics=[&#39;accuracy&#39;]`.</span>
<span class="sd">            To specify different metrics for different outputs of a</span>
<span class="sd">            multi-output model, you could also pass a dictionary, such as</span>
<span class="sd">            `metrics={&#39;output_a&#39;: &#39;accuracy&#39;, &#39;output_b&#39;: [&#39;accuracy&#39;, &#39;mse&#39;]}`.</span>
<span class="sd">            You can also pass a list (len = len(outputs)) of lists of metrics</span>
<span class="sd">            such as `metrics=[[&#39;accuracy&#39;], [&#39;accuracy&#39;, &#39;mse&#39;]]` or</span>
<span class="sd">            `metrics=[&#39;accuracy&#39;, [&#39;accuracy&#39;, &#39;mse&#39;]]`.</span>
<span class="sd">        loss_weights: Optional list or dictionary specifying scalar</span>
<span class="sd">            coefficients (Python floats) to weight the loss contributions</span>
<span class="sd">            of different model outputs.</span>
<span class="sd">            The loss value that will be minimized by the model</span>
<span class="sd">            will then be the *weighted sum* of all individual losses,</span>
<span class="sd">            weighted by the `loss_weights` coefficients.</span>
<span class="sd">            If a list, it is expected to have a 1:1 mapping</span>
<span class="sd">            to the model&#39;s outputs. If a tensor, it is expected to map</span>
<span class="sd">            output names (strings) to scalar coefficients.</span>
<span class="sd">        sample_weight_mode: If you need to do timestep-wise</span>
<span class="sd">            sample weighting (2D weights), set this to `&quot;temporal&quot;`.</span>
<span class="sd">            `None` defaults to sample-wise weights (1D).</span>
<span class="sd">            If the model has multiple outputs, you can use a different</span>
<span class="sd">            `sample_weight_mode` on each output by passing a</span>
<span class="sd">            dictionary or a list of modes.</span>
<span class="sd">        weighted_metrics: List of metrics to be evaluated and weighted</span>
<span class="sd">            by sample_weight or class_weight during training and testing.</span>
<span class="sd">        target_tensors: By default, Keras will create placeholders for the</span>
<span class="sd">            model&#39;s target, which will be fed with the target data during</span>
<span class="sd">            training. If instead you would like to use your own</span>
<span class="sd">            target tensors (in turn, Keras will not expect external</span>
<span class="sd">            Numpy data for these targets at training time), you</span>
<span class="sd">            can specify them via the `target_tensors` argument. It can be</span>
<span class="sd">            a single tensor (for a single-output model), a list of tensors,</span>
<span class="sd">            or a dict mapping output names to target tensors.</span>
<span class="sd">        distribute: NOT SUPPORTED IN TF 2.0, please create and compile the</span>
<span class="sd">            model under distribution strategy scope instead of passing it to</span>
<span class="sd">            compile.</span>
<span class="sd">        **kwargs: Any additional arguments.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: In case of invalid arguments for</span>
<span class="sd">            `optimizer`, `loss`, `metrics` or `sample_weight_mode`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_run_eagerly</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;run_eagerly&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_experimental_run_tf_function</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
        <span class="s1">&#39;experimental_run_tf_function&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_set_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="n">is_any_optimizer_v1</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">)</span>
                              <span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">))</span>

    <span class="k">if</span> <span class="p">((</span><span class="n">sample_weight_mode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
        <span class="ow">or</span> <span class="p">(</span><span class="n">target_tensors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
        <span class="ow">or</span> <span class="n">is_any_optimizer_v1</span>
        <span class="ow">or</span> <span class="ow">not</span> <span class="n">ops</span><span class="o">.</span><span class="n">executing_eagerly_outside_functions</span><span class="p">()):</span>
      <span class="c1"># Fallback out of things that aren&#39;t supported with v2 loops</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_experimental_run_tf_function</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_compile_time_distribution_strategy</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">distribution_strategy_context</span><span class="o">.</span><span class="n">get_strategy</span><span class="p">())</span>

    <span class="k">if</span> <span class="n">distribute</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">tf2</span><span class="o">.</span><span class="n">enabled</span><span class="p">()</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_experimental_run_tf_function</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;Distribute argument in compile is not available in TF 2.0 please &#39;</span>
            <span class="s1">&#39;create the model under the distribution strategy scope.&#39;</span><span class="p">)</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Distribute argument in compile is deprecated please &#39;</span>
                      <span class="s1">&#39;create the model under the distribution strategy scope.&#39;</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span> <span class="o">=</span> <span class="n">distribute</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_compile_distribution</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">distribution_strategy_context</span><span class="o">.</span><span class="n">has_strategy</span><span class="p">():</span>
        <span class="c1"># When the user builds the model in the DS scope and cross replica</span>
        <span class="c1"># context we want distribution strategy to be set but when building the</span>
        <span class="c1"># replica copies of the models internally we should not be compiling</span>
        <span class="c1"># with distribution strategy and use the default compilation path.</span>
        <span class="k">if</span> <span class="n">distribution_strategy_context</span><span class="o">.</span><span class="n">in_cross_replica_context</span><span class="p">():</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span> <span class="o">=</span> <span class="p">(</span>
              <span class="n">distribution_strategy_context</span><span class="o">.</span><span class="n">get_strategy</span><span class="p">())</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_experimental_run_tf_function</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_validate_compile_param_for_distribution_strategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span><span class="p">,</span>
                                                             <span class="n">sample_weight_mode</span><span class="p">,</span>
                                                             <span class="n">target_tensors</span><span class="p">,</span>
                                                             <span class="n">weighted_metrics</span><span class="p">)</span>
    <span class="c1"># We&#39;ve disabled automatic dependency tracking for this method, but do want</span>
    <span class="c1"># to add a checkpoint dependency on the optimizer if it&#39;s trackable.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">trackable</span><span class="o">.</span><span class="n">Trackable</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_track_trackable</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span> <span class="o">=</span> <span class="n">loss_weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sample_weight_mode</span> <span class="o">=</span> <span class="n">sample_weight_mode</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_compile_metrics</span> <span class="o">=</span> <span class="n">metrics</span> <span class="ow">or</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_compile_weighted_metrics</span> <span class="o">=</span> <span class="n">weighted_metrics</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span> <span class="ow">and</span> <span class="n">target_tensors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s1">&#39;target_tensors argument is not supported when &#39;</span>
          <span class="s1">&#39;running a model eagerly.&#39;</span><span class="p">)</span>

    <span class="c1"># _training_endpoints contains a list of _TrainingEndpoint object, which has</span>
    <span class="c1"># all the model output/target/loss and related metadata.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Used to freeze the behavior of the Model once `compile` has been called.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_trainable_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_trainable_state</span><span class="p">()</span>

    <span class="c1"># Set tf.distribute.Strategy specific parameters.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_distributed_model_cache</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_distributed_function_cache</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># Clear any `_eager_losses` that was added.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_clear_losses</span><span class="p">()</span>

    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">()</span> <span class="ow">and</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
      <span class="c1"># Ensures a Session is created and configured correctly for Distribution</span>
      <span class="c1"># Strategy.</span>
      <span class="n">K</span><span class="o">.</span><span class="n">configure_and_create_distributed_session</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">)</span>
    <span class="c1"># Initialize model metric attributes.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_init_metric_attributes</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">built</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
      <span class="c1"># Model is not compilable because it does not know its number of inputs</span>
      <span class="c1"># and outputs, nor their shapes and names. We will compile after the first</span>
      <span class="c1"># time the model gets called on training data.</span>
      <span class="k">return</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_is_compiled</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">_keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;compile&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Prepare list of loss functions, same size of model outputs.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">loss_functions</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">prepare_loss_functions</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_names</span><span class="p">)</span>

    <span class="n">target_tensors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_target_tensor_for_compile</span><span class="p">(</span><span class="n">target_tensors</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">o</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_names</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">loss_functions</span><span class="p">,</span> <span class="n">target_tensors</span><span class="p">):</span>
      <span class="n">endpoint</span> <span class="o">=</span> <span class="n">_TrainingEndpoint</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
      <span class="n">endpoint</span><span class="o">.</span><span class="n">create_training_target</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">run_eagerly</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">endpoint</span><span class="p">)</span>

    <span class="c1"># Prepare list loss weights, same size of model outputs.</span>
    <span class="n">training_utils</span><span class="o">.</span><span class="n">prepare_loss_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">,</span> <span class="n">loss_weights</span><span class="p">)</span>

    <span class="c1"># Initialization for Eager mode execution.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_compile_eagerly</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">weighted_metrics</span><span class="p">,</span> <span class="n">sample_weight_mode</span><span class="p">)</span>
      <span class="k">return</span>

    <span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">get_graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="c1"># Save all metric attributes per output of the model.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_cache_output_metric_attributes</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">weighted_metrics</span><span class="p">)</span>

      <span class="c1"># Set metric attributes on model.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_set_metric_attributes</span><span class="p">()</span>

      <span class="c1"># Invoke metric functions (unweighted) for all the outputs.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_handle_metrics</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span>
          <span class="n">targets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_targets</span><span class="p">,</span>
          <span class="n">skip_target_masks</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_prepare_skip_target_masks</span><span class="p">(),</span>
          <span class="n">masks</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_prepare_output_masks</span><span class="p">())</span>

      <span class="c1"># Prepare sample weight modes. List with the same length as model outputs.</span>
      <span class="n">training_utils</span><span class="o">.</span><span class="n">prepare_sample_weight_modes</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">,</span> <span class="n">sample_weight_mode</span><span class="p">)</span>

      <span class="c1"># Creates the model loss and weighted metrics sub-graphs.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_compile_weights_loss_and_weighted_metrics</span><span class="p">()</span>

      <span class="c1"># Functions for train, test and predict will</span>
      <span class="c1"># be compiled lazily when required.</span>
      <span class="c1"># This saves time when the user is not using all functions.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_function_kwargs</span> <span class="o">=</span> <span class="n">kwargs</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">test_function</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">predict_function</span> <span class="o">=</span> <span class="kc">None</span>

      <span class="c1"># Collected trainable weights, sorted in topological order.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_collected_trainable_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unique_trainable_weights</span>

      <span class="c1"># Validate all variables were correctly created in distribution scope.</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compile_distribution</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">variables</span><span class="p">:</span>
          <span class="n">strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span>
          <span class="k">if</span> <span class="ow">not</span> <span class="n">strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">variable_created_in_scope</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;Variable (</span><span class="si">%s</span><span class="s1">) was not created in the distribution strategy &#39;</span>
                <span class="s1">&#39;scope of (</span><span class="si">%s</span><span class="s1">). It is most likely due to not all layers or &#39;</span>
                <span class="s1">&#39;the model or optimizer being created outside the distribution &#39;</span>
                <span class="s1">&#39;strategy scope. Try to make sure your code looks similar &#39;</span>
                <span class="s1">&#39;to the following.</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;with strategy.scope():</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;  model=_create_model()</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;  model.compile(...)&#39;</span><span class="o">%</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">strategy</span><span class="p">))</span>

  <span class="nd">@trackable</span><span class="o">.</span><span class="n">no_automatic_dependency_tracking</span>
  <span class="k">def</span> <span class="nf">_init_distributed_function_cache_if_not_compiled</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_distributed_function_cache&#39;</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_distributed_function_cache</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the model&#39;s metrics added using `compile`, `add_metric` APIs.&quot;&quot;&quot;</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_compiled</span><span class="p">:</span>
      <span class="n">metrics</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compile_metric_functions</span>
    <span class="n">metrics</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_metrics</span><span class="p">)</span>
    <span class="n">metrics</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">_get_metrics_from_layers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_layers</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">metrics</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">metrics_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the model&#39;s display labels for all outputs.&quot;&quot;&quot;</span>
    <span class="n">metrics_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_compiled</span><span class="p">:</span>
      <span class="c1"># Add output loss metric names to the metric names list.</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">metrics_names</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span>
            <span class="n">e</span><span class="o">.</span><span class="n">loss_name</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">e</span><span class="o">.</span><span class="n">should_skip_target</span><span class="p">()</span>
        <span class="p">])</span>

      <span class="c1"># Add compile metrics/weighted metrics&#39; names to the metric names list.</span>
      <span class="n">metrics_names</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">m</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compile_metric_functions</span><span class="p">])</span>

    <span class="c1"># Add metric names from layers.</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
      <span class="n">metrics_names</span> <span class="o">+=</span> <span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">_metrics</span><span class="p">]</span>  <span class="c1"># pylint: disable=protected-access</span>
    <span class="n">metrics_names</span> <span class="o">+=</span> <span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metrics</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">metrics_names</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">run_eagerly</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Settable attribute indicating whether the model should run eagerly.</span>

<span class="sd">    Running eagerly means that your model will be run step by step,</span>
<span class="sd">    like Python code. Your model might run slower, but it should become easier</span>
<span class="sd">    for you to debug it by stepping into individual layer calls.</span>

<span class="sd">    By default, we will attempt to compile your model to a static graph to</span>
<span class="sd">    deliver the best execution performance.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Boolean, whether the model should run eagerly.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_eagerly</span> <span class="ow">is</span> <span class="kc">True</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;You can only set `run_eagerly=True` if eager execution &#39;</span>
                       <span class="s1">&#39;is enabled.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">dynamic</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_eagerly</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Respect `tf.config.experimental_run_functions_eagerly` unless</span>
        <span class="c1"># `run_eagerly` was explicitly passed to `compile`.</span>
        <span class="k">return</span> <span class="n">def_function</span><span class="o">.</span><span class="n">RUN_FUNCTIONS_EAGERLY</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_eagerly</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Your model contains layers that can only be &#39;</span>
                         <span class="s1">&#39;successfully run in eager execution (layers &#39;</span>
                         <span class="s1">&#39;constructed with `dynamic=True`). &#39;</span>
                         <span class="s1">&#39;You must enable eager execution with &#39;</span>
                         <span class="s1">&#39;`tf.enable_eager_execution()`.&#39;</span><span class="p">)</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_eagerly</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
        <span class="c1"># TODO(fchollet): consider using py_func to enable this.</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Your model contains layers that can only be &#39;</span>
                         <span class="s1">&#39;successfully run in eager execution (layers &#39;</span>
                         <span class="s1">&#39;constructed with `dynamic=True`). &#39;</span>
                         <span class="s1">&#39;You cannot set `run_eagerly=False`.&#39;</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">()</span>

  <span class="nd">@run_eagerly</span><span class="o">.</span><span class="n">setter</span>
  <span class="k">def</span> <span class="nf">run_eagerly</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_run_eagerly</span> <span class="o">=</span> <span class="n">value</span>

  <span class="k">def</span> <span class="nf">_select_training_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Select training loop for fit/eval/predict based on the inputs.&quot;&quot;&quot;</span>
    <span class="c1"># TODO(kaftan) or TODO(scottzhu): This check should eventually be nicely</span>
    <span class="c1">#  integrated into the data adapters in the v2 loop. We can&#39;t do this yet</span>
    <span class="c1">#  because we currently have to fall back for unhandled data types.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="n">iterator_ops</span><span class="o">.</span><span class="n">Iterator</span><span class="p">,</span>
                           <span class="n">iterator_ops</span><span class="o">.</span><span class="n">IteratorV2</span><span class="p">)):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;For performance reasons Keras `fit`, `evaluate` and&#39;</span>
                       <span class="s1">&#39;`predict` accept tf.data `Datasets` as input but not &#39;</span>
                       <span class="s1">&#39;iterators that have been manually generated from &#39;</span>
                       <span class="s1">&#39;Datasets by users. Please directly pass in the &#39;</span>
                       <span class="s1">&#39;original `Dataset` object instead of passing in &#39;</span>
                       <span class="s1">&#39;`iter(dataset)`.&#39;</span><span class="p">)</span>

    <span class="c1"># Experiment training loop with default DS path.</span>
    <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">()</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_experimental_run_tf_function</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">valid_adapter</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">select_data_adapter</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
      <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">data_failure_exception</span><span class="p">:</span>
        <span class="n">valid_adapter</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Falling back from v2 loop because of error: &#39;</span>
                        <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">data_failure_exception</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">valid_adapter</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_in_multi_worker_mode</span><span class="p">():</span>
          <span class="k">return</span> <span class="n">training_distributed</span><span class="o">.</span><span class="n">DistributionMultiWorkerTrainingLoop</span><span class="p">(</span>
              <span class="n">training_v2</span><span class="o">.</span><span class="n">Loop</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">training_v2</span><span class="o">.</span><span class="n">Loop</span><span class="p">()</span>

    <span class="c1"># Case 1: distribution strategy.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_in_multi_worker_mode</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">training_distributed</span><span class="o">.</span><span class="n">DistributionMultiWorkerTrainingLoop</span><span class="p">(</span>
            <span class="n">training_distributed</span><span class="o">.</span><span class="n">DistributionSingleWorkerTrainingLoop</span><span class="p">())</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">training_distributed</span><span class="o">.</span><span class="n">DistributionSingleWorkerTrainingLoop</span><span class="p">()</span>

    <span class="c1"># Case 2: generator-like. Input is Python generator, or Sequence object,</span>
    <span class="c1"># or a non-distributed Dataset or iterator in eager execution.</span>
    <span class="k">if</span> <span class="n">data_utils</span><span class="o">.</span><span class="n">is_generator_or_sequence</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">training_generator</span><span class="o">.</span><span class="n">GeneratorOrSequenceTrainingLoop</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">is_eager_dataset_or_iterator</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">training_generator</span><span class="o">.</span><span class="n">EagerDatasetOrIteratorTrainingLoop</span><span class="p">()</span>

    <span class="c1"># Case 3: Symbolic tensors or Numpy array-like.</span>
    <span class="c1"># This includes Datasets and iterators in graph mode (since they</span>
    <span class="c1"># generate symbolic tensors).</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">training_generator</span><span class="o">.</span><span class="n">GeneratorLikeTrainingLoop</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">training_arrays</span><span class="o">.</span><span class="n">ArrayLikeTrainingLoop</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
          <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
          <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
          <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
          <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
          <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
          <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
          <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Trains the model for a fixed number of epochs (iterations on a dataset).</span>

<span class="sd">    Arguments:</span>
<span class="sd">        x: Input data. It could be:</span>
<span class="sd">          - A Numpy array (or array-like), or a list of arrays</span>
<span class="sd">            (in case the model has multiple inputs).</span>
<span class="sd">          - A TensorFlow tensor, or a list of tensors</span>
<span class="sd">            (in case the model has multiple inputs).</span>
<span class="sd">          - A dict mapping input names to the corresponding array/tensors,</span>
<span class="sd">            if the model has named inputs.</span>
<span class="sd">          - A `tf.data` dataset. Should return a tuple</span>
<span class="sd">            of either `(inputs, targets)` or</span>
<span class="sd">            `(inputs, targets, sample_weights)`.</span>
<span class="sd">          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`</span>
<span class="sd">            or `(inputs, targets, sample weights)`.</span>
<span class="sd">        y: Target data. Like the input data `x`,</span>
<span class="sd">          it could be either Numpy array(s) or TensorFlow tensor(s).</span>
<span class="sd">          It should be consistent with `x` (you cannot have Numpy inputs and</span>
<span class="sd">          tensor targets, or inversely). If `x` is a dataset, generator,</span>
<span class="sd">          or `keras.utils.Sequence` instance, `y` should</span>
<span class="sd">          not be specified (since targets will be obtained from `x`).</span>
<span class="sd">        batch_size: Integer or `None`.</span>
<span class="sd">            Number of samples per gradient update.</span>
<span class="sd">            If unspecified, `batch_size` will default to 32.</span>
<span class="sd">            Do not specify the `batch_size` if your data is in the</span>
<span class="sd">            form of symbolic tensors, datasets,</span>
<span class="sd">            generators, or `keras.utils.Sequence` instances (since they generate</span>
<span class="sd">            batches).</span>
<span class="sd">        epochs: Integer. Number of epochs to train the model.</span>
<span class="sd">            An epoch is an iteration over the entire `x` and `y`</span>
<span class="sd">            data provided.</span>
<span class="sd">            Note that in conjunction with `initial_epoch`,</span>
<span class="sd">            `epochs` is to be understood as &quot;final epoch&quot;.</span>
<span class="sd">            The model is not trained for a number of iterations</span>
<span class="sd">            given by `epochs`, but merely until the epoch</span>
<span class="sd">            of index `epochs` is reached.</span>
<span class="sd">        verbose: 0, 1, or 2. Verbosity mode.</span>
<span class="sd">            0 = silent, 1 = progress bar, 2 = one line per epoch.</span>
<span class="sd">            Note that the progress bar is not particularly useful when</span>
<span class="sd">            logged to a file, so verbose=2 is recommended when not running</span>
<span class="sd">            interactively (eg, in a production environment).</span>
<span class="sd">        callbacks: List of `keras.callbacks.Callback` instances.</span>
<span class="sd">            List of callbacks to apply during training.</span>
<span class="sd">            See `tf.keras.callbacks`.</span>
<span class="sd">        validation_split: Float between 0 and 1.</span>
<span class="sd">            Fraction of the training data to be used as validation data.</span>
<span class="sd">            The model will set apart this fraction of the training data,</span>
<span class="sd">            will not train on it, and will evaluate</span>
<span class="sd">            the loss and any model metrics</span>
<span class="sd">            on this data at the end of each epoch.</span>
<span class="sd">            The validation data is selected from the last samples</span>
<span class="sd">            in the `x` and `y` data provided, before shuffling. This argument is</span>
<span class="sd">            not supported when `x` is a dataset, generator or</span>
<span class="sd">           `keras.utils.Sequence` instance.</span>
<span class="sd">        validation_data: Data on which to evaluate</span>
<span class="sd">            the loss and any model metrics at the end of each epoch.</span>
<span class="sd">            The model will not be trained on this data.</span>
<span class="sd">            `validation_data` will override `validation_split`.</span>
<span class="sd">            `validation_data` could be:</span>
<span class="sd">              - tuple `(x_val, y_val)` of Numpy arrays or tensors</span>
<span class="sd">              - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays</span>
<span class="sd">              - dataset</span>
<span class="sd">            For the first two cases, `batch_size` must be provided.</span>
<span class="sd">            For the last case, `validation_steps` must be provided.</span>
<span class="sd">        shuffle: Boolean (whether to shuffle the training data</span>
<span class="sd">            before each epoch) or str (for &#39;batch&#39;).</span>
<span class="sd">            &#39;batch&#39; is a special option for dealing with the</span>
<span class="sd">            limitations of HDF5 data; it shuffles in batch-sized chunks.</span>
<span class="sd">            Has no effect when `steps_per_epoch` is not `None`.</span>
<span class="sd">        class_weight: Optional dictionary mapping class indices (integers)</span>
<span class="sd">            to a weight (float) value, used for weighting the loss function</span>
<span class="sd">            (during training only).</span>
<span class="sd">            This can be useful to tell the model to</span>
<span class="sd">            &quot;pay more attention&quot; to samples from</span>
<span class="sd">            an under-represented class.</span>
<span class="sd">        sample_weight: Optional Numpy array of weights for</span>
<span class="sd">            the training samples, used for weighting the loss function</span>
<span class="sd">            (during training only). You can either pass a flat (1D)</span>
<span class="sd">            Numpy array with the same length as the input samples</span>
<span class="sd">            (1:1 mapping between weights and samples),</span>
<span class="sd">            or in the case of temporal data,</span>
<span class="sd">            you can pass a 2D array with shape</span>
<span class="sd">            `(samples, sequence_length)`,</span>
<span class="sd">            to apply a different weight to every timestep of every sample.</span>
<span class="sd">            In this case you should make sure to specify</span>
<span class="sd">            `sample_weight_mode=&quot;temporal&quot;` in `compile()`. This argument is not</span>
<span class="sd">            supported when `x` is a dataset, generator, or</span>
<span class="sd">           `keras.utils.Sequence` instance, instead provide the sample_weights</span>
<span class="sd">            as the third element of `x`.</span>
<span class="sd">        initial_epoch: Integer.</span>
<span class="sd">            Epoch at which to start training</span>
<span class="sd">            (useful for resuming a previous training run).</span>
<span class="sd">        steps_per_epoch: Integer or `None`.</span>
<span class="sd">            Total number of steps (batches of samples)</span>
<span class="sd">            before declaring one epoch finished and starting the</span>
<span class="sd">            next epoch. When training with input tensors such as</span>
<span class="sd">            TensorFlow data tensors, the default `None` is equal to</span>
<span class="sd">            the number of samples in your dataset divided by</span>
<span class="sd">            the batch size, or 1 if that cannot be determined. If x is a</span>
<span class="sd">            `tf.data` dataset, and &#39;steps_per_epoch&#39;</span>
<span class="sd">            is None, the epoch will run until the input dataset is exhausted.</span>
<span class="sd">            This argument is not supported with array inputs.</span>
<span class="sd">        validation_steps: Only relevant if `validation_data` is provided and</span>
<span class="sd">            is a `tf.data` dataset. Total number of steps (batches of</span>
<span class="sd">            samples) to draw before stopping when performing validation</span>
<span class="sd">            at the end of every epoch. If validation_data is a `tf.data` dataset</span>
<span class="sd">            and &#39;validation_steps&#39; is None, validation</span>
<span class="sd">            will run until the `validation_data` dataset is exhausted.</span>
<span class="sd">        validation_freq: Only relevant if validation data is provided. Integer</span>
<span class="sd">            or `collections_abc.Container` instance (e.g. list, tuple, etc.).</span>
<span class="sd">            If an integer, specifies how many training epochs to run before a</span>
<span class="sd">            new validation run is performed, e.g. `validation_freq=2` runs</span>
<span class="sd">            validation every 2 epochs. If a Container, specifies the epochs on</span>
<span class="sd">            which to run validation, e.g. `validation_freq=[1, 2, 10]` runs</span>
<span class="sd">            validation at the end of the 1st, 2nd, and 10th epochs.</span>
<span class="sd">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>
<span class="sd">            input only. Maximum size for the generator queue.</span>
<span class="sd">            If unspecified, `max_queue_size` will default to 10.</span>
<span class="sd">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>
<span class="sd">            only. Maximum number of processes to spin up</span>
<span class="sd">            when using process-based threading. If unspecified, `workers`</span>
<span class="sd">            will default to 1. If 0, will execute the generator on the main</span>
<span class="sd">            thread.</span>
<span class="sd">        use_multiprocessing: Boolean. Used for generator or</span>
<span class="sd">            `keras.utils.Sequence` input only. If `True`, use process-based</span>
<span class="sd">            threading. If unspecified, `use_multiprocessing` will default to</span>
<span class="sd">            `False`. Note that because this implementation relies on</span>
<span class="sd">            multiprocessing, you should not pass non-picklable arguments to</span>
<span class="sd">            the generator as they can&#39;t be passed easily to children processes.</span>
<span class="sd">        **kwargs: Used for backwards compatibility.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `History` object. Its `History.history` attribute is</span>
<span class="sd">        a record of training loss values and metrics values</span>
<span class="sd">        at successive epochs, as well as validation loss values</span>
<span class="sd">        and validation metrics values (if applicable).</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: If the model was never compiled.</span>
<span class="sd">        ValueError: In case of mismatch between the provided input data</span>
<span class="sd">            and what the model expects.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># Legacy support</span>
    <span class="k">if</span> <span class="s1">&#39;nb_epoch&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
          <span class="s1">&#39;The `nb_epoch` argument in `fit` has been renamed `epochs`.&#39;</span><span class="p">)</span>
      <span class="n">epochs</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;nb_epoch&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Unrecognized keyword arguments: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">kwargs</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span>

    <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_training_loop</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">func</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
        <span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span><span class="p">,</span>
        <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
        <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span>
        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>
        <span class="n">validation_steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>
        <span class="n">validation_freq</span><span class="o">=</span><span class="n">validation_freq</span><span class="p">,</span>
        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>
        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>
        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
               <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the loss value &amp; metrics values for the model in test mode.</span>

<span class="sd">    Computation is done in batches.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        x: Input data. It could be:</span>
<span class="sd">          - A Numpy array (or array-like), or a list of arrays</span>
<span class="sd">            (in case the model has multiple inputs).</span>
<span class="sd">          - A TensorFlow tensor, or a list of tensors</span>
<span class="sd">            (in case the model has multiple inputs).</span>
<span class="sd">          - A dict mapping input names to the corresponding array/tensors,</span>
<span class="sd">            if the model has named inputs.</span>
<span class="sd">          - A `tf.data` dataset.</span>
<span class="sd">          - A generator or `keras.utils.Sequence` instance.</span>
<span class="sd">        y: Target data. Like the input data `x`,</span>
<span class="sd">          it could be either Numpy array(s) or TensorFlow tensor(s).</span>
<span class="sd">          It should be consistent with `x` (you cannot have Numpy inputs and</span>
<span class="sd">          tensor targets, or inversely).</span>
<span class="sd">          If `x` is a dataset, generator or</span>
<span class="sd">          `keras.utils.Sequence` instance, `y` should not be specified (since</span>
<span class="sd">          targets will be obtained from the iterator/dataset).</span>
<span class="sd">        batch_size: Integer or `None`.</span>
<span class="sd">            Number of samples per gradient update.</span>
<span class="sd">            If unspecified, `batch_size` will default to 32.</span>
<span class="sd">            Do not specify the `batch_size` is your data is in the</span>
<span class="sd">            form of symbolic tensors, dataset,</span>
<span class="sd">            generators, or `keras.utils.Sequence` instances (since they generate</span>
<span class="sd">            batches).</span>
<span class="sd">        verbose: 0 or 1. Verbosity mode.</span>
<span class="sd">            0 = silent, 1 = progress bar.</span>
<span class="sd">        sample_weight: Optional Numpy array of weights for</span>
<span class="sd">            the test samples, used for weighting the loss function.</span>
<span class="sd">            You can either pass a flat (1D)</span>
<span class="sd">            Numpy array with the same length as the input samples</span>
<span class="sd">            (1:1 mapping between weights and samples),</span>
<span class="sd">            or in the case of temporal data,</span>
<span class="sd">            you can pass a 2D array with shape</span>
<span class="sd">            `(samples, sequence_length)`,</span>
<span class="sd">            to apply a different weight to every timestep of every sample.</span>
<span class="sd">            In this case you should make sure to specify</span>
<span class="sd">            `sample_weight_mode=&quot;temporal&quot;` in `compile()`. This argument is not</span>
<span class="sd">            supported when `x` is a dataset, instead pass</span>
<span class="sd">            sample weights as the third element of `x`.</span>
<span class="sd">        steps: Integer or `None`.</span>
<span class="sd">            Total number of steps (batches of samples)</span>
<span class="sd">            before declaring the evaluation round finished.</span>
<span class="sd">            Ignored with the default value of `None`.</span>
<span class="sd">            If x is a `tf.data` dataset and `steps` is</span>
<span class="sd">            None, &#39;evaluate&#39; will run until the dataset is exhausted.</span>
<span class="sd">            This argument is not supported with array inputs.</span>
<span class="sd">        callbacks: List of `keras.callbacks.Callback` instances.</span>
<span class="sd">            List of callbacks to apply during evaluation.</span>
<span class="sd">            See [callbacks](/api_docs/python/tf/keras/callbacks).</span>
<span class="sd">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>
<span class="sd">            input only. Maximum size for the generator queue.</span>
<span class="sd">            If unspecified, `max_queue_size` will default to 10.</span>
<span class="sd">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>
<span class="sd">            only. Maximum number of processes to spin up when using</span>
<span class="sd">            process-based threading. If unspecified, `workers` will default</span>
<span class="sd">            to 1. If 0, will execute the generator on the main thread.</span>
<span class="sd">        use_multiprocessing: Boolean. Used for generator or</span>
<span class="sd">            `keras.utils.Sequence` input only. If `True`, use process-based</span>
<span class="sd">            threading. If unspecified, `use_multiprocessing` will default to</span>
<span class="sd">            `False`. Note that because this implementation relies on</span>
<span class="sd">            multiprocessing, you should not pass non-picklable arguments to</span>
<span class="sd">            the generator as they can&#39;t be passed easily to children processes.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Scalar test loss (if the model has a single output and no metrics)</span>
<span class="sd">        or list of scalars (if the model has multiple outputs</span>
<span class="sd">        and/or metrics). The attribute `model.metrics_names` will give you</span>
<span class="sd">        the display labels for the scalar outputs.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: in case of invalid arguments.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span>

    <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_training_loop</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">func</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>
        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>
        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
              <span class="n">x</span><span class="p">,</span>
              <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
              <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
              <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
              <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generates output predictions for the input samples.</span>

<span class="sd">    Computation is done in batches.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        x: Input samples. It could be:</span>
<span class="sd">          - A Numpy array (or array-like), or a list of arrays</span>
<span class="sd">            (in case the model has multiple inputs).</span>
<span class="sd">          - A TensorFlow tensor, or a list of tensors</span>
<span class="sd">            (in case the model has multiple inputs).</span>
<span class="sd">          - A `tf.data` dataset.</span>
<span class="sd">          - A generator or `keras.utils.Sequence` instance.</span>
<span class="sd">        batch_size: Integer or `None`.</span>
<span class="sd">            Number of samples per gradient update.</span>
<span class="sd">            If unspecified, `batch_size` will default to 32.</span>
<span class="sd">            Do not specify the `batch_size` is your data is in the</span>
<span class="sd">            form of symbolic tensors, dataset,</span>
<span class="sd">            generators, or `keras.utils.Sequence` instances (since they generate</span>
<span class="sd">            batches).</span>
<span class="sd">        verbose: Verbosity mode, 0 or 1.</span>
<span class="sd">        steps: Total number of steps (batches of samples)</span>
<span class="sd">            before declaring the prediction round finished.</span>
<span class="sd">            Ignored with the default value of `None`. If x is a `tf.data`</span>
<span class="sd">            dataset and `steps` is None, `predict` will</span>
<span class="sd">            run until the input dataset is exhausted.</span>
<span class="sd">        callbacks: List of `keras.callbacks.Callback` instances.</span>
<span class="sd">            List of callbacks to apply during prediction.</span>
<span class="sd">            See [callbacks](/api_docs/python/tf/keras/callbacks).</span>
<span class="sd">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>
<span class="sd">            input only. Maximum size for the generator queue.</span>
<span class="sd">            If unspecified, `max_queue_size` will default to 10.</span>
<span class="sd">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>
<span class="sd">            only. Maximum number of processes to spin up when using</span>
<span class="sd">            process-based threading. If unspecified, `workers` will default</span>
<span class="sd">            to 1. If 0, will execute the generator on the main thread.</span>
<span class="sd">        use_multiprocessing: Boolean. Used for generator or</span>
<span class="sd">            `keras.utils.Sequence` input only. If `True`, use process-based</span>
<span class="sd">            threading. If unspecified, `use_multiprocessing` will default to</span>
<span class="sd">            `False`. Note that because this implementation relies on</span>
<span class="sd">            multiprocessing, you should not pass non-picklable arguments to</span>
<span class="sd">            the generator as they can&#39;t be passed easily to children processes.</span>


<span class="sd">    Returns:</span>
<span class="sd">        Numpy array(s) of predictions.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: In case of mismatch between the provided</span>
<span class="sd">            input data and the model&#39;s expectations,</span>
<span class="sd">            or in case a stateful model receives a number of samples</span>
<span class="sd">            that is not a multiple of the batch size.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span>

    <span class="n">func</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_training_loop</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">func</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>
        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>
        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">reset_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Resets the state of metrics.&quot;&quot;&quot;</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_training_eval_metrics</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
      <span class="n">m</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>

    <span class="c1"># Reset metrics on all the distributed (cloned) models.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">:</span>
      <span class="n">distributed_training_utils</span><span class="o">.</span><span class="n">_reset_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

  <span class="k">def</span> <span class="nf">train_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                     <span class="n">x</span><span class="p">,</span>
                     <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Runs a single gradient update on a single batch of data.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        x: Input data. It could be:</span>
<span class="sd">          - A Numpy array (or array-like), or a list of arrays</span>
<span class="sd">              (in case the model has multiple inputs).</span>
<span class="sd">          - A TensorFlow tensor, or a list of tensors</span>
<span class="sd">              (in case the model has multiple inputs).</span>
<span class="sd">          - A dict mapping input names to the corresponding array/tensors,</span>
<span class="sd">              if the model has named inputs.</span>
<span class="sd">          - A `tf.data` dataset.</span>
<span class="sd">        y: Target data. Like the input data `x`, it could be either Numpy</span>
<span class="sd">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>
<span class="sd">          (you cannot have Numpy inputs and tensor targets, or inversely). If</span>
<span class="sd">          `x` is a dataset, `y` should not be specified</span>
<span class="sd">          (since targets will be obtained from the iterator).</span>
<span class="sd">        sample_weight: Optional array of the same length as x, containing</span>
<span class="sd">          weights to apply to the model&#39;s loss for each sample. In the case of</span>
<span class="sd">          temporal data, you can pass a 2D array with shape (samples,</span>
<span class="sd">          sequence_length), to apply a different weight to every timestep of</span>
<span class="sd">          every sample. In this case you should make sure to specify</span>
<span class="sd">          sample_weight_mode=&quot;temporal&quot; in compile(). This argument is not</span>
<span class="sd">          supported when `x` is a dataset.</span>
<span class="sd">        class_weight: Optional dictionary mapping class indices (integers) to a</span>
<span class="sd">          weight (float) to apply to the model&#39;s loss for the samples from this</span>
<span class="sd">          class during training. This can be useful to tell the model to &quot;pay</span>
<span class="sd">          more attention&quot; to samples from an under-represented class.</span>
<span class="sd">        reset_metrics: If `True`, the metrics returned will be only for this</span>
<span class="sd">          batch. If `False`, the metrics will be statefully accumulated across</span>
<span class="sd">          batches.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Scalar training loss</span>
<span class="sd">        (if the model has a single output and no metrics)</span>
<span class="sd">        or list of scalars (if the model has multiple outputs</span>
<span class="sd">        and/or metrics). The attribute `model.metrics_names` will give you</span>
<span class="sd">        the display labels for the scalar outputs.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: In case of invalid user-provided arguments.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;train_on_batch&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_experimental_run_tf_function</span><span class="p">:</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">training_v2_utils</span><span class="o">.</span><span class="n">train_on_batch</span><span class="p">(</span>
          <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
          <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span> <span class="n">reset_metrics</span><span class="o">=</span><span class="n">reset_metrics</span><span class="p">)</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;total_loss&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;output_losses&#39;</span><span class="p">]</span> <span class="o">+</span>
                 <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;metrics&#39;</span><span class="p">])</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">training_v2_utils</span><span class="o">.</span><span class="n">_non_none_constant_value</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>  <span class="c1"># pylint: disable=protected-access</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="k">return</span> <span class="n">outputs</span>

    <span class="c1"># If at this point we are in the replica context, then it is okay to execute</span>
    <span class="c1"># the Eager code path.  The expected way to get here is to call `fit` that</span>
    <span class="c1"># calls `train_on_batch` on each replica.</span>
    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span> <span class="ow">and</span>
        <span class="n">distribution_strategy_context</span><span class="o">.</span><span class="n">in_cross_replica_context</span><span class="p">()):</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;`train_on_batch` is not supported for models &#39;</span>
                                <span class="s1">&#39;distributed with tf.distribute.Strategy.&#39;</span><span class="p">)</span>
    <span class="c1"># Validate and standardize user data.</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_standardize_user_data</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>
        <span class="n">extract_tensors_from_dataset</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># If `self._distribution_strategy` is True, then we are in a replica context</span>
    <span class="c1"># at this point because of the check above.  `train_on_batch` is being run</span>
    <span class="c1"># for each replica by `self._distribution_strategy` and the same code path</span>
    <span class="c1"># as Eager is expected to be taken.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">:</span>
      <span class="n">output_dict</span> <span class="o">=</span> <span class="n">training_eager</span><span class="o">.</span><span class="n">train_on_batch</span><span class="p">(</span>
          <span class="bp">self</span><span class="p">,</span>
          <span class="n">x</span><span class="p">,</span>
          <span class="n">y</span><span class="p">,</span>
          <span class="n">sample_weights</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">,</span>
          <span class="n">output_loss_metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_loss_metrics</span><span class="p">)</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">output_dict</span><span class="p">[</span><span class="s1">&#39;total_loss&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">output_dict</span><span class="p">[</span><span class="s1">&#39;output_losses&#39;</span><span class="p">]</span>
                 <span class="o">+</span> <span class="n">output_dict</span><span class="p">[</span><span class="s1">&#39;metrics&#39;</span><span class="p">])</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">training_v2_utils</span><span class="o">.</span><span class="n">_non_none_constant_value</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>  <span class="c1"># pylint: disable=protected-access</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">ModelInputs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
      <span class="n">ins</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="ow">or</span> <span class="p">[])</span> <span class="o">+</span> <span class="p">(</span><span class="n">sample_weights</span> <span class="ow">or</span> <span class="p">[])</span>

      <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">symbolic_learning_phase</span><span class="p">(),</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">ins</span> <span class="o">+=</span> <span class="p">[</span><span class="kc">True</span><span class="p">]</span>  <span class="c1"># Add learning phase value.</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">_update_sample_weight_modes</span><span class="p">(</span><span class="n">sample_weights</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_make_train_function</span><span class="p">()</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">ins</span><span class="p">)</span>  <span class="c1"># pylint: disable=not-callable</span>

    <span class="k">if</span> <span class="n">reset_metrics</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">outputs</span>

  <span class="k">def</span> <span class="nf">test_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Test the model on a single batch of samples.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        x: Input data. It could be:</span>
<span class="sd">          - A Numpy array (or array-like), or a list of arrays</span>
<span class="sd">            (in case the model has multiple inputs).</span>
<span class="sd">          - A TensorFlow tensor, or a list of tensors</span>
<span class="sd">            (in case the model has multiple inputs).</span>
<span class="sd">          - A dict mapping input names to the corresponding array/tensors,</span>
<span class="sd">            if the model has named inputs.</span>
<span class="sd">          - A `tf.data` dataset.</span>
<span class="sd">        y: Target data. Like the input data `x`,</span>
<span class="sd">          it could be either Numpy array(s) or TensorFlow tensor(s).</span>
<span class="sd">          It should be consistent with `x` (you cannot have Numpy inputs and</span>
<span class="sd">          tensor targets, or inversely). If `x` is a dataset `y` should</span>
<span class="sd">          not be specified (since targets will be obtained from the iterator).</span>
<span class="sd">        sample_weight: Optional array of the same length as x, containing</span>
<span class="sd">            weights to apply to the model&#39;s loss for each sample.</span>
<span class="sd">            In the case of temporal data, you can pass a 2D array</span>
<span class="sd">            with shape (samples, sequence_length),</span>
<span class="sd">            to apply a different weight to every timestep of every sample.</span>
<span class="sd">            In this case you should make sure to specify</span>
<span class="sd">            sample_weight_mode=&quot;temporal&quot; in compile(). This argument is not</span>
<span class="sd">            supported when `x` is a dataset.</span>
<span class="sd">        reset_metrics: If `True`, the metrics returned will be only for this</span>
<span class="sd">          batch. If `False`, the metrics will be statefully accumulated across</span>
<span class="sd">          batches.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Scalar test loss (if the model has a single output and no metrics)</span>
<span class="sd">        or list of scalars (if the model has multiple outputs</span>
<span class="sd">        and/or metrics). The attribute `model.metrics_names` will give you</span>
<span class="sd">        the display labels for the scalar outputs.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: In case of invalid user-provided arguments.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;test_on_batch&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_experimental_run_tf_function</span><span class="p">:</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">training_v2_utils</span><span class="o">.</span><span class="n">test_on_batch</span><span class="p">(</span>
          <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
          <span class="n">reset_metrics</span><span class="o">=</span><span class="n">reset_metrics</span><span class="p">)</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;total_loss&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;output_losses&#39;</span><span class="p">]</span> <span class="o">+</span>
                 <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;metrics&#39;</span><span class="p">])</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">training_v2_utils</span><span class="o">.</span><span class="n">_non_none_constant_value</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>  <span class="c1"># pylint: disable=protected-access</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span> <span class="ow">and</span>
        <span class="n">distribution_strategy_context</span><span class="o">.</span><span class="n">in_cross_replica_context</span><span class="p">()):</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;`test_on_batch` is not supported for models &#39;</span>
                                <span class="s1">&#39;distributed with tf.distribute.Strategy.&#39;</span><span class="p">)</span>
    <span class="c1"># Validate and standardize user data.</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_standardize_user_data</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">extract_tensors_from_dataset</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># If `self._distribution_strategy` is True, then we are in a replica context</span>
    <span class="c1"># at this point.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">:</span>
      <span class="n">output_dict</span> <span class="o">=</span> <span class="n">training_eager</span><span class="o">.</span><span class="n">test_on_batch</span><span class="p">(</span>
          <span class="bp">self</span><span class="p">,</span>
          <span class="n">x</span><span class="p">,</span>
          <span class="n">y</span><span class="p">,</span>
          <span class="n">sample_weights</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">,</span>
          <span class="n">output_loss_metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_loss_metrics</span><span class="p">)</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">output_dict</span><span class="p">[</span><span class="s1">&#39;total_loss&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">output_dict</span><span class="p">[</span><span class="s1">&#39;output_losses&#39;</span><span class="p">]</span>
                 <span class="o">+</span> <span class="n">output_dict</span><span class="p">[</span><span class="s1">&#39;metrics&#39;</span><span class="p">])</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">training_v2_utils</span><span class="o">.</span><span class="n">_non_none_constant_value</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>  <span class="c1"># pylint: disable=protected-access</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">ModelInputs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="ow">or</span> <span class="p">[])</span> <span class="o">+</span> <span class="p">(</span><span class="n">sample_weights</span> <span class="ow">or</span> <span class="p">[])</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">_update_sample_weight_modes</span><span class="p">(</span><span class="n">sample_weights</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_make_test_function</span><span class="p">()</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>  <span class="c1"># pylint: disable=not-callable</span>

    <span class="k">if</span> <span class="n">reset_metrics</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">outputs</span>

  <span class="k">def</span> <span class="nf">predict_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns predictions for a single batch of samples.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        x: Input data. It could be:</span>
<span class="sd">          - A Numpy array (or array-like), or a list of arrays</span>
<span class="sd">            (in case the model has multiple inputs).</span>
<span class="sd">          - A TensorFlow tensor, or a list of tensors</span>
<span class="sd">            (in case the model has multiple inputs).</span>
<span class="sd">          - A `tf.data` dataset.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Numpy array(s) of predictions.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: In case of mismatch between given number of inputs and</span>
<span class="sd">          expectations of the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;predict_on_batch&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_experimental_run_tf_function</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">training_v2_utils</span><span class="o">.</span><span class="n">predict_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span> <span class="ow">and</span>
        <span class="n">distribution_strategy_context</span><span class="o">.</span><span class="n">in_cross_replica_context</span><span class="p">()):</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
          <span class="s1">&#39;`predict_on_batch` is not supported for models distributed with&#39;</span>
          <span class="s1">&#39; tf.distribute.Strategy.&#39;</span><span class="p">)</span>
    <span class="c1"># Validate and standardize user data.</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_standardize_user_data</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">extract_tensors_from_dataset</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># If `self._distribution_strategy` is True, then we are in a replica context</span>
    <span class="c1"># at this point.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">:</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">cast_if_floating_dtype</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">collections_abc</span><span class="o">.</span><span class="n">Sequence</span><span class="p">):</span>
        <span class="c1"># Unwrap lists with only one input, as we do when training on batch</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
          <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

      <span class="k">return</span> <span class="bp">self</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>  <span class="c1"># pylint: disable=not-callable</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_make_predict_function</span><span class="p">()</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_function</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">outputs</span>

  <span class="k">def</span> <span class="nf">fit_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                    <span class="n">generator</span><span class="p">,</span>
                    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Fits the model on data yielded batch-by-batch by a Python generator.</span>

<span class="sd">    The generator is run in parallel to the model, for efficiency.</span>
<span class="sd">    For instance, this allows you to do real-time data augmentation</span>
<span class="sd">    on images on CPU in parallel to training your model on GPU.</span>

<span class="sd">    The use of `keras.utils.Sequence` guarantees the ordering</span>
<span class="sd">    and guarantees the single use of every input per epoch when</span>
<span class="sd">    using `use_multiprocessing=True`.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        generator: A generator or an instance of `Sequence`</span>
<span class="sd">          (`keras.utils.Sequence`)</span>
<span class="sd">            object in order to avoid duplicate data</span>
<span class="sd">            when using multiprocessing.</span>
<span class="sd">            The output of the generator must be either</span>
<span class="sd">            - a tuple `(inputs, targets)`</span>
<span class="sd">            - a tuple `(inputs, targets, sample_weights)`.</span>
<span class="sd">            This tuple (a single output of the generator) makes a single batch.</span>
<span class="sd">            Therefore, all arrays in this tuple must have the same length (equal</span>
<span class="sd">            to the size of this batch). Different batches may have different</span>
<span class="sd">              sizes.</span>
<span class="sd">            For example, the last batch of the epoch is commonly smaller than</span>
<span class="sd">              the</span>
<span class="sd">            others, if the size of the dataset is not divisible by the batch</span>
<span class="sd">              size.</span>
<span class="sd">            The generator is expected to loop over its data</span>
<span class="sd">            indefinitely. An epoch finishes when `steps_per_epoch`</span>
<span class="sd">            batches have been seen by the model.</span>
<span class="sd">        steps_per_epoch: Total number of steps (batches of samples)</span>
<span class="sd">            to yield from `generator` before declaring one epoch</span>
<span class="sd">            finished and starting the next epoch. It should typically</span>
<span class="sd">            be equal to the number of samples of your dataset</span>
<span class="sd">            divided by the batch size.</span>
<span class="sd">            Optional for `Sequence`: if unspecified, will use</span>
<span class="sd">            the `len(generator)` as a number of steps.</span>
<span class="sd">        epochs: Integer, total number of iterations on the data.</span>
<span class="sd">        verbose: Verbosity mode, 0, 1, or 2.</span>
<span class="sd">        callbacks: List of callbacks to be called during training.</span>
<span class="sd">        validation_data: This can be either</span>
<span class="sd">            - a generator for the validation data</span>
<span class="sd">            - a tuple (inputs, targets)</span>
<span class="sd">            - a tuple (inputs, targets, sample_weights).</span>
<span class="sd">        validation_steps: Only relevant if `validation_data`</span>
<span class="sd">            is a generator. Total number of steps (batches of samples)</span>
<span class="sd">            to yield from `generator` before stopping.</span>
<span class="sd">            Optional for `Sequence`: if unspecified, will use</span>
<span class="sd">            the `len(validation_data)` as a number of steps.</span>
<span class="sd">        validation_freq: Only relevant if validation data is provided. Integer</span>
<span class="sd">            or `collections_abc.Container` instance (e.g. list, tuple, etc.).</span>
<span class="sd">            If an integer, specifies how many training epochs to run before a</span>
<span class="sd">            new validation run is performed, e.g. `validation_freq=2` runs</span>
<span class="sd">            validation every 2 epochs. If a Container, specifies the epochs on</span>
<span class="sd">            which to run validation, e.g. `validation_freq=[1, 2, 10]` runs</span>
<span class="sd">            validation at the end of the 1st, 2nd, and 10th epochs.</span>
<span class="sd">        class_weight: Dictionary mapping class indices to a weight</span>
<span class="sd">            for the class.</span>
<span class="sd">        max_queue_size: Integer. Maximum size for the generator queue.</span>
<span class="sd">            If unspecified, `max_queue_size` will default to 10.</span>
<span class="sd">        workers: Integer. Maximum number of processes to spin up</span>
<span class="sd">            when using process-based threading.</span>
<span class="sd">            If unspecified, `workers` will default to 1. If 0, will</span>
<span class="sd">            execute the generator on the main thread.</span>
<span class="sd">        use_multiprocessing: Boolean.</span>
<span class="sd">            If `True`, use process-based threading.</span>
<span class="sd">            If unspecified, `use_multiprocessing` will default to `False`.</span>
<span class="sd">            Note that because this implementation relies on multiprocessing,</span>
<span class="sd">            you should not pass non-picklable arguments to the generator</span>
<span class="sd">            as they can&#39;t be passed easily to children processes.</span>
<span class="sd">        shuffle: Boolean. Whether to shuffle the order of the batches at</span>
<span class="sd">            the beginning of each epoch. Only used with instances</span>
<span class="sd">            of `Sequence` (`keras.utils.Sequence`).</span>
<span class="sd">            Has no effect when `steps_per_epoch` is not `None`.</span>
<span class="sd">        initial_epoch: Epoch at which to start training</span>
<span class="sd">            (useful for resuming a previous training run)</span>

<span class="sd">    Returns:</span>
<span class="sd">        A `History` object.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```python</span>
<span class="sd">        def generate_arrays_from_file(path):</span>
<span class="sd">            while 1:</span>
<span class="sd">                f = open(path)</span>
<span class="sd">                for line in f:</span>
<span class="sd">                    # create numpy arrays of input data</span>
<span class="sd">                    # and labels, from each line in the file</span>
<span class="sd">                    x1, x2, y = process_line(line)</span>
<span class="sd">                    yield ({&#39;input_1&#39;: x1, &#39;input_2&#39;: x2}, {&#39;output&#39;: y})</span>
<span class="sd">                f.close()</span>

<span class="sd">        model.fit_generator(generate_arrays_from_file(&#39;/my_file.txt&#39;),</span>
<span class="sd">                            steps_per_epoch=10000, epochs=10)</span>
<span class="sd">    ```</span>
<span class="sd">    Raises:</span>
<span class="sd">        ValueError: In case the generator yields data in an invalid format.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;`fit_generator` is not supported for &#39;</span>
                                <span class="s1">&#39;models compiled with tf.distribute.Strategy.&#39;</span><span class="p">)</span>
    <span class="n">_keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;fit_generator&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;fit_generator&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">training_generator</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">,</span>
        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
        <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span><span class="p">,</span>
        <span class="n">validation_steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>
        <span class="n">validation_freq</span><span class="o">=</span><span class="n">validation_freq</span><span class="p">,</span>
        <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>
        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>
        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>
        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
        <span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span>
        <span class="n">steps_name</span><span class="o">=</span><span class="s1">&#39;steps_per_epoch&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">evaluate_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                         <span class="n">generator</span><span class="p">,</span>
                         <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                         <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                         <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                         <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluates the model on a data generator.</span>

<span class="sd">    The generator should return the same kind of data</span>
<span class="sd">    as accepted by `test_on_batch`.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        generator: Generator yielding tuples (inputs, targets)</span>
<span class="sd">            or (inputs, targets, sample_weights)</span>
<span class="sd">            or an instance of `keras.utils.Sequence`</span>
<span class="sd">            object in order to avoid duplicate data</span>
<span class="sd">            when using multiprocessing.</span>
<span class="sd">        steps: Total number of steps (batches of samples)</span>
<span class="sd">            to yield from `generator` before stopping.</span>
<span class="sd">            Optional for `Sequence`: if unspecified, will use</span>
<span class="sd">            the `len(generator)` as a number of steps.</span>
<span class="sd">        callbacks: List of `keras.callbacks.Callback` instances.</span>
<span class="sd">            List of callbacks to apply during evaluation.</span>
<span class="sd">            See [callbacks](/api_docs/python/tf/keras/callbacks).</span>
<span class="sd">        max_queue_size: maximum size for the generator queue</span>
<span class="sd">        workers: Integer. Maximum number of processes to spin up</span>
<span class="sd">            when using process-based threading.</span>
<span class="sd">            If unspecified, `workers` will default to 1. If 0, will</span>
<span class="sd">            execute the generator on the main thread.</span>
<span class="sd">        use_multiprocessing: Boolean.</span>
<span class="sd">            If `True`, use process-based threading.</span>
<span class="sd">            If unspecified, `use_multiprocessing` will default to `False`.</span>
<span class="sd">            Note that because this implementation relies on multiprocessing,</span>
<span class="sd">            you should not pass non-picklable arguments to the generator</span>
<span class="sd">            as they can&#39;t be passed easily to children processes.</span>
<span class="sd">        verbose: Verbosity mode, 0 or 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Scalar test loss (if the model has a single output and no metrics)</span>
<span class="sd">        or list of scalars (if the model has multiple outputs</span>
<span class="sd">        and/or metrics). The attribute `model.metrics_names` will give you</span>
<span class="sd">        the display labels for the scalar outputs.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: in case of invalid arguments.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: In case the generator yields data in an invalid format.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;`evaluate_generator` is not supported for &#39;</span>
                                <span class="s1">&#39;models compiled with tf.distribute.Strategy.&#39;</span><span class="p">)</span>
    <span class="n">_keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;evaluate_generator&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;evaluate_generator&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">training_generator</span><span class="o">.</span><span class="n">evaluate_generator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">,</span>
        <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>
        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>
        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>
        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">predict_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                        <span class="n">generator</span><span class="p">,</span>
                        <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                        <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generates predictions for the input samples from a data generator.</span>

<span class="sd">    The generator should return the same kind of data as accepted by</span>
<span class="sd">    `predict_on_batch`.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        generator: Generator yielding batches of input samples</span>
<span class="sd">            or an instance of `keras.utils.Sequence` object in order to</span>
<span class="sd">            avoid duplicate data when using multiprocessing.</span>
<span class="sd">        steps: Total number of steps (batches of samples)</span>
<span class="sd">            to yield from `generator` before stopping.</span>
<span class="sd">            Optional for `Sequence`: if unspecified, will use</span>
<span class="sd">            the `len(generator)` as a number of steps.</span>
<span class="sd">        callbacks: List of `keras.callbacks.Callback` instances.</span>
<span class="sd">            List of callbacks to apply during prediction.</span>
<span class="sd">            See [callbacks](/api_docs/python/tf/keras/callbacks).</span>
<span class="sd">        max_queue_size: Maximum size for the generator queue.</span>
<span class="sd">        workers: Integer. Maximum number of processes to spin up</span>
<span class="sd">            when using process-based threading.</span>
<span class="sd">            If unspecified, `workers` will default to 1. If 0, will</span>
<span class="sd">            execute the generator on the main thread.</span>
<span class="sd">        use_multiprocessing: Boolean.</span>
<span class="sd">            If `True`, use process-based threading.</span>
<span class="sd">            If unspecified, `use_multiprocessing` will default to `False`.</span>
<span class="sd">            Note that because this implementation relies on multiprocessing,</span>
<span class="sd">            you should not pass non-picklable arguments to the generator</span>
<span class="sd">            as they can&#39;t be passed easily to children processes.</span>
<span class="sd">        verbose: verbosity mode, 0 or 1.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Numpy array(s) of predictions.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: In case the generator yields data in an invalid format.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;`predict_generator` is not supported for &#39;</span>
                                <span class="s1">&#39;models compiled with tf.distribute.Strategy.&#39;</span><span class="p">)</span>
    <span class="n">_keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;predict_generator&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">training_generator</span><span class="o">.</span><span class="n">predict_generator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">,</span>
        <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>
        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>
        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>
        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_check_call_args</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method_name</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Check that `call` has only one positional arg.&quot;&quot;&quot;</span>
    <span class="c1"># Always allow first arg, regardless of arg name.</span>
    <span class="n">fullargspec</span> <span class="o">=</span> <span class="n">tf_inspect</span><span class="o">.</span><span class="n">getfullargspec</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">call</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">fullargspec</span><span class="o">.</span><span class="n">defaults</span><span class="p">:</span>
      <span class="n">positional_args</span> <span class="o">=</span> <span class="n">fullargspec</span><span class="o">.</span><span class="n">args</span><span class="p">[:</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">fullargspec</span><span class="o">.</span><span class="n">defaults</span><span class="p">)]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">positional_args</span> <span class="o">=</span> <span class="n">fullargspec</span><span class="o">.</span><span class="n">args</span>
    <span class="k">if</span> <span class="s1">&#39;training&#39;</span> <span class="ow">in</span> <span class="n">positional_args</span><span class="p">:</span>
      <span class="n">positional_args</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;training&#39;</span><span class="p">)</span>

    <span class="c1"># self and first arg can be positional.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">positional_args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
      <span class="n">extra_args</span> <span class="o">=</span> <span class="n">positional_args</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s1">&#39;Models passed to `&#39;</span> <span class="o">+</span> <span class="n">method_name</span> <span class="o">+</span> <span class="s1">&#39;` can only have `training` &#39;</span>
          <span class="s1">&#39;and the first argument in `call` as positional arguments, &#39;</span>
          <span class="s1">&#39;found: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">extra_args</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_set_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets self.optimizer.</span>

<span class="sd">    Sets self.optimizer to `optimizer`, potentially wrapping it with a</span>
<span class="sd">    LossScaleOptimizer.</span>

<span class="sd">    Args:</span>
<span class="sd">      optimizer: The optimizer(s) to assign to self.optimizer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="p">[</span><span class="n">optimizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">opt</span><span class="p">)</span> <span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype_policy</span><span class="o">.</span><span class="n">loss_scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span>
        <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
                       <span class="n">loss_scale_optimizer</span><span class="o">.</span><span class="n">LossScaleOptimizer</span><span class="p">)):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;When a dtype policy with a loss scale is used, you &#39;</span>
                         <span class="s1">&#39;can only pass a single optimizer. Using policy </span><span class="si">%s</span><span class="s1"> &#39;</span>
                         <span class="s1">&#39;and got optimizers: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>
                         <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_policy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_v2</span><span class="o">.</span><span class="n">OptimizerV2</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;&quot;optimizer&quot; must be an instance of &#39;</span>
                         <span class="s1">&#39;tf.keras.optimizers.Optimizer when a dype policy &#39;</span>
                         <span class="s1">&#39;with a loss scale  used, but got: </span><span class="si">%s</span><span class="s1">. Using policy: &#39;</span>
                         <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>
                         <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_policy</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">loss_scale_optimizer</span><span class="o">.</span><span class="n">LossScaleOptimizer</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_policy</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_scale_optimizer</span><span class="o">.</span><span class="n">LossScaleOptimizer</span><span class="p">)</span> <span class="ow">and</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_policy</span><span class="o">.</span><span class="n">loss_scale</span> <span class="ow">and</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">loss_scale</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_policy</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;LossScale of LossScaleOptimizer passed to compile (</span><span class="si">%s</span><span class="s1">) &#39;</span>
                      <span class="s1">&#39;is not the same as the dtype policy</span><span class="se">\&#39;</span><span class="s1">s loss scale (</span><span class="si">%s</span><span class="s1">). &#39;</span>
                      <span class="s1">&#39;Because the dtype policy has a loss scale, you should &#39;</span>
                      <span class="s1">&#39;pass an optimizer that is not wrapped with a &#39;</span>
                      <span class="s1">&#39;LossScaleOptimizer,&#39;</span>
                      <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">,</span>
                         <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_policy</span><span class="o">.</span><span class="n">loss_scale</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">_prepare_validation_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                               <span class="n">validation_steps</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Unpack and check the validation data.&quot;&quot;&quot;</span>
    <span class="n">val_x</span><span class="p">,</span> <span class="n">val_y</span><span class="p">,</span> <span class="n">val_sample_weights</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">unpack_validation_data</span><span class="p">(</span>
        <span class="n">validation_data</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_standardize_user_data</span><span class="p">(</span>
        <span class="n">val_x</span><span class="p">,</span>
        <span class="n">val_y</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weights</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>
        <span class="n">steps_name</span><span class="o">=</span><span class="s1">&#39;validation_steps&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_validate_compile_param_for_distribution_strategy</span><span class="p">(</span>
      <span class="bp">self</span><span class="p">,</span> <span class="n">run_eagerly</span><span class="p">,</span> <span class="n">sample_weight_mode</span><span class="p">,</span> <span class="n">target_tensors</span><span class="p">,</span> <span class="n">weighted_metrics</span><span class="p">):</span>
    <span class="c1"># Validate that arguments passed by the user to `compile` are supported by</span>
    <span class="c1"># tf.distribute.Strategy.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">sample_weight_mode</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;sample_weight_mode is not supported with &#39;</span>
                                  <span class="s1">&#39;tf.distribute.Strategy.&#39;</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">weighted_metrics</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;weighted_metrics is not supported with &#39;</span>
                                  <span class="s1">&#39;tf.distribute.Strategy.&#39;</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">target_tensors</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;target_tensors is not supported with &#39;</span>
                         <span class="s1">&#39;tf.distribute.Strategy.&#39;</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">run_eagerly</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;We currently do not support enabling `run_eagerly` with &#39;</span>
            <span class="s1">&#39;distribution strategy.&#39;</span><span class="p">)</span>

      <span class="k">if</span> <span class="p">(</span><span class="n">distributed_training_utils</span><span class="o">.</span><span class="n">is_distributing_by_cloning</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="ow">and</span>
          <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">built</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;We currently do not support distribution strategy with a &#39;</span>
            <span class="s1">&#39;`Sequential` model that is created without `input_shape`/&#39;</span>
            <span class="s1">&#39;`input_dim` set in its first layer or a subclassed model.&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_process_target_tensor_for_compile</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_tensors</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span><span class="p">:</span>
      <span class="c1"># target tensor is not supported with run_eagerly. Create a list with None</span>
      <span class="c1"># as placeholder for each output.</span>
      <span class="k">return</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_names</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">target_tensors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">target_tensors</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span>
                                           <span class="n">target_tensors</span> <span class="o">==</span> <span class="p">[]):</span>  <span class="c1"># pylint: disable=g-explicit-bool-comparison</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_tensors</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_tensors</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">):</span>
          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
              <span class="s1">&#39;When passing a list as `target_tensors`, &#39;</span>
              <span class="s1">&#39;it should have one entry per model output. &#39;</span>
              <span class="s1">&#39;The model has </span><span class="si">%s</span><span class="s1"> outputs, but you passed target_tensors=</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>
              <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">),</span> <span class="n">target_tensors</span><span class="p">))</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target_tensors</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">unexpected_target_tensor_names</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">target_tensors</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_names</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">unexpected_target_tensor_names</span><span class="p">:</span>
          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
              <span class="s1">&#39;Unknown entry in `target_tensors` dictionary: &quot;</span><span class="si">{name}</span><span class="s1">&quot;. &#39;</span>
              <span class="s1">&#39;Only expected the following keys: </span><span class="si">{keys}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                  <span class="n">name</span><span class="o">=</span><span class="n">unexpected_target_tensor_names</span><span class="p">,</span>
                  <span class="n">keys</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_names</span><span class="p">)))</span>
        <span class="n">tmp_target_tensors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_names</span><span class="p">:</span>
          <span class="n">tmp_target_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_tensors</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
        <span class="n">target_tensors</span> <span class="o">=</span> <span class="n">tmp_target_tensors</span>
      <span class="k">elif</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">target_tensors</span><span class="p">):</span>
        <span class="n">target_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">target_tensors</span><span class="p">]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Expected `target_tensors` to be a list or tuple or &#39;</span>
                        <span class="s1">&#39;dict or a single tensor, but got:&#39;</span><span class="p">,</span> <span class="n">target_tensors</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># In case target tensor is empty or None, create a list with Nones</span>
      <span class="c1"># that has same length as self.output_names. With that, the None check of</span>
      <span class="c1"># target tensor can be skipped downstream.</span>
      <span class="n">target_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_names</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">target_tensors</span>

  <span class="k">def</span> <span class="nf">_compile_eagerly</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">weighted_metrics</span><span class="p">,</span> <span class="n">sample_weight_mode</span><span class="p">):</span>
    <span class="c1"># Prepare sample weight modes. List with the same length as model outputs.</span>
    <span class="n">training_utils</span><span class="o">.</span><span class="n">prepare_sample_weight_modes</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">,</span> <span class="n">sample_weight_mode</span><span class="p">)</span>
    <span class="c1"># Prepare sample weights.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_sample_weights</span><span class="p">()</span>
    <span class="c1"># Save all metric attributes per output of the model.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_cache_output_metric_attributes</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">weighted_metrics</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">total_loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># Set metric attributes on model.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_set_metric_attributes</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_collected_trainable_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unique_trainable_weights</span>

  <span class="k">def</span> <span class="nf">_update_sample_weight_modes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Updates sample weight modes based on training/eval inputs.</span>

<span class="sd">    Sample weight placeholders will be created for all or no outputs</span>
<span class="sd">    based on whether sample_weight is provided for any output.</span>

<span class="sd">    If model contains `_sample_weight_modes` we check if the input</span>
<span class="sd">    `sample_weights` corresponds to the sample weight modes.</span>
<span class="sd">      1. Set sample weight mode to be &#39;temporal&#39; for output i, if `compile`</span>
<span class="sd">        sample_weight_mode was set to `temporal` and sample weight inputs</span>
<span class="sd">        are given for one or more outputs.</span>
<span class="sd">      2. Set sample weight mode to be &#39;samplewise&#39; for output i, if `compile`</span>
<span class="sd">        sample_weight_mode was not set and sample weight inputs are given for</span>
<span class="sd">        one or more outputs.</span>
<span class="sd">      3. Reset sample weight mode to None for output i if sample weight mode</span>
<span class="sd">        was set but there is no sample weight input.</span>

<span class="sd">    Args:</span>
<span class="sd">      sample_weights: List of sample weights of the same length as model outputs</span>
<span class="sd">        or None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_compiled</span><span class="p">:</span>
      <span class="k">return</span>
    <span class="k">if</span> <span class="n">sample_weights</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">([</span><span class="n">s</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sample_weights</span><span class="p">]):</span>
      <span class="k">for</span> <span class="n">endpoint</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">:</span>
        <span class="n">endpoint</span><span class="o">.</span><span class="n">sample_weight_mode</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">endpoint</span><span class="o">.</span><span class="n">sample_weight_mode</span> <span class="ow">or</span> <span class="s1">&#39;samplewise&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">endpoint</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">:</span>
        <span class="n">endpoint</span><span class="o">.</span><span class="n">sample_weight_mode</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="k">def</span> <span class="nf">_recompile_weights_loss_and_weighted_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_compiled</span><span class="p">:</span>
      <span class="k">return</span> <span class="kc">False</span>
    <span class="n">recompile</span> <span class="o">=</span> <span class="nb">any</span><span class="p">([</span><span class="n">e</span><span class="o">.</span><span class="n">sample_weights_mismatch</span><span class="p">()</span>
                     <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">recompile</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_compile_weights_loss_and_weighted_metrics</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">recompile</span>

  <span class="nd">@trackable</span><span class="o">.</span><span class="n">no_automatic_dependency_tracking</span>
  <span class="k">def</span> <span class="nf">_compile_weights_loss_and_weighted_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compiles the model loss and weighted metric sub-graphs.</span>

<span class="sd">    This may be used to set graph tensors as sample weights (instead of creating</span>
<span class="sd">    placeholders). This functionality is necessary for</span>
<span class="sd">    `tf.keras.estimator.model_to_estimator`, which calls Keras models in a v1</span>
<span class="sd">    graph, and creates iterator tensors for inputs, targets, and sample weights.</span>

<span class="sd">    Args:</span>
<span class="sd">      sample_weights: List of tensors to use as the sample weights. Must be the</span>
<span class="sd">        same length as the number of outputs. If left as `None`, placeholders</span>
<span class="sd">        are used instead.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">get_graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">sample_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_sample_weight_modes</span><span class="p">(</span><span class="n">sample_weights</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_sample_weights</span><span class="p">(</span><span class="n">sample_weights</span><span class="p">)</span>

      <span class="n">masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_output_masks</span><span class="p">()</span>

      <span class="c1"># Compute weighted metrics.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_handle_metrics</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span>
          <span class="n">targets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_targets</span><span class="p">,</span>
          <span class="n">skip_target_masks</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_prepare_skip_target_masks</span><span class="p">(),</span>
          <span class="n">sample_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_weights</span><span class="p">,</span>
          <span class="n">masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span>
          <span class="n">return_weighted_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

      <span class="c1"># Compute total loss.</span>
      <span class="c1"># Used to keep track of the total loss value (stateless).</span>
      <span class="c1"># eg., total_loss = loss_weight_1 * output_1_loss_fn(...) +</span>
      <span class="c1">#                   loss_weight_2 * output_2_loss_fn(...) +</span>
      <span class="c1">#                   layer losses.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">total_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_total_loss</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_prepare_skip_target_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Boolean mask for whether the target in the output list should be skipped.</span>

<span class="sd">    If the loss function corresponding to a model output is None, then this</span>
<span class="sd">    output will be skipped during total loss calculation and feed targets</span>
<span class="sd">    preparation.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A boolean list for whether the corresponding target in the output list</span>
<span class="sd">      should be skipped during loss calculation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">l</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_functions</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">_prepare_output_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns masks corresponding to model outputs.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span><span class="nb">getattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;_keras_mask&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">_prepare_total_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">masks</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes total loss from loss functions.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        masks: List of mask values corresponding to each model output.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A list of loss weights of python floats.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If model run_eagerly is True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;total loss can not be computed when compiled with &#39;</span>
                      <span class="s1">&#39;run_eagerly = True.&#39;</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">mask</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">,</span> <span class="n">masks</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">endpoint</span><span class="o">.</span><span class="n">should_skip_target</span><span class="p">():</span>
          <span class="k">continue</span>
        <span class="n">y_true</span> <span class="o">=</span> <span class="n">endpoint</span><span class="o">.</span><span class="n">training_target</span><span class="o">.</span><span class="n">target</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">endpoint</span><span class="o">.</span><span class="n">output</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">endpoint</span><span class="o">.</span><span class="n">loss_fn</span>
        <span class="n">loss_weight</span> <span class="o">=</span> <span class="n">endpoint</span><span class="o">.</span><span class="n">loss_weight</span>
        <span class="n">loss_name</span> <span class="o">=</span> <span class="n">endpoint</span><span class="o">.</span><span class="n">loss_name</span><span class="p">()</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">endpoint</span><span class="o">.</span><span class="n">sample_weight</span>

        <span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">loss_name</span><span class="p">):</span>
          <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="c1"># Update weights with mask.</span>
            <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
              <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">mask</span>
            <span class="k">else</span><span class="p">:</span>
              <span class="c1"># Update dimensions of weights to match with mask if possible.</span>
              <span class="n">mask</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">sample_weight</span> <span class="o">=</span> <span class="p">(</span>
                  <span class="n">tf_losses_utils</span><span class="o">.</span><span class="n">squeeze_or_expand_dimensions</span><span class="p">(</span>
                      <span class="n">mask</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">))</span>
              <span class="n">sample_weight</span> <span class="o">*=</span> <span class="n">mask</span>

          <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="s1">&#39;reduction&#39;</span><span class="p">):</span>
            <span class="n">per_sample_losses</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
            <span class="n">weighted_losses</span> <span class="o">=</span> <span class="n">losses_utils</span><span class="o">.</span><span class="n">compute_weighted_loss</span><span class="p">(</span>
                <span class="n">per_sample_losses</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
                <span class="n">reduction</span><span class="o">=</span><span class="n">losses_utils</span><span class="o">.</span><span class="n">ReductionV2</span><span class="o">.</span><span class="n">NONE</span><span class="p">)</span>
            <span class="n">loss_reduction</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="o">.</span><span class="n">reduction</span>

            <span class="c1"># `AUTO` loss reduction defaults to `SUM_OVER_BATCH_SIZE` for all</span>
            <span class="c1"># compile use cases.</span>
            <span class="k">if</span> <span class="n">loss_reduction</span> <span class="o">==</span> <span class="n">losses_utils</span><span class="o">.</span><span class="n">ReductionV2</span><span class="o">.</span><span class="n">AUTO</span><span class="p">:</span>
              <span class="n">loss_reduction</span> <span class="o">=</span> <span class="n">losses_utils</span><span class="o">.</span><span class="n">ReductionV2</span><span class="o">.</span><span class="n">SUM_OVER_BATCH_SIZE</span>

            <span class="c1"># Compute the stateless loss value.</span>
            <span class="n">output_loss</span> <span class="o">=</span> <span class="n">losses_utils</span><span class="o">.</span><span class="n">reduce_weighted_loss</span><span class="p">(</span>
                <span class="n">weighted_losses</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">loss_reduction</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Compute the stateless loss value for a custom loss class.</span>
            <span class="c1"># Here we assume that the class takes care of loss reduction</span>
            <span class="c1"># because if this class returns a vector value we cannot</span>
            <span class="c1"># differentiate between use case where a custom optimizer</span>
            <span class="c1"># expects a vector loss value vs unreduced per-sample loss value.</span>
            <span class="n">output_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
            <span class="n">loss_reduction</span> <span class="o">=</span> <span class="n">losses_utils</span><span class="o">.</span><span class="n">ReductionV2</span><span class="o">.</span><span class="n">SUM_OVER_BATCH_SIZE</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
          <span class="c1"># Keep track of stateful result tensor for the loss.</span>
          <span class="n">endpoint</span><span class="o">.</span><span class="n">output_loss_metric</span><span class="p">(</span><span class="n">output_loss</span><span class="p">)</span>

        <span class="c1"># Scale output loss for distribution. For custom losses we assume</span>
        <span class="c1"># reduction was mean.</span>
        <span class="k">if</span> <span class="n">loss_reduction</span> <span class="o">==</span> <span class="n">losses_utils</span><span class="o">.</span><span class="n">ReductionV2</span><span class="o">.</span><span class="n">SUM_OVER_BATCH_SIZE</span><span class="p">:</span>
          <span class="n">output_loss</span> <span class="o">=</span> <span class="n">losses_utils</span><span class="o">.</span><span class="n">scale_loss_for_distribution</span><span class="p">(</span><span class="n">output_loss</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">total_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">total_loss</span> <span class="o">=</span> <span class="n">loss_weight</span> <span class="o">*</span> <span class="n">output_loss</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss_weight</span> <span class="o">*</span> <span class="n">output_loss</span>
      <span class="k">if</span> <span class="n">total_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">:</span>
          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The model cannot be compiled &#39;</span>
                           <span class="s1">&#39;because it has no loss to optimize.&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>

      <span class="c1"># Add regularization penalties and other layer-specific losses.</span>
      <span class="n">custom_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_losses_for</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_losses_for</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">custom_losses</span><span class="p">:</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">losses_utils</span><span class="o">.</span><span class="n">scale_loss_for_distribution</span><span class="p">(</span>
            <span class="n">math_ops</span><span class="o">.</span><span class="n">add_n</span><span class="p">(</span><span class="n">custom_losses</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">total_loss</span>

  <span class="k">def</span> <span class="nf">_get_callback_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the Callback Model for this Model.&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_replicated_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replicated_model</span><span class="p">:</span>
      <span class="c1"># When using training_distributed, we set the callback model</span>
      <span class="c1"># to an instance of the `DistributedModel` that we create in</span>
      <span class="c1"># the `compile` call. The `DistributedModel` is initialized</span>
      <span class="c1"># with the first replicated model. We need to set the callback</span>
      <span class="c1"># model to a DistributedModel to allow us to override saving</span>
      <span class="c1"># and loading weights when we checkpoint the model during training.</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replicated_model</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;callback_model&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback_model</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback_model</span>
    <span class="k">return</span> <span class="bp">self</span>

  <span class="k">def</span> <span class="nf">_make_callback_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grouped_model</span><span class="p">):</span>
    <span class="n">first_replicated_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">unwrap</span><span class="p">(</span>
        <span class="n">grouped_model</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># We initialize the callback model with the first replicated model.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_replicated_model</span> <span class="o">=</span> <span class="n">DistributedCallbackModel</span><span class="p">(</span><span class="n">first_replicated_model</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_replicated_model</span><span class="o">.</span><span class="n">set_original_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_validate_or_infer_batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Validates that the `batch_size` provided is consistent with InputLayer.</span>

<span class="sd">    It&#39;s possible that the user specified a static batch size in their</span>
<span class="sd">    InputLayer. If so, this method checks the provided `batch_size` and `x`</span>
<span class="sd">    arguments are consistent with this static batch size. Also, if</span>
<span class="sd">    `batch_size` is `None`, this method will attempt to infer the batch size</span>
<span class="sd">    from the static batch size of the InputLayer. Lastly, ValueError will be</span>
<span class="sd">    raised if `x` is a tf.data.Dataset and `batch_size` is specified as we</span>
<span class="sd">    expect users to provide batched datasets.</span>

<span class="sd">    Arguments:</span>
<span class="sd">      batch_size: The batch_size provided as an argument to</span>
<span class="sd">        fit/evaluate/predict.</span>
<span class="sd">      steps: The steps provided as an argument to fit/evaluate/predict.</span>
<span class="sd">      x: The data passed as `x` to fit/evaluate/predict.</span>

<span class="sd">    Returns:</span>
<span class="sd">      The validated batch_size, auto-inferred from the first layer if not</span>
<span class="sd">      provided.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV1</span><span class="p">,</span>
                       <span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV2</span><span class="p">,</span>
                       <span class="n">data_utils</span><span class="o">.</span><span class="n">Sequence</span><span class="p">))</span> <span class="ow">or</span>
        <span class="n">tf_inspect</span><span class="o">.</span><span class="n">isgenerator</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
      <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;The `batch_size` argument must not be specified for the given &#39;</span>
            <span class="s1">&#39;input type. Received input: </span><span class="si">{}</span><span class="s1">, batch_size: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">))</span>
      <span class="k">return</span>

    <span class="n">layers</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">layers</span>  <span class="c1"># Avoids the override in Sequential.</span>
    <span class="k">if</span> <span class="n">layers</span><span class="p">:</span>
      <span class="n">first_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="c1"># The per-replica static batch size.</span>
      <span class="n">static_batch_size</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">get_static_batch_size</span><span class="p">(</span><span class="n">first_layer</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">static_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

        <span class="c1"># Determine number of times the user-supplied batch size will be split.</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span> <span class="ow">and</span>
            <span class="n">distributed_training_utils</span><span class="o">.</span><span class="n">global_batch_size_supported</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">)):</span>
          <span class="n">num_splits_for_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">num_replicas_in_sync</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">num_splits_for_ds</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="c1"># Check `batch_size` argument is consistent with InputLayer.</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">batch_size</span> <span class="o">%</span> <span class="n">num_splits_for_ds</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The `batch_size` argument value </span><span class="si">{}</span><span class="s1"> cannot be &#39;</span>
                             <span class="s1">&#39;divisible by number of replicas </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                 <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_splits_for_ds</span><span class="p">))</span>
          <span class="n">per_replica_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">//</span> <span class="n">num_splits_for_ds</span>

          <span class="k">if</span> <span class="n">per_replica_batch_size</span> <span class="o">!=</span> <span class="n">static_batch_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The `batch_size` argument value </span><span class="si">{}</span><span class="s1"> is &#39;</span>
                             <span class="s1">&#39;incompatible with the specified batch size of &#39;</span>
                             <span class="s1">&#39;your Input Layer: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                 <span class="n">per_replica_batch_size</span><span class="p">,</span> <span class="n">static_batch_size</span><span class="p">))</span>

        <span class="c1"># Check Dataset/Iterator batch size is consistent with InputLayer.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV2</span><span class="p">,</span> <span class="n">iterator_ops</span><span class="o">.</span><span class="n">Iterator</span><span class="p">,</span>
                          <span class="n">iterator_ops</span><span class="o">.</span><span class="n">IteratorV2</span><span class="p">)):</span>
          <span class="n">ds_batch_size</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">as_dimension</span><span class="p">(</span>
              <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">dataset_ops</span><span class="o">.</span><span class="n">get_legacy_output_shapes</span><span class="p">(</span><span class="n">x</span><span class="p">))[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">value</span>
          <span class="k">if</span> <span class="n">ds_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ds_batch_size</span> <span class="o">%</span> <span class="n">num_splits_for_ds</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
              <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                  <span class="s1">&#39;The batch output shape of your `Dataset` </span><span class="si">{}</span><span class="s1"> &#39;</span>
                  <span class="s1">&#39;cannot be divisible by number of replicas </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                      <span class="n">ds_batch_size</span><span class="p">,</span> <span class="n">num_splits_for_ds</span><span class="p">))</span>

            <span class="n">ds_per_replica_batch_size</span> <span class="o">=</span> <span class="n">ds_batch_size</span> <span class="o">//</span> <span class="n">num_splits_for_ds</span>
            <span class="k">if</span> <span class="n">ds_per_replica_batch_size</span> <span class="o">!=</span> <span class="n">static_batch_size</span><span class="p">:</span>
              <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The batch output shape of your `Dataset` is &#39;</span>
                               <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">, which is incompatible with the specified &#39;</span>
                               <span class="s1">&#39;batch size of your Input Layer: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                   <span class="n">ds_per_replica_batch_size</span><span class="p">,</span>
                                   <span class="n">static_batch_size</span><span class="p">))</span>

        <span class="c1"># Set inferred batch size from the InputLayer.</span>
        <span class="k">if</span> <span class="n">steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">batch_size</span> <span class="o">=</span> <span class="n">static_batch_size</span> <span class="o">*</span> <span class="n">num_splits_for_ds</span>

    <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="c1"># Backwards compatibility</span>
      <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="k">return</span> <span class="n">batch_size</span>

  <span class="k">def</span> <span class="nf">_prepare_sample_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets sample weight attribute on the model.&quot;&quot;&quot;</span>
    <span class="c1"># List with the same length as model outputs.</span>
    <span class="k">if</span> <span class="n">sample_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample_weights</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Provided sample weights must have same length as the &#39;</span>
                         <span class="s1">&#39;number of outputs. Expected: </span><span class="si">{}</span><span class="s1">, got: </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                             <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">),</span>
                             <span class="nb">len</span><span class="p">(</span><span class="n">sample_weights</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">sample_weights</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">endpoint</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">,</span> <span class="n">sample_weights</span><span class="p">):</span>
      <span class="n">endpoint</span><span class="o">.</span><span class="n">populate_sample_weight</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">.</span><span class="n">sample_weight_mode</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_cache_output_metric_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">weighted_metrics</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Caches metric name and function attributes for every model output.&quot;&quot;&quot;</span>
    <span class="n">output_shapes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">output</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">rank</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">output_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_per_output_metrics</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">collect_per_output_metric_info</span><span class="p">(</span>
        <span class="n">metrics</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_names</span><span class="p">,</span> <span class="n">output_shapes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_functions</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_per_output_weighted_metrics</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">training_utils</span><span class="o">.</span><span class="n">collect_per_output_metric_info</span><span class="p">(</span>
            <span class="n">weighted_metrics</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_names</span><span class="p">,</span>
            <span class="n">output_shapes</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_functions</span><span class="p">,</span>
            <span class="n">is_weighted</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">_add_unique_metric_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">output_index</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Makes the metric name unique and adds it to the model&#39;s metric name list.</span>

<span class="sd">      If there are multiple outputs for which the metrics are calculated, the</span>
<span class="sd">      metric names have to be made unique by appending an integer.</span>

<span class="sd">    Arguments:</span>
<span class="sd">      metric_name: Metric name that corresponds to the metric specified by the</span>
<span class="sd">          user. For example: &#39;acc&#39;.</span>
<span class="sd">      output_index: The index of the model output for which the metric name is</span>
<span class="sd">        being added.</span>

<span class="sd">    Returns:</span>
<span class="sd">      string, name of the model&#39;s unique metric name</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_names</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">metric_name</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_names</span><span class="p">[</span><span class="n">output_index</span><span class="p">],</span> <span class="n">metric_name</span><span class="p">)</span>
    <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">base_metric_name</span> <span class="o">=</span> <span class="n">metric_name</span>
    <span class="k">while</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">:</span>
      <span class="n">metric_name</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">base_metric_name</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
      <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">metric_name</span>

  <span class="k">def</span> <span class="nf">_init_metric_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initialized model metric attributes.&quot;&quot;&quot;</span>
    <span class="c1"># List of stateful metric functions. Used for resetting metric state during</span>
    <span class="c1"># training/eval.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_compile_metric_functions</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">def</span> <span class="nf">_set_per_output_metric_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics_dict</span><span class="p">,</span> <span class="n">output_index</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the metric attributes on the model for the given output.</span>

<span class="sd">    Arguments:</span>
<span class="sd">      metrics_dict: A dict with metric names as keys and metric fns as values.</span>
<span class="sd">      output_index: The index of the model output for which the metric</span>
<span class="sd">        attributes are added.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Metrics dict updated with unique metric names as keys.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">updated_metrics_dict</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_fn</span> <span class="ow">in</span> <span class="n">metrics_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="n">metric_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_unique_metric_name</span><span class="p">(</span><span class="n">metric_name</span><span class="p">,</span> <span class="n">output_index</span><span class="p">)</span>

      <span class="c1"># Update the name on the metric class to be the unique generated name.</span>
      <span class="n">metric_fn</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">metric_name</span>  <span class="c1"># pylint: disable=protected-access</span>
      <span class="n">updated_metrics_dict</span><span class="p">[</span><span class="n">metric_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">metric_fn</span>
      <span class="c1"># Keep track of metric name and function.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_compile_metric_functions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_fn</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">updated_metrics_dict</span>

  <span class="k">def</span> <span class="nf">_set_metric_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the metric attributes on the model for all the model outputs.&quot;&quot;&quot;</span>
    <span class="n">updated_per_output_metrics</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">updated_per_output_weighted_metrics</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">endpoint</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">endpoint</span><span class="o">.</span><span class="n">should_skip_target</span><span class="p">():</span>
        <span class="n">updated_per_output_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_per_output_metrics</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">updated_per_output_weighted_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_per_output_weighted_metrics</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">continue</span>
      <span class="n">updated_per_output_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_set_per_output_metric_attributes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_per_output_metrics</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                                 <span class="n">i</span><span class="p">))</span>
      <span class="n">updated_per_output_weighted_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_set_per_output_metric_attributes</span><span class="p">(</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">_per_output_weighted_metrics</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">i</span><span class="p">))</span>

    <span class="c1"># Create a metric wrapper for each output loss. This computes mean of an</span>
    <span class="c1"># output loss across mini-batches (irrespective of how we reduce within a</span>
    <span class="c1"># batch).</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">endpoint</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">endpoint</span><span class="o">.</span><span class="n">should_skip_target</span><span class="p">():</span>
          <span class="n">endpoint</span><span class="o">.</span><span class="n">output_loss_metric</span> <span class="o">=</span> <span class="n">metrics_module</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span>
              <span class="n">name</span><span class="o">=</span><span class="n">endpoint</span><span class="o">.</span><span class="n">loss_name</span><span class="p">())</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_per_output_metrics</span> <span class="o">=</span> <span class="n">updated_per_output_metrics</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_per_output_weighted_metrics</span> <span class="o">=</span> <span class="n">updated_per_output_weighted_metrics</span>

  <span class="k">def</span> <span class="nf">_handle_per_output_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                 <span class="n">metrics_dict</span><span class="p">,</span>
                                 <span class="n">y_true</span><span class="p">,</span>
                                 <span class="n">y_pred</span><span class="p">,</span>
                                 <span class="n">mask</span><span class="p">,</span>
                                 <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls metric functions for a single output.</span>

<span class="sd">    Arguments:</span>
<span class="sd">      metrics_dict: A dict with metric names as keys and metric fns as values.</span>
<span class="sd">      y_true: Target output.</span>
<span class="sd">      y_pred: Predicted output.</span>
<span class="sd">      mask: Computed mask value for the current output.</span>
<span class="sd">      weights: Weights to be applied on the current output.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A list of metric result tensors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">metric_results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_fn</span> <span class="ow">in</span> <span class="n">metrics_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">metric_name</span><span class="p">):</span>
        <span class="n">metric_result</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">call_metric_function</span><span class="p">(</span>
            <span class="n">metric_fn</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
        <span class="n">metric_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_result</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">metric_results</span>

  <span class="k">def</span> <span class="nf">_handle_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                      <span class="n">outputs</span><span class="p">,</span>
                      <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                      <span class="n">skip_target_masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                      <span class="n">sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                      <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                      <span class="n">return_weighted_metrics</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                      <span class="n">return_weighted_and_unweighted_metrics</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Handles calling metric functions.</span>

<span class="sd">    Arguments:</span>
<span class="sd">      outputs: List of outputs (predictions).</span>
<span class="sd">      targets: List of targets.</span>
<span class="sd">      skip_target_masks: Optional. List of boolean for whether the corresponding</span>
<span class="sd">        target should be ignored or not.</span>
<span class="sd">      sample_weights: Optional list of sample weight arrays.</span>
<span class="sd">      masks: List of computed output mask values.</span>
<span class="sd">      return_weighted_metrics: Flag that indicates whether weighted metrics</span>
<span class="sd">        should be computed instead of unweighted metrics. This flag is ignored</span>
<span class="sd">        when `return_weighted_and_unweighted_metrics` is enabled.</span>
<span class="sd">      return_weighted_and_unweighted_metrics: Flag that is used to indicate</span>
<span class="sd">        whether both weighted and unweighted metrics should be computed. When</span>
<span class="sd">        this is not enabled, we use `return_weighted_metrics` param to indicate</span>
<span class="sd">        whether weighted or unweighted metrics should be returned.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A list of metric result tensors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO(scottzhu): Update this to use the new training_endpoints. Currently</span>
    <span class="c1"># the eager and graph logic is bit different.</span>
    <span class="n">skip_target_masks</span> <span class="o">=</span> <span class="n">skip_target_masks</span> <span class="ow">or</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
    <span class="n">metric_results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;metrics&#39;</span><span class="p">):</span>
      <span class="c1"># Invoke all metrics added using `compile`.</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">skip_target_masks</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
          <span class="k">continue</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">outputs</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">targets</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">output_mask</span> <span class="o">=</span> <span class="n">masks</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">masks</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">return_weighted_and_unweighted_metrics</span> <span class="ow">or</span>
            <span class="ow">not</span> <span class="n">return_weighted_metrics</span><span class="p">):</span>
          <span class="n">metric_results</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">_handle_per_output_metrics</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_per_output_metrics</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                              <span class="n">target</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">output_mask</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">return_weighted_and_unweighted_metrics</span> <span class="ow">or</span> <span class="n">return_weighted_metrics</span><span class="p">:</span>
          <span class="n">metric_results</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">_handle_per_output_metrics</span><span class="p">(</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">_per_output_weighted_metrics</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                  <span class="n">target</span><span class="p">,</span>
                  <span class="n">output</span><span class="p">,</span>
                  <span class="n">output_mask</span><span class="p">,</span>
                  <span class="n">weights</span><span class="o">=</span><span class="n">sample_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">sample_weights</span> <span class="k">else</span> <span class="kc">None</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">metric_results</span>

  <span class="k">def</span> <span class="nf">_check_trainable_weights_consistency</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Check trainable weights count consistency.</span>

<span class="sd">    This will raise a warning if `trainable_weights` and</span>
<span class="sd">    `_collected_trainable_weights` are inconsistent (i.e. have different</span>
<span class="sd">    number of parameters).</span>
<span class="sd">    Inconsistency will typically arise when one modifies `model.trainable`</span>
<span class="sd">    without calling `model.compile` again.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_collected_trainable_weights&#39;</span><span class="p">):</span>
      <span class="k">return</span>

    <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_unique_trainable_weights</span><span class="p">)</span> <span class="o">!=</span>
        <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_collected_trainable_weights</span><span class="p">)):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">log_first_n</span><span class="p">(</span>
          <span class="n">logging</span><span class="o">.</span><span class="n">WARN</span><span class="p">,</span> <span class="s1">&#39;Discrepancy between trainable weights and collected&#39;</span>
          <span class="s1">&#39; trainable weights, did you set `model.trainable`&#39;</span>
          <span class="s1">&#39; without calling `model.compile` after ?&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_make_train_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">has_recompiled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recompile_weights_loss_and_weighted_metrics</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_trainable_weights_consistency</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The `optimizer` in `compile` should be a single &#39;</span>
                       <span class="s1">&#39;optimizer.&#39;</span><span class="p">)</span>
    <span class="c1"># If we have re-compiled the loss/weighted metric sub-graphs then create</span>
    <span class="c1"># train function even if one exists already. This is because</span>
    <span class="c1"># `_feed_sample_weights` list has been updated on re-copmpile.</span>
    <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;train_function&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">has_recompiled</span><span class="p">:</span>
      <span class="c1"># Restore the compiled trainable state.</span>
      <span class="n">current_trainable_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_trainable_state</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_set_trainable_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_compiled_trainable_state</span><span class="p">)</span>

      <span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_feed_inputs</span> <span class="o">+</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_feed_targets</span> <span class="o">+</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_feed_sample_weights</span><span class="p">)</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">symbolic_learning_phase</span><span class="p">(),</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">K</span><span class="o">.</span><span class="n">symbolic_learning_phase</span><span class="p">()]</span>

      <span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">get_graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
        <span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;training&#39;</span><span class="p">):</span>
          <span class="c1"># Training updates</span>
          <span class="n">updates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">get_updates</span><span class="p">(</span>
              <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_collected_trainable_weights</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">total_loss</span><span class="p">)</span>
          <span class="c1"># Unconditional updates</span>
          <span class="n">updates</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_updates_for</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
          <span class="c1"># Conditional updates relevant to this model</span>
          <span class="n">updates</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_updates_for</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span>

        <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_training_eval_metrics</span><span class="p">()</span>
        <span class="n">metrics_tensors</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">m</span><span class="o">.</span><span class="n">_call_result</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metrics</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;_call_result&#39;</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>
        <span class="p">]</span>

      <span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;training&#39;</span><span class="p">):</span>
        <span class="c1"># Gets loss and metrics. Updates weights at each call.</span>
        <span class="n">fn</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">total_loss</span><span class="p">]</span> <span class="o">+</span> <span class="n">metrics_tensors</span><span class="p">,</span>
            <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;train_function&#39;</span><span class="p">,</span>
            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_function_kwargs</span><span class="p">)</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;train_function&#39;</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>

      <span class="c1"># Restore the current trainable state</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_set_trainable_state</span><span class="p">(</span><span class="n">current_trainable_state</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_make_test_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">has_recompiled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recompile_weights_loss_and_weighted_metrics</span><span class="p">()</span>
    <span class="c1"># If we have re-compiled the loss/weighted metric sub-graphs then create</span>
    <span class="c1"># test function even if one exists already. This is because</span>
    <span class="c1"># `_feed_sample_weights` list has been updated on re-copmpile.</span>
    <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;test_function&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">has_recompiled</span><span class="p">:</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_feed_inputs</span> <span class="o">+</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_feed_targets</span> <span class="o">+</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_feed_sample_weights</span><span class="p">)</span>

      <span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">get_graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_training_eval_metrics</span><span class="p">()</span>
        <span class="n">metrics_tensors</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">m</span><span class="o">.</span><span class="n">_call_result</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metrics</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;_call_result&#39;</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>
        <span class="p">]</span>

      <span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;evaluation&#39;</span><span class="p">):</span>
        <span class="n">updates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_updates</span>
        <span class="c1"># Return loss and metrics, no gradient updates.</span>
        <span class="c1"># Does update the network states.</span>
        <span class="n">fn</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">total_loss</span><span class="p">]</span> <span class="o">+</span> <span class="n">metrics_tensors</span><span class="p">,</span>
            <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_function&#39;</span><span class="p">,</span>
            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_function_kwargs</span><span class="p">)</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;test_function&#39;</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_make_predict_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;predict_function&#39;</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">predict_function</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feed_inputs</span>
      <span class="c1"># Gets network outputs. Does not update weights.</span>
      <span class="c1"># Does update the network states.</span>
      <span class="n">kwargs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_function_kwargs&#39;</span><span class="p">,</span> <span class="p">{})</span>
      <span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predict_function</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span>
            <span class="n">updates</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_updates</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predict_function&#39;</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_make_execution_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_make_train_function</span><span class="p">()</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_make_test_function</span><span class="p">()</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_function</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_make_predict_function</span><span class="p">()</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_function</span>

  <span class="k">def</span> <span class="nf">_distribution_standardize_user_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                          <span class="n">x</span><span class="p">,</span>
                                          <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                          <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                          <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                          <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                          <span class="n">validation_split</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                          <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                          <span class="n">allow_partial_batch</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Runs validation checks on input and target data passed by the user.</span>

<span class="sd">    This is called when using tf.distribute.Strategy to train, evaluate or serve</span>
<span class="sd">    the model.</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Input data. A numpy array or `tf.data` dataset.</span>
<span class="sd">      y: Target data. A numpy array or None if x is a `tf.data` dataset.</span>
<span class="sd">      sample_weight: An optional sample-weight array passed by the user to</span>
<span class="sd">        weight the importance of each sample in `x`.</span>
<span class="sd">      class_weight: An optional class-weight array by the user to</span>
<span class="sd">        weight the importance of samples in `x` based on the class they belong</span>
<span class="sd">        to, as conveyed by `y`.</span>
<span class="sd">      batch_size: Integer batch size. If provided, it is used to run additional</span>
<span class="sd">        validation checks on stateful models.</span>
<span class="sd">      validation_split: Float between 0 and 1.</span>
<span class="sd">        Fraction of the training data to be used as validation data.</span>
<span class="sd">      shuffle: Boolean whether to shuffle the training data before each epoch.</span>
<span class="sd">      epochs: Integer epochs. If &gt; 1, repeat the numpy training data epochs</span>
<span class="sd">        times when converting to training dataset.</span>
<span class="sd">      allow_partial_batch: Boolean whether to enforce that all batches have the</span>
<span class="sd">        same size.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Dataset instance.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: In case of invalid user-provided data.</span>
<span class="sd">      RuntimeError: If the model was never compiled.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">class_weight</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;`class_weight` is currently not supported &#39;</span>
                                <span class="s1">&#39;when using tf.distribute.Strategy.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">sample_weight</span><span class="o">.</span><span class="n">all</span><span class="p">()</span> <span class="ow">and</span>
        <span class="n">distributed_training_utils</span><span class="o">.</span><span class="n">is_tpu_strategy</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">)):</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;`sample_weight` is currently not supported &#39;</span>
                                <span class="s1">&#39;when using TPUStrategy.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stateful</span> <span class="ow">and</span> <span class="n">distributed_training_utils</span><span class="o">.</span><span class="n">is_tpu_strategy</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span>
        <span class="n">num_replicas_in_sync</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Single core must be used for computation on &#39;</span>
                       <span class="s1">&#39;stateful models. Consider adding `device_assignment` &#39;</span>
                       <span class="s1">&#39;parameter to TPUStrategy using</span><span class="se">\n</span><span class="s1">&#39;</span>
                       <span class="s1">&#39;topology = tf.contrib.distribute.&#39;</span>
                       <span class="s1">&#39;initialize_tpu_system()</span><span class="se">\n</span><span class="s1">&#39;</span>
                       <span class="s1">&#39;device_assignment = tf.contrib.tpu.DeviceAssignment(&#39;</span>
                       <span class="s1">&#39;topology, core_assignment=tf.contrib.tpu.&#39;</span>
                       <span class="s1">&#39;SINGLE_CORE_ASSIGNMENT)</span><span class="se">\n</span><span class="s1">&#39;</span>
                       <span class="s1">&#39;tpu_strategy = tf.contrib.distribute.TPUStrategy(&#39;</span>
                       <span class="s1">&#39;device_assignment=device_assignment)&#39;</span><span class="p">)</span>

    <span class="c1"># Validates `steps` and `shuffle` arguments right at the beginning</span>
    <span class="c1"># since we use it to construct the dataset object.</span>
    <span class="c1"># TODO(anjalisridhar): Remove this check once we refactor the</span>
    <span class="c1"># _standardize_user_data code path. This check is already present elsewhere</span>
    <span class="c1"># in the codebase.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV2</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="n">training_utils</span><span class="o">.</span><span class="n">verify_dataset_shuffled</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span>
    <span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
      <span class="c1"># We should be sure to call get_session() inside the strategy.scope()</span>
      <span class="c1"># so the strategy can affect the session options.</span>
      <span class="k">if</span> <span class="n">ops</span><span class="o">.</span><span class="n">executing_eagerly_outside_functions</span><span class="p">():</span>
        <span class="n">session</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">session</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>

      <span class="n">first_x_value</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">first_x_value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">list_to_tuple</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">y</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">list_to_tuple</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
          <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">list_to_tuple</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">)</span>
            <span class="n">in_tuple</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">in_tuple</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">in_tuple</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">ds</span> <span class="o">=</span> <span class="n">strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">experimental_make_numpy_dataset</span><span class="p">(</span><span class="n">in_tuple</span><span class="p">,</span>
                                                               <span class="n">session</span><span class="o">=</span><span class="n">session</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
          <span class="c1"># We want a buffer size that is larger than the batch size provided by</span>
          <span class="c1"># the user and provides sufficient randomness. Note that larger</span>
          <span class="c1"># numbers introduce more memory usage based on the size of each</span>
          <span class="c1"># sample.</span>
          <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="mi">8</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">epochs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
          <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>

        <span class="c1"># We need to use the drop_remainder argument to get a known static</span>
        <span class="c1"># input shape which is required for TPUs.</span>
        <span class="n">drop_remainder</span> <span class="o">=</span> <span class="p">(</span><span class="ow">not</span> <span class="n">allow_partial_batch</span> <span class="ow">and</span>
                          <span class="n">strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">experimental_require_static_shapes</span><span class="p">)</span>

        <span class="c1"># TODO(b/131720208): We still drop remainder here if number of examples</span>
        <span class="c1"># is divisible by batch size, as sometimes dynamic padder will time out</span>
        <span class="c1"># with keras.metrics.CategoricalAccuracy() metric.</span>
        <span class="k">if</span> <span class="n">distributed_training_utils</span><span class="o">.</span><span class="n">is_tpu_strategy</span><span class="p">(</span>
            <span class="n">strategy</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">drop_remainder</span><span class="p">:</span>
          <span class="n">dataset_size</span> <span class="o">=</span> <span class="n">first_x_value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
          <span class="k">if</span> <span class="n">dataset_size</span> <span class="o">%</span> <span class="n">batch_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">drop_remainder</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="n">drop_remainder</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV2</span><span class="p">)</span>
        <span class="n">training_utils</span><span class="o">.</span><span class="n">validate_dataset_input</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span>
                                              <span class="n">validation_split</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>

  <span class="k">def</span> <span class="nf">_standardize_user_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                             <span class="n">x</span><span class="p">,</span>
                             <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="n">check_steps</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                             <span class="n">steps_name</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">,</span>
                             <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="n">validation_split</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                             <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                             <span class="n">extract_tensors_from_dataset</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Runs validation checks on input and target data passed by the user.</span>

<span class="sd">    Also standardizes the data to lists of arrays, in order.</span>

<span class="sd">    Also builds and compiles the model on the fly if it is a subclassed model</span>
<span class="sd">    that has never been called before (and thus has no inputs/outputs).</span>

<span class="sd">    This is a purely internal method, subject to refactoring at any time.</span>

<span class="sd">    Args:</span>
<span class="sd">      x: Input data. It could be:</span>
<span class="sd">        - A Numpy array (or array-like), or a list of arrays</span>
<span class="sd">          (in case the model has multiple inputs).</span>
<span class="sd">        - A TensorFlow tensor, or a list of tensors</span>
<span class="sd">          (in case the model has multiple inputs).</span>
<span class="sd">        - A dict mapping input names to the corresponding array/tensors,</span>
<span class="sd">          if the model has named inputs.</span>
<span class="sd">        - A `tf.data` dataset.</span>
<span class="sd">      y: Target data. Like the input data `x`,</span>
<span class="sd">        it could be either Numpy array(s) or TensorFlow tensor(s).</span>
<span class="sd">        It should be consistent with `x` (you cannot have Numpy inputs and</span>
<span class="sd">        tensor targets, or inversely). If `x` is a dataset, `y` should not be</span>
<span class="sd">        specified (since targets will be obtained from the iterator).</span>
<span class="sd">      sample_weight: An optional sample-weight array passed by the user to</span>
<span class="sd">        weight the importance of each sample in `x`.</span>
<span class="sd">      class_weight: An optional class-weight array by the user to</span>
<span class="sd">        weight the importance of samples in `x` based on the class they belong</span>
<span class="sd">        to, as conveyed by `y`. If both `sample_weight` and `class_weight` are</span>
<span class="sd">        provided, the weights are multiplied.</span>
<span class="sd">      batch_size: Integer batch size. If provided, it is used to run additional</span>
<span class="sd">        validation checks on stateful models.</span>
<span class="sd">      check_steps: boolean, True if we want to check for validity of `steps` and</span>
<span class="sd">        False, otherwise. For example, when we are standardizing one batch of</span>
<span class="sd">        data for train_on_batch/predict_on_batch/test_on_batch APIs, `steps`</span>
<span class="sd">        value is not required and we should not check for its validity in these</span>
<span class="sd">        cases.</span>
<span class="sd">      steps_name: The public API&#39;s parameter name for `steps`.</span>
<span class="sd">      steps: Integer or `None`. Total number of steps (batches of samples) to</span>
<span class="sd">        execute.</span>
<span class="sd">      validation_split: Float between 0 and 1.</span>
<span class="sd">        Fraction of the training data to be used as validation data.</span>
<span class="sd">      shuffle: Boolean whether to shuffle the training data before each epoch.</span>
<span class="sd">      extract_tensors_from_dataset: Boolean. When `x` is a dataset instance,</span>
<span class="sd">        this indicates whether to extract actual tensors from the dataset or</span>
<span class="sd">        instead output the dataset instance itself.</span>
<span class="sd">        Set to True when calling from `train_on_batch`/etc.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple of 3: inputs (arrays or dicts, depending on whether `x` was a dict</span>
<span class="sd">      or not), target arrays, sample-weight arrays.</span>
<span class="sd">      If the model&#39;s input and targets are symbolic, these lists are empty</span>
<span class="sd">      (since the model takes no user-provided data, instead the data comes</span>
<span class="sd">      from the symbolic inputs/targets).</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: In case of invalid user-provided data.</span>
<span class="sd">      RuntimeError: If the model was never compiled.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV1</span><span class="p">,</span> <span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV2</span><span class="p">)):</span>
      <span class="c1"># Graph mode dataset. We&#39;ll pass the dataset as-is (unless</span>
      <span class="c1"># `extract_tensors_from_dataset` is True, in which case we extract</span>
      <span class="c1"># the tensors from the dataset and we output them.</span>
      <span class="n">training_utils</span><span class="o">.</span><span class="n">validate_dataset_input</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span>
                                            <span class="n">validation_split</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="n">training_utils</span><span class="o">.</span><span class="n">verify_dataset_shuffled</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

      <span class="n">is_dataset</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="k">if</span> <span class="n">extract_tensors_from_dataset</span><span class="p">:</span>
        <span class="c1"># We do this for `train_on_batch`/etc.</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">extract_tensors_from_dataset</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">iterator_ops</span><span class="o">.</span><span class="n">Iterator</span><span class="p">):</span>
      <span class="c1"># Graph mode iterator. We extract the symbolic tensors.</span>
      <span class="n">training_utils</span><span class="o">.</span><span class="n">validate_dataset_input</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span>
                                            <span class="n">validation_split</span><span class="p">)</span>
      <span class="n">iterator</span> <span class="o">=</span> <span class="n">x</span>
      <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">unpack_iterator_input</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
      <span class="n">is_dataset</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">is_dataset</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Validates `steps` argument based on x&#39;s type.</span>
    <span class="k">if</span> <span class="n">check_steps</span><span class="p">:</span>
      <span class="n">training_utils</span><span class="o">.</span><span class="n">check_steps_argument</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">steps_name</span><span class="p">)</span>

    <span class="c1"># First, we build the model on the fly if necessary.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span>
      <span class="n">all_inputs</span><span class="p">,</span> <span class="n">y_input</span><span class="p">,</span> <span class="n">dict_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_model_with_inputs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="n">is_build_called</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">all_inputs</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="c1"># Whether this is a subclassed model that expects dictionary inputs</span>
      <span class="c1"># rather than list inputs (e.g. FeatureColumn-based models).</span>
      <span class="n">dict_inputs</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
      <span class="n">is_build_called</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">y_input</span> <span class="o">=</span> <span class="n">y</span>

    <span class="c1"># Second, we compile the model on the fly if necessary, mostly for subclass</span>
    <span class="c1"># models.</span>
    <span class="n">is_compile_called</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_compiled</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_compile_from_inputs</span><span class="p">(</span><span class="n">all_inputs</span><span class="p">,</span> <span class="n">y_input</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="n">is_compile_called</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># In graph mode, if we had just set inputs and targets as symbolic tensors</span>
    <span class="c1"># by invoking build and compile on the model respectively, we do not have to</span>
    <span class="c1"># feed anything to the model. Model already has input and target data as</span>
    <span class="c1"># part of the graph.</span>
    <span class="c1"># Note: in this case, `any` and `all` are equivalent since we disallow</span>
    <span class="c1"># mixed symbolic/value inputs.</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span> <span class="ow">and</span> <span class="n">is_build_called</span> <span class="ow">and</span> <span class="n">is_compile_called</span> <span class="ow">and</span>
        <span class="ow">not</span> <span class="n">is_dataset</span>  <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">_is_symbolic_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_inputs</span><span class="p">)):</span>
      <span class="k">return</span> <span class="p">[],</span> <span class="p">[],</span> <span class="kc">None</span>

    <span class="c1"># What follows is input validation and standardization to list format,</span>
    <span class="c1"># in the case where all inputs are value arrays.</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span><span class="p">:</span>
      <span class="c1"># In eager mode, do not do shape validation</span>
      <span class="c1"># since the network has no input nodes (placeholders) to be fed.</span>
      <span class="n">feed_input_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_names</span>
      <span class="n">feed_input_shapes</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_graph_network</span><span class="p">:</span>
      <span class="c1"># Case: symbolic-mode subclassed network. Do not do shape validation.</span>
      <span class="n">feed_input_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feed_input_names</span>
      <span class="n">feed_input_shapes</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># Case: symbolic-mode graph network.</span>
      <span class="c1"># In this case, we run extensive shape validation checks.</span>
      <span class="n">feed_input_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feed_input_names</span>
      <span class="n">feed_input_shapes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feed_input_shapes</span>

    <span class="c1"># Standardize the inputs.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV1</span><span class="p">,</span> <span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV2</span><span class="p">)):</span>
      <span class="c1"># TODO(fchollet): run static checks with dataset output shape(s).</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">standardize_input_data</span><span class="p">(</span>
          <span class="n">x</span><span class="p">,</span>
          <span class="n">feed_input_names</span><span class="p">,</span>
          <span class="n">feed_input_shapes</span><span class="p">,</span>
          <span class="n">check_batch_axis</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># Don&#39;t enforce the batch size.</span>
          <span class="n">exception_prefix</span><span class="o">=</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>

    <span class="c1"># Get typespecs for the input data and sanitize it if necessary.</span>
    <span class="c1"># TODO(momernick): This should be capable of doing full input validation</span>
    <span class="c1"># at all times - validate that this is so and refactor the standardization</span>
    <span class="c1"># code.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV2</span><span class="p">):</span>
      <span class="n">x_shapes</span> <span class="o">=</span> <span class="n">dataset_ops</span><span class="o">.</span><span class="n">get_structure</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_shapes</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="c1"># If the output of a Dataset is a tuple, we assume it&#39;s either of the</span>
        <span class="c1"># form (x_data, y_data) or (x_data, y_data, sample_weights). In either</span>
        <span class="c1"># case, we only care about x_data here.</span>
        <span class="n">x_shapes</span> <span class="o">=</span> <span class="n">x_shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">flat_inputs</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">expand_composites</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="n">flat_expected_inputs</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">expand_composites</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="n">converted_x</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">flat_inputs</span><span class="p">,</span> <span class="n">flat_expected_inputs</span><span class="p">):</span>
        <span class="n">converted_x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_convert_scipy_sparse_tensor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">pack_sequence_as</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">converted_x</span><span class="p">,</span> <span class="n">expand_composites</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="n">x_shapes</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">type_spec</span><span class="o">.</span><span class="n">type_spec_from_value</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

    <span class="n">flat_inputs</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x_shapes</span><span class="p">,</span> <span class="n">expand_composites</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">flat_expected_inputs</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">expand_composites</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">flat_inputs</span><span class="p">,</span> <span class="n">flat_expected_inputs</span><span class="p">):</span>
      <span class="n">nest</span><span class="o">.</span><span class="n">assert_same_structure</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">expand_composites</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="c1"># Prepare self._sample_weight_modes. List with the same length as</span>
      <span class="c1"># model outputs.</span>
      <span class="n">training_utils</span><span class="o">.</span><span class="n">prepare_sample_weight_modes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">,</span>
                                                 <span class="bp">self</span><span class="o">.</span><span class="n">sample_weight_mode</span><span class="p">)</span>
      <span class="n">feed_output_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feed_output_names</span>
      <span class="n">feed_sample_weight_modes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_weight_modes</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_graph_network</span><span class="p">:</span>
        <span class="n">feed_output_shapes</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">feed_output_shapes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feed_output_shapes</span>

      <span class="c1"># Standardize the outputs.</span>
      <span class="n">y</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">standardize_input_data</span><span class="p">(</span>
          <span class="n">y</span><span class="p">,</span>
          <span class="n">feed_output_names</span><span class="p">,</span>
          <span class="c1"># Don&#39;t enforce target shapes to match output shapes.</span>
          <span class="c1"># Precise checks will be run in `check_loss_and_target_compatibility`.</span>
          <span class="n">shapes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">check_batch_axis</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># Don&#39;t enforce the batch size.</span>
          <span class="n">exception_prefix</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>

      <span class="c1"># Generate sample-wise weight values given the `sample_weight` and</span>
      <span class="c1"># `class_weight` arguments.</span>
      <span class="n">sample_weights</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">standardize_sample_weights</span><span class="p">(</span>
          <span class="n">sample_weight</span><span class="p">,</span> <span class="n">feed_output_names</span><span class="p">)</span>
      <span class="n">class_weights</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">standardize_class_weights</span><span class="p">(</span>
          <span class="n">class_weight</span><span class="p">,</span> <span class="n">feed_output_names</span><span class="p">)</span>
      <span class="n">sample_weights</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">training_utils</span><span class="o">.</span><span class="n">standardize_weights</span><span class="p">(</span><span class="n">ref</span><span class="p">,</span> <span class="n">sw</span><span class="p">,</span> <span class="n">cw</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
          <span class="k">for</span> <span class="p">(</span><span class="n">ref</span><span class="p">,</span> <span class="n">sw</span><span class="p">,</span> <span class="n">cw</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sample_weights</span><span class="p">,</span> <span class="n">class_weights</span><span class="p">,</span>
                                         <span class="n">feed_sample_weight_modes</span><span class="p">)</span>
      <span class="p">]</span>
      <span class="c1"># Check that all arrays have the same length.</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">:</span>
        <span class="n">training_utils</span><span class="o">.</span><span class="n">check_array_lengths</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weights</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_graph_network</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span><span class="p">:</span>
          <span class="c1"># Additional checks to avoid users mistakenly using improper loss fns.</span>
          <span class="n">training_utils</span><span class="o">.</span><span class="n">check_loss_and_target_compatibility</span><span class="p">(</span>
              <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feed_loss_fns</span><span class="p">,</span> <span class="n">feed_output_shapes</span><span class="p">)</span>

      <span class="c1"># If sample weight mode has not been set and weights are None for all the</span>
      <span class="c1"># model outputs, return None (we do not create placeholders for</span>
      <span class="c1"># sample weights) so we do not want to feed any value.</span>
      <span class="n">is_sample_weight_mode_set</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
          <span class="n">s</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">feed_sample_weight_modes</span><span class="p">)</span>
      <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">is_sample_weight_mode_set</span> <span class="ow">and</span>
          <span class="nb">all</span><span class="p">(</span><span class="n">s</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sample_weights</span><span class="p">)):</span>
        <span class="n">sample_weights</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># If the list contains only None, return None</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">y</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">sample_weights</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateful</span> <span class="ow">and</span> <span class="n">batch_size</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_dataset</span><span class="p">:</span>
      <span class="c1"># Check that for stateful networks, number of samples is a multiple</span>
      <span class="c1"># of the static batch size.</span>
      <span class="k">if</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;In a stateful network, &#39;</span>
                         <span class="s1">&#39;you should only pass inputs with &#39;</span>
                         <span class="s1">&#39;a number of samples that can be &#39;</span>
                         <span class="s1">&#39;divided by the batch size. Found: &#39;</span> <span class="o">+</span>
                         <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39; samples&#39;</span><span class="p">)</span>

    <span class="c1"># If dictionary inputs were provided, we return a dictionary as well.</span>
    <span class="k">if</span> <span class="n">dict_inputs</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV1</span><span class="p">,</span>
                                          <span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV2</span><span class="p">)):</span>
      <span class="n">x</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">feed_input_names</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weights</span>

  <span class="k">def</span> <span class="nf">_build_model_with_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Build the model (set model inputs/outputs), mainly for subclass model.&quot;&quot;&quot;</span>
    <span class="n">processed_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">is_dict_inputs</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">orig_inputs</span> <span class="o">=</span> <span class="n">inputs</span>
    <span class="c1"># We need to use `inputs` to set the model inputs.</span>
    <span class="c1"># If input data is a dataset iterator in graph mode or if it is an eager</span>
    <span class="c1"># iterator and only one batch of samples is required, we fetch the data</span>
    <span class="c1"># tensors from the iterator and then standardize them.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV1</span><span class="p">,</span> <span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV2</span><span class="p">)):</span>
      <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">extract_tensors_from_dataset</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="c1"># We type-check that `inputs` and `targets` are either single arrays</span>
    <span class="c1"># or lists of arrays, and extract a flat list of inputs from the passed</span>
    <span class="c1"># structure.</span>
    <span class="n">training_utils</span><span class="o">.</span><span class="n">validate_input_types</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">orig_inputs</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
      <span class="n">processed_inputs</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
      <span class="n">is_dict_inputs</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">keys</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
      <span class="n">processed_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">processed_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="c1"># Now that we have a flat set of inputs, we make sure that none of them</span>
    <span class="c1"># are CompositeTensors or CompositeTensorValues of any type (or scipy</span>
    <span class="c1"># sparse arrays, which we treat as SparseTensor values). We cannot safely</span>
    <span class="c1"># infer input data from an arbitrary composite tensor, so we don&#39;t try -</span>
    <span class="c1"># users should explicitly add composite tensor inputs to their subclassed</span>
    <span class="c1"># models.</span>
    <span class="k">for</span> <span class="n">input_tensor</span> <span class="ow">in</span> <span class="n">processed_inputs</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">composite_tensor_utils</span><span class="o">.</span><span class="n">is_composite_or_composite_value</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">):</span>
        <span class="c1"># TODO(b/132691975): Document subclass-model CT input handling.</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;All SparseTensor and RaggedTensor inputs must be explicitly &#39;</span>
            <span class="s1">&#39;declared using a keras.Input() with sparse=True or ragged=True. &#39;</span>
            <span class="s1">&#39;We found an undeclared input </span><span class="si">%s</span><span class="s1">. For Sequential models, please &#39;</span>
            <span class="s1">&#39;add a keras.Input() as your first Layer. For subclassed models, &#39;</span>
            <span class="s1">&#39;please call self._set_inputs() on your input set, which you can &#39;</span>
            <span class="s1">&#39;create using keras.Input() for each input to your model.&#39;</span> <span class="o">%</span>
            <span class="p">(</span><span class="n">input_tensor</span><span class="p">,))</span>
    <span class="c1"># Build the model using the retrieved inputs (value or symbolic).</span>
    <span class="c1"># If values are generated from a dataset, then in symbolic-mode</span>
    <span class="c1"># placeholders will be created to match the value shapes.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">orig_inputs</span><span class="p">,</span> <span class="p">(</span><span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV1</span><span class="p">,</span> <span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV2</span><span class="p">,</span>
                                <span class="n">iterator_ops</span><span class="o">.</span><span class="n">Iterator</span><span class="p">)):</span>
      <span class="k">def</span> <span class="nf">create_tensor_spec</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tensor_spec</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

      <span class="n">cast_inputs</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">create_tensor_spec</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">has_tensors</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
      <span class="n">cast_inputs</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">cast_if_floating_dtype</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">cast_inputs</span> <span class="o">=</span> <span class="n">inputs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_set_inputs</span><span class="p">(</span><span class="n">cast_inputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">processed_inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">is_dict_inputs</span>

  <span class="k">def</span> <span class="nf">_compile_from_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">all_inputs</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">orig_inputs</span><span class="p">,</span> <span class="n">orig_target</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">target</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="c1"># We need to use `y` to set the model targets.</span>
      <span class="k">if</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">has_tensors</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">cast_if_floating_dtype_and_mismatch</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">)</span>
      <span class="n">training_utils</span><span class="o">.</span><span class="n">validate_input_types</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">orig_target</span><span class="p">,</span>
                                          <span class="n">allow_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">field_name</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="n">all_inputs</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">all_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
    <span class="c1"># Type check that all inputs are *either* value *or* symbolic.</span>
    <span class="c1"># TODO(fchollet): this check could be removed in Eager mode?</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">tensor_util</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_inputs</span><span class="p">):</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">tensor_util</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_inputs</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Do not pass inputs that mix Numpy arrays and &#39;</span>
                         <span class="s1">&#39;TensorFlow tensors. &#39;</span>
                         <span class="s1">&#39;You passed: x=&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">orig_inputs</span><span class="p">)</span> <span class="o">+</span>
                         <span class="s1">&#39;; y=&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">orig_target</span><span class="p">))</span>
    <span class="n">is_dataset</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">orig_inputs</span><span class="p">,</span> <span class="p">(</span><span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV1</span><span class="p">,</span>
                                          <span class="n">dataset_ops</span><span class="o">.</span><span class="n">DatasetV2</span><span class="p">,</span>
                                          <span class="n">iterator_ops</span><span class="o">.</span><span class="n">Iterator</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">is_dataset</span> <span class="ow">or</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
      <span class="n">target_tensors</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># Handle target tensors if any passed.</span>
      <span class="k">if</span> <span class="n">target</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
          <span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="n">target</span><span class="p">]</span>
        <span class="n">target_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">target</span> <span class="k">if</span> <span class="n">_is_symbolic_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">)]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">target_tensors</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
        <span class="n">loss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_compile_metrics</span><span class="p">,</span>
        <span class="n">weighted_metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_compile_weighted_metrics</span><span class="p">,</span>
        <span class="n">loss_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="p">,</span>
        <span class="n">target_tensors</span><span class="o">=</span><span class="n">target_tensors</span><span class="p">,</span>
        <span class="n">sample_weight_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_weight_mode</span><span class="p">,</span>
        <span class="n">run_eagerly</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">run_eagerly</span><span class="p">,</span>
        <span class="n">experimental_run_tf_function</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_experimental_run_tf_function</span><span class="p">)</span>

  <span class="c1"># TODO(omalleyt): Consider changing to a more descriptive function name.</span>
  <span class="k">def</span> <span class="nf">_set_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set model&#39;s input and output specs based on the input data received.</span>

<span class="sd">    This is to be used for Model subclasses, which do not know at instantiation</span>
<span class="sd">    time what their inputs look like.</span>

<span class="sd">    Args:</span>
<span class="sd">      inputs: Single array, or list of arrays. The arrays could be placeholders,</span>
<span class="sd">        Numpy arrays, data tensors, or TensorSpecs.</span>
<span class="sd">        - if placeholders: the model is built on top of these placeholders,</span>
<span class="sd">          and we expect Numpy data to be fed for them when calling `fit`/etc.</span>
<span class="sd">        - if Numpy data or TensorShapes: we create placeholders matching the</span>
<span class="sd">          TensorShapes or shapes of the Numpy arrays. We expect Numpy data to be</span>
<span class="sd">          fed for these placeholders when calling `fit`/etc.</span>
<span class="sd">        - if data tensors: the model is built on top of these tensors.</span>
<span class="sd">          We do not expect any Numpy data to be provided when calling `fit`/etc.</span>
<span class="sd">      outputs: None, a data tensor, or a list of tensors. If None, the</span>
<span class="sd">        outputs will be determined by invoking `self.call()`, otherwise the</span>
<span class="sd">        provided value will be used.</span>
<span class="sd">      training: Boolean or None. Only relevant in symbolic mode. Specifies</span>
<span class="sd">        whether to build the model&#39;s graph in inference mode (False), training</span>
<span class="sd">        mode (True), or using the Keras learning phase (None).</span>
<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If dict inputs are passed to a Sequential Model where the</span>
<span class="sd">        first layer isn&#39;t FeatureLayer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_input_attrs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_expects_training_arg</span><span class="p">:</span>
        <span class="c1"># In V2 mode, feeding `training=None` is not allowed because any value</span>
        <span class="c1"># explicitly passed by the user is respected, even `None`.`</span>
        <span class="k">if</span> <span class="n">training</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">ops</span><span class="o">.</span><span class="n">executing_eagerly_outside_functions</span><span class="p">():</span>
          <span class="n">training</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">learning_phase</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">training</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;training&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">training</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
      <span class="k">except</span> <span class="ne">NotImplementedError</span><span class="p">:</span>
        <span class="c1"># This Model or a submodel is dynamic and hasn&#39;t overridden</span>
        <span class="c1"># `compute_output_shape`.</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_set_output_attrs</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>

  <span class="nd">@trackable</span><span class="o">.</span><span class="n">no_automatic_dependency_tracking</span>
  <span class="k">def</span> <span class="nf">_set_input_attrs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets attributes related to the inputs of the Model.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Model inputs are already set.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;Sequential&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">built</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
        <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">):</span>
        <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="c1"># We assert that the first layer is a FeatureLayer.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">is_feature_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Passing a dictionary input to a Sequential Model &#39;</span>
                           <span class="s1">&#39;which doesn</span><span class="se">\&#39;</span><span class="s1">t have FeatureLayer as the first layer&#39;</span>
                           <span class="s1">&#39; is an error.&#39;</span><span class="p">)</span>
        <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_build_input_shape</span> <span class="o">=</span> <span class="n">input_shape</span>

    <span class="c1"># On-the-fly setting of symbolic model inputs (either by using the tensor</span>
    <span class="c1"># provided, or by creating a placeholder if Numpy data was provided).</span>
    <span class="n">model_inputs</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">ModelInputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="o">.</span><span class="n">get_symbolic_inputs</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="o">.</span><span class="n">get_symbolic_inputs</span><span class="p">(</span><span class="n">return_single_as_list</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_names</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="o">.</span><span class="n">get_input_names</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_feed_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_feed_input_names</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_feed_input_shapes</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">model_inputs</span><span class="o">.</span><span class="n">as_dict</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">K</span><span class="o">.</span><span class="n">is_placeholder</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_feed_input_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_feed_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_feed_input_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">inputs</span>

  <span class="nd">@trackable</span><span class="o">.</span><span class="n">no_automatic_dependency_tracking</span>
  <span class="k">def</span> <span class="nf">_set_output_attrs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets attributes related to the outputs of the Model.&quot;&quot;&quot;</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_names</span> <span class="o">=</span> <span class="n">training_utils</span><span class="o">.</span><span class="n">generic_output_names</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
    <span class="c1"># TODO(scottzhu): Should we cleanup the self._training_endpoints here?</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">built</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_targets</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The output target tensors for the model.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="n">e</span><span class="o">.</span><span class="n">training_target</span><span class="o">.</span><span class="n">target</span>
        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span>
        <span class="k">if</span> <span class="n">e</span><span class="o">.</span><span class="n">has_training_target</span><span class="p">()</span>
    <span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_feed_targets</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="n">e</span><span class="o">.</span><span class="n">training_target</span><span class="o">.</span><span class="n">target</span>
        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span>
        <span class="k">if</span> <span class="n">e</span><span class="o">.</span><span class="n">has_feedable_training_target</span><span class="p">()</span>
    <span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_feed_output_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="n">e</span><span class="o">.</span><span class="n">output_name</span>
        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span>
        <span class="k">if</span> <span class="n">e</span><span class="o">.</span><span class="n">has_feedable_training_target</span><span class="p">()</span>
    <span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_feed_output_shapes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="n">e</span><span class="o">.</span><span class="n">feed_output_shape</span>
        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span>
        <span class="k">if</span> <span class="n">e</span><span class="o">.</span><span class="n">has_feedable_training_target</span><span class="p">()</span>
    <span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_feed_loss_fns</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="n">e</span><span class="o">.</span><span class="n">loss_fn</span>
        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span>
        <span class="k">if</span> <span class="n">e</span><span class="o">.</span><span class="n">has_feedable_training_target</span><span class="p">()</span>
    <span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_loss_weights_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">e</span><span class="o">.</span><span class="n">loss_weight</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_output_loss_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_training_endpoints&#39;</span><span class="p">):</span>
      <span class="k">return</span> <span class="p">[</span>
          <span class="n">e</span><span class="o">.</span><span class="n">output_loss_metric</span>
          <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span>
          <span class="k">if</span> <span class="n">e</span><span class="o">.</span><span class="n">output_loss_metric</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
      <span class="p">]</span>
    <span class="k">return</span> <span class="kc">None</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">sample_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">e</span><span class="o">.</span><span class="n">sample_weight</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_sample_weight_modes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">e</span><span class="o">.</span><span class="n">sample_weight_mode</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span><span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_feed_sample_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">e</span><span class="o">.</span><span class="n">sample_weight</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_endpoints</span>
            <span class="k">if</span> <span class="n">e</span><span class="o">.</span><span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">_maybe_load_initial_epoch_from_ckpt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_epoch</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Maybe load initial epoch from ckpt considering possible worker recovery.</span>

<span class="sd">    Refer to tensorflow/python/keras/distribute/multi_worker_training_state.py</span>
<span class="sd">    for more information.</span>

<span class="sd">    Arguments:</span>
<span class="sd">      initial_epoch: The original initial_epoch user passes in in `fit()`.</span>
<span class="sd">      mode: The mode for running `model.fit()`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      If the training is recovering from previous failure under multi-worker</span>
<span class="sd">      training setting, return the epoch the training is supposed to continue</span>
<span class="sd">      at. Otherwise, return the `initial_epoch` the user passes in.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_training_state&#39;</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span><span class="o">.</span><span class="n">maybe_load_initial_epoch_from_ckpt</span><span class="p">(</span>
          <span class="n">initial_epoch</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">initial_epoch</span>

  <span class="k">def</span> <span class="nf">_get_training_eval_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns all the metrics that are to be reported.</span>

<span class="sd">    This includes the output loss metrics, compile metrics/weighted metrics,</span>
<span class="sd">    add_metric metrics.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_output_loss_metrics&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">metrics</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_loss_metrics</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;metrics&#39;</span><span class="p">):</span>
      <span class="n">metrics</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">metrics</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_object_identifier</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="s1">&#39;_tf_keras_model&#39;</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_tracking_metadata</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">metadata</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">_tracking_metadata</span><span class="p">)</span>
    <span class="n">metadata</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">saving_utils</span><span class="o">.</span><span class="n">model_metadata</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">require_config</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">serialization</span><span class="o">.</span><span class="n">get_json_type</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_assert_compile_was_called</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Checks whether `compile` has been called. If it has been called,</span>
    <span class="c1"># then the optimizer is set. This is different from whether the</span>
    <span class="c1"># model is compiled</span>
    <span class="c1"># (i.e. whether the model is built and its inputs/outputs are set).</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;You must compile your model before &#39;</span>
                         <span class="s1">&#39;training/testing. &#39;</span>
                         <span class="s1">&#39;Use `model.compile(optimizer, loss)`.&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_in_multi_worker_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Method to infer if this `Model` is working in multi-worker settings.</span>

<span class="sd">    Experimental. Signature and implementation are subject to change.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Whether this model indicates it&#39;s working in multi-worker settings.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># If the model was compiled under the scope of a `tf.distribute.Strategy&#39;,</span>
    <span class="c1"># `self._distribution_strategy` would have been set and model should infer</span>
    <span class="c1"># that as the used strategy (even if it&#39;s out of strategy scope already).</span>
    <span class="n">strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span>

    <span class="c1"># Otherwise, use the strategy whose scope this is in.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">strategy</span> <span class="ow">and</span> <span class="n">distribution_strategy_context</span><span class="o">.</span><span class="n">has_strategy</span><span class="p">():</span>
      <span class="n">strategy</span> <span class="o">=</span> <span class="n">distribution_strategy_context</span><span class="o">.</span><span class="n">get_strategy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">strategy</span> <span class="ow">and</span> <span class="n">strategy</span><span class="o">.</span><span class="n">_in_multi_worker_mode</span><span class="p">()</span>  <span class="c1"># pylint: disable=protected-access</span></div>


<span class="k">class</span> <span class="nc">DistributedCallbackModel</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Model that is used for callbacks with tf.distribute.Strategy.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">DistributedCallbackModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">optimizer</span>

  <span class="k">def</span> <span class="nf">set_original_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">orig_model</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_original_model</span> <span class="o">=</span> <span class="n">orig_model</span>

  <span class="k">def</span> <span class="nf">save_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_replicated_model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="n">overwrite</span><span class="p">,</span>
                                        <span class="n">save_format</span><span class="o">=</span><span class="n">save_format</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="c1"># save weights from the distributed model to the original model</span>
    <span class="n">distributed_model_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_original_model</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">distributed_model_weights</span><span class="p">)</span>
    <span class="c1"># TODO(anjalisridhar): Do we need to save the original model here?</span>
    <span class="c1"># Saving the first replicated model works as well.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_original_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">by_name</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_original_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">by_name</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># Copy the weights from the original model to each of the replicated models.</span>
    <span class="n">orig_model_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_original_model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
    <span class="n">distributed_training_utils</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_original_model</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span>  <span class="c1"># pylint: disable=protected-access</span>
        <span class="n">orig_model_weights</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
    <span class="c1"># Whitelisted atttributes of the model that can be accessed by the user</span>
    <span class="c1"># during a callback.</span>
    <span class="k">if</span> <span class="n">item</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;_setattr_tracking&#39;</span><span class="p">,</span> <span class="s1">&#39;_layers&#39;</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;You are accessing attribute &#39;</span> <span class="o">+</span> <span class="n">item</span> <span class="o">+</span> <span class="s1">&#39; of the &#39;</span>
                      <span class="s1">&#39;DistributedCallbackModel that may not have been set &#39;</span>
                      <span class="s1">&#39;correctly.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">DistributedCallbackModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_TrainingEndpoint</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A container for the training output/target and related entities.</span>

<span class="sd">  In the case of model with multiple outputs, there is a one-to-one mapping</span>
<span class="sd">  between model output (y_pred), model target (y_true), loss, metrics etc.</span>
<span class="sd">  By unifying these entities into one class, different entity can access</span>
<span class="sd">  information between each other, rather than currently access different list of</span>
<span class="sd">  attributes of the model.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">output</span><span class="p">,</span>
               <span class="n">output_name</span><span class="p">,</span>
               <span class="n">loss_fn</span><span class="p">,</span>
               <span class="n">loss_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">training_target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">output_loss_metric</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">sample_weight_mode</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initialize the _TrainingEndpoint.</span>

<span class="sd">    Note that the output and output_name should be stable as long as the model</span>
<span class="sd">    structure doesn&#39;t change. The training_target suppose to be mutable since</span>
<span class="sd">    the information is provided via `compile()`</span>

<span class="sd">    Args:</span>
<span class="sd">      output: the output tensor of the model.</span>
<span class="sd">      output_name: the unique name of the output tensor.</span>
<span class="sd">      loss_fn: the loss function for the output tensor.</span>
<span class="sd">      loss_weight: float, the weights for the loss.</span>
<span class="sd">      training_target: the _TrainingTarget for the model.</span>
<span class="sd">      output_loss_metric: the metric object for the loss function.</span>
<span class="sd">      sample_weight: the weights for how a sample is weighted during metric and</span>
<span class="sd">        loss calculation. Could be None.</span>
<span class="sd">      sample_weight_mode: string, &#39;temporal&#39;, &#39;samplewise&#39; or None. The mode for</span>
<span class="sd">        how the sample_weight is populated.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_output</span> <span class="o">=</span> <span class="n">output</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_output_name</span> <span class="o">=</span> <span class="n">output_name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_loss_weight</span> <span class="o">=</span> <span class="n">loss_weight</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_training_target</span> <span class="o">=</span> <span class="n">training_target</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_output_loss_metric</span> <span class="o">=</span> <span class="n">output_loss_metric</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_sample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_sample_weight_mode</span> <span class="o">=</span> <span class="n">sample_weight_mode</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_name</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">loss_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_weight</span>

  <span class="nd">@loss_weight</span><span class="o">.</span><span class="n">setter</span>
  <span class="k">def</span> <span class="nf">loss_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_loss_weight</span> <span class="o">=</span> <span class="n">value</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">training_target</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_target</span>

  <span class="nd">@training_target</span><span class="o">.</span><span class="n">setter</span>
  <span class="k">def</span> <span class="nf">training_target</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_training_target</span> <span class="o">=</span> <span class="n">value</span>

  <span class="k">def</span> <span class="nf">create_training_target</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create training_target instance and update the self.training_target.</span>

<span class="sd">    Note that the input target should just be a tensor or None, and</span>
<span class="sd">    corresponding training target will be created based on the output and</span>
<span class="sd">    loss_fn.</span>

<span class="sd">    Args:</span>
<span class="sd">      target: the target tensor for the current output. Could be None.</span>
<span class="sd">      run_eagerly: boolean, whether the model is in run_eagerly mode.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError if the training_target field for the current instance has</span>
<span class="sd">      already been populated.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_training_target</span><span class="p">():</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The training_target field for the _TrainingEndpoint &#39;</span>
                       <span class="s1">&#39;instance has already been populated&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">run_eagerly</span><span class="p">:</span>
      <span class="c1"># When run_eagerly, the target tensor is ignored, and the None placeholder</span>
      <span class="c1"># is created instead.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">training_target</span> <span class="o">=</span> <span class="n">_TrainingTarget</span><span class="p">(</span>
          <span class="kc">None</span><span class="p">,</span> <span class="n">feedable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">skip_target_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="k">return</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">should_skip_target</span><span class="p">():</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">training_target</span> <span class="o">=</span> <span class="n">_TrainingTarget</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">target</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">K</span><span class="o">.</span><span class="n">is_placeholder</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
        <span class="n">feedable</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">skip_target_weights</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">feedable</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">skip_target_weights</span> <span class="o">=</span> <span class="kc">False</span>

      <span class="k">if</span> <span class="n">target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">target_dtype</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">LABEL_DTYPES_FOR_LOSSES</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">K</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">))</span>

        <span class="n">target</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span>
            <span class="n">ndim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_name</span> <span class="o">+</span> <span class="s1">&#39;_target&#39;</span><span class="p">,</span>
            <span class="n">sparse</span><span class="o">=</span><span class="n">K</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">target_dtype</span><span class="p">)</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">training_target</span> <span class="o">=</span> <span class="n">_TrainingTarget</span><span class="p">(</span>
          <span class="n">target</span><span class="p">,</span>
          <span class="n">feedable</span><span class="o">=</span><span class="n">feedable</span><span class="p">,</span>
          <span class="n">skip_target_weights</span><span class="o">=</span><span class="n">skip_target_weights</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_loss_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_loss_metric</span>

  <span class="nd">@output_loss_metric</span><span class="o">.</span><span class="n">setter</span>
  <span class="k">def</span> <span class="nf">output_loss_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_output_loss_metric</span> <span class="o">=</span> <span class="n">value</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">sample_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_weight</span>

  <span class="nd">@sample_weight</span><span class="o">.</span><span class="n">setter</span>
  <span class="k">def</span> <span class="nf">sample_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_sample_weight</span> <span class="o">=</span> <span class="n">value</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">sample_weight_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_weight_mode</span>

  <span class="nd">@sample_weight_mode</span><span class="o">.</span><span class="n">setter</span>
  <span class="k">def</span> <span class="nf">sample_weight_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_sample_weight_mode</span> <span class="o">=</span> <span class="n">value</span>

  <span class="k">def</span> <span class="nf">should_skip_target</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span> <span class="ow">is</span> <span class="kc">None</span>

  <span class="k">def</span> <span class="nf">should_skip_target_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">should_skip_target</span><span class="p">()</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_target</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">training_target</span><span class="o">.</span><span class="n">skip_target_weights</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">has_training_target</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_target</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

  <span class="k">def</span> <span class="nf">has_feedable_training_target</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">should_skip_target</span><span class="p">()</span> <span class="ow">and</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">training_target</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_target</span><span class="o">.</span><span class="n">feedable</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">loss_name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_name</span> <span class="o">+</span> <span class="s1">&#39;_loss&#39;</span>
    <span class="k">return</span> <span class="kc">None</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">feed_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The output shape for the feedable target.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_feedable_training_target</span><span class="p">():</span>
      <span class="k">return</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="p">((</span><span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">losses</span><span class="o">.</span><span class="n">LossFunctionWrapper</span><span class="p">)</span> <span class="ow">and</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="o">.</span><span class="n">fn</span> <span class="o">==</span> <span class="n">losses</span><span class="o">.</span><span class="n">sparse_categorical_crossentropy</span><span class="p">))</span> <span class="ow">or</span> <span class="p">(</span>
             <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">)):</span>
      <span class="k">if</span> <span class="n">K</span><span class="o">.</span><span class="n">image_data_format</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;channels_first&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
    <span class="k">elif</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">losses</span><span class="o">.</span><span class="n">Loss</span><span class="p">)</span> <span class="ow">or</span>
          <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">losses</span><span class="o">.</span><span class="n">LossFunctionWrapper</span><span class="p">)</span> <span class="ow">and</span>
           <span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="o">.</span><span class="n">fn</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">))):</span>
      <span class="c1"># If the given loss is not an instance of the `Loss` class (custom</span>
      <span class="c1"># class) or if the loss function that is wrapped is not in the</span>
      <span class="c1"># `losses` module, then it is a user-defined loss and we make no</span>
      <span class="c1"># assumptions about it.</span>
      <span class="k">return</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>

  <span class="k">def</span> <span class="nf">sample_weights_mismatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Check if the sample weight and the mode match or not.&quot;&quot;&quot;</span>
    <span class="c1"># If there is a mismatch between sample weight mode and the placeholders</span>
    <span class="c1"># created, then recompile the sub-graphs that depend on sample weights.</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_weight_mode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_weight</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_weight_mode</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">populate_sample_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">sample_weight_mode</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Populate the sample weight and based on the sample weight mode.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">sample_weight</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">should_skip_target_weights</span><span class="p">()</span> <span class="ow">or</span> <span class="n">sample_weight_mode</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span>
         <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">())):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_sample_weight</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">return</span>

    <span class="k">assert</span> <span class="n">sample_weight_mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;temporal&#39;</span><span class="p">,</span> <span class="s1">&#39;samplewise&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">sample_weight_mode</span> <span class="o">==</span> <span class="s1">&#39;temporal&#39;</span><span class="p">:</span>
      <span class="n">default_value</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">1.</span><span class="p">]]</span>
      <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># sample_weight_mode == &#39;samplewise&#39;</span>
      <span class="n">default_value</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.</span><span class="p">]</span>
      <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">sample_weight</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Received sample weight with shape </span><span class="si">{}</span><span class="s1">. Expected shape &#39;</span>
                         <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sample_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">shape</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_sample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_sample_weight</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">placeholder_with_default</span><span class="p">(</span>
          <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">default_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">K</span><span class="o">.</span><span class="n">floatx</span><span class="p">()),</span>
          <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
          <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_name</span> <span class="o">+</span> <span class="s1">&#39;_sample_weights&#39;</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_TrainingTarget</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Container for a target tensor (y_true) and its metadata (shape, loss...).</span>

<span class="sd">  Arguments:</span>
<span class="sd">    target: A target tensor for the model. It may be `None` if the</span>
<span class="sd">      output is excluded from loss computation. It is still kept as None</span>
<span class="sd">      since each output of the model should have a corresponding target. If</span>
<span class="sd">      the target is None, the rest of the attributes will be None as well.</span>
<span class="sd">    feedable: Boolean, whether the target is feedable (requires data to be</span>
<span class="sd">      passed in `fit` or `train_on_batch`), or not (model compiled with</span>
<span class="sd">      `target_tensors` argument).</span>
<span class="sd">    skip_target_weights: Boolean, whether the target should be skipped during</span>
<span class="sd">      weights calculation.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">feedable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">skip_target_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_target</span> <span class="o">=</span> <span class="n">target</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_feedable</span> <span class="o">=</span> <span class="n">feedable</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_skip_target_weights</span> <span class="o">=</span> <span class="n">skip_target_weights</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">target</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">feedable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feedable</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">skip_target_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_skip_target_weights</span>


<span class="k">def</span> <span class="nf">_is_symbolic_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">EagerTensor</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_convert_scipy_sparse_tensor</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">expected_input</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Handle scipy sparse tensor conversions.</span>

<span class="sd">  This method takes a value &#39;value&#39; and returns the proper conversion. If</span>
<span class="sd">  value is a scipy sparse tensor and the expected input is a dense tensor,</span>
<span class="sd">  we densify &#39;value&#39;. If value is a scipy sparse tensor and the expected input</span>
<span class="sd">  is a TF SparseTensor, we convert &#39;value&#39; to a SparseTensor. If &#39;value&#39; is</span>
<span class="sd">  not a scipy sparse tensor, or scipy is not imported, we pass it through</span>
<span class="sd">  unchanged.</span>

<span class="sd">  Arguments:</span>
<span class="sd">    value: An object that may be a scipy sparse tensor</span>
<span class="sd">    expected_input: The expected input placeholder.</span>

<span class="sd">  Returns:</span>
<span class="sd">    The possibly-converted &#39;value&#39;.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">issparse</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">issparse</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ops</span><span class="o">.</span><span class="n">is_dense_tensor_like</span><span class="p">(</span><span class="n">expected_input</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">sparse_coo</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">tocoo</span><span class="p">()</span>
      <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="n">sparse_coo</span><span class="o">.</span><span class="n">row</span><span class="p">,</span> <span class="n">sparse_coo</span><span class="o">.</span><span class="n">col</span>
      <span class="n">data</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="n">sparse_coo</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">sparse_coo</span><span class="o">.</span><span class="n">shape</span>
      <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                               <span class="mi">1</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">sparse_tensor</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">value</span>


<span class="k">def</span> <span class="nf">_get_metrics_from_layers</span><span class="p">(</span><span class="n">layers</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns list of metrics from the given layers.</span>

<span class="sd">  This will not include the `compile` metrics of a model layer.</span>

<span class="sd">  Arguments:</span>
<span class="sd">    layers: List of layers.</span>

<span class="sd">  Returns:</span>
<span class="sd">    List of metrics.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">metrics</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">layers</span> <span class="o">=</span> <span class="n">trackable_layer_utils</span><span class="o">.</span><span class="n">filter_empty_layer_containers</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">Model</span><span class="p">):</span>
      <span class="c1"># We cannot call &#39;metrics&#39; on the model because we do not want to</span>
      <span class="c1"># include the metrics that were added in compile API of a nested model.</span>
      <span class="n">metrics</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_metrics</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>
      <span class="n">metrics</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">_get_metrics_from_layers</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">layers</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">metrics</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">metrics</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, BigDL Authors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>