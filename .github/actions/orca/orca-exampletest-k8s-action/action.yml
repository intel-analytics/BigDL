name: 'ORCA-Spark-K8s-Example-Prvn'
description: 'ORCA-Spark-K8s-Example-Prvn'
inputs:
  image:
    description: 'image'
    required: true
    default: 'intelanalytics/bigdl-k8s'
  image-tag:
    description: 'image tag'
    required: true
    default: 'latest'
runs:
  using: "composite"
  steps:
    - name: Env Prepare
      shell: bash
      run: |
        source activate bigdl
        export RUNTIME_PERSISTENT_VOLUME_CLAIM=nfsvolumeclaim

    - name: TF1 Examples Test
      shell: bash
      run: |
        /opt/spark/bin/spark-submit \
        --master ${RUNTIME_SPARK_MASTER} \
        --deploy-mode client \
        --conf spark.driver.host=${RUNTIME_DRIVER_HOST} \
        --conf spark.driver.port=54321 \
        --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
        --name basic_text_classification \
        --conf spark.kubernetes.container.image=$CONTAINER_NAME \
        --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.nfsvolumeclaim.options.claimName=nfsvolumeclaim \
        --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.nfsvolumeclaim.mount.path=/bigdl2.0/data \
        --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.nfsvolumeclaim.options.claimName=nfsvolumeclaim \
        --conf spark.kubernetes.executor.volumes.persistentVolumeClaim.nfsvolumeclaim.mount.path=/bigdl2.0/data \
        --conf spark.kubernetes.driverEnv.http_proxy=http://child-prc.intel.com:913 \
        --conf spark.kubernetes.driverEnv.https_proxy=http://child-prc.intel.com:913 \
        --conf spark.kubernetes.executorEnv.http_proxy=http://child-prc.intel.com:913 \
        --conf spark.kubernetes.executorEnv.https_proxy=http://child-prc.intel.com:913 \
        --conf spark.kubernetes.container.image.pullPolicy=Always \
        --archives /opt/spark/work-dir/environment.tar.gz#environment \
        --conf spark.pyspark.driver.python=python \
        --conf spark.pyspark.python=environment/bin/python \
        --conf spark.executor.instances=4 \
        --executor-cores 16 \
        --executor-memory 50g \
        --total-executor-cores 64 \
        --driver-cores 4 \
        --driver-memory 50g \
        --properties-file /opt/bigdl-2.3.0-SNAPSHOT/conf/spark-bigdl.conf \
        --py-files /opt/bigdl-2.3.0-SNAPSHOT/python/bigdl-orca-spark_3.1.3-2.3.0-SNAPSHOT-python-api.zip,/opt/bigdl-2.3.0-SNAPSHOT/examples/orca/learn/tf/basic_text_classification/basic_text_classification.py  \
        --conf spark.driver.extraJavaOptions=-Dderby.stream.error.file=/tmp \
        --conf spark.sql.catalogImplementation='in-memory' \
        --conf spark.driver.extraClassPath=local:///opt/bigdl-2.3.0-SNAPSHOT/jars/* \
        --conf spark.executor.extraClassPath=local:///opt/bigdl-2.3.0-SNAPSHOT/jars/* \
        local:///opt/bigdl-2.3.0-SNAPSHOT/examples/orca/learn/tf/basic_text_classification/basic_text_classification.py \
        --cluster_mode 'spark-submit'
