name: Nightly Test

on:
  pull_request:
  push:
  schedule:
    - cron: '0 15 * * *'
  workflow_dispatch:

permissions:
  contents: read
  packages: write

jobs:
  Orca-Python-ExampleTest-Py37-Spark3:

    runs-on: [self-hosted, Gondolin, ubuntu-20.04-lts]

    steps:
    - uses: actions/checkout@v3
    - name: Set up JDK8
      uses: ./.github/actions/jdk-setup-action

    - name: Set up maven
      uses: ./.github/actions/maven-setup-action
      with:
        arda_nexus: ${{ secrets.ARDA_NEXUS }}
    - name: Setup Env
      run: |
        apt-get update
        apt-get install wget

    - name: Set up Python 
      uses: actions/setup-python@v2
      with:
        python-version: '3.7.6'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        python -m pip install --upgrade setuptools==58.0.4
        pip uninstall -y bigdl-friesian bigdl-friesian-spark3 bigdl-dllib bigdl-dllib-spark3 bigdl-orca pyspark bigdl-orca-spark3 bigdl-chronos bigdl-chronos-spark3 bigdl-friesian bigdl-friesian-spark3
        pip uninstall -r python/orca/dev/example/requirements-ray.txt -y
        pip install -i https://pypi.org/simple --pre --upgrade bigdl-orca-spark3
        pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r python/orca/dev/example/requirements-ray.txt 
        pip uninstall -y opencv-python-headless
        pip install opencv-python-headless
    - name: Run Test
      run: |
        export MAVEN_OPTS="-XX:MaxPermSize=3G -Xmx100G -XX:ReservedCodeCacheSize=512m"
        export _JAVA_OPTIONS="-Xmx100G -XX:MaxPermSize=3G"
        export SPARK_LOCAL_HOSTNAME=localhost
        chmod a+x python/orca/dev/example/run-example-tests.sh
        python/orca/dev/example/run-example-tests.sh
      env:
        BIGDL_ROOT: ${{ github.workspace }}
        ANALYTICS_ZOO_ROOT: ${{ github.workspace }}

  Orca-Python-ExampleTest-Ray-Py37-Spark3:

    runs-on: [self-hosted, Gondolin, ubuntu-20.04-lts]

    steps:
    - uses: actions/checkout@v3

    - name: Set up JDK8
      uses: ./.github/actions/jdk-setup-action

    - name: Set up maven
      uses: ./.github/actions/maven-setup-action
      with:
        arda_nexus: ${{ secrets.ARDA_NEXUS }}
    - name: Setup Env
      run: |
        apt-get update
        apt-get install wget

    - name: Set up Python 
      uses: actions/setup-python@v2
      with:
        python-version: '3.7'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        python -m pip install --upgrade setuptools==58.0.4
        pip uninstall -y bigdl-friesian bigdl-friesian-spark3 bigdl-dllib bigdl-dllib-spark3 bigdl-orca pyspark bigdl-orca-spark3 bigdl-chronos bigdl-chronos-spark3 bigdl-friesian bigdl-friesian-spark3
        pip uninstall -r python/orca/dev/example/requirements-ray.txt -y
        pip install -i https://pypi.org/simple --pre --upgrade bigdl-orca-spark3
        pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r python/orca/dev/example/requirements-ray.txt 
        pip uninstall -y opencv-python-headless
        pip install opencv-python-headless

    - name: Run Test
      run: |
        export SPARK_LOCAL_HOSTNAME=localhost
        chmod a+x python/orca/dev/example/run-example-test-ray.sh
        python/orca/dev/example/run-example-test-ray.sh
      env:
        BIGDL_ROOT: ${{ github.workspace }}
        ANALYTICS_ZOO_ROOT: ${{ github.workspace }}

  Orca-Jep-ExampleTest-Py37-Spark2:

    runs-on: [self-hosted, Gondolin, ubuntu-20.04-lts]

    steps:
    - uses: actions/checkout@v3
    - name: Set up JDK8
      uses: ./.github/actions/jdk-setup-action
    - name: Set up maven
      uses: ./.github/actions/maven-setup-action
      with:
        arda_nexus: ${{ secrets.ARDA_NEXUS }}
    - name: Setup Env
      run: |
        apt-get update
        apt-get install wget
    - name: Set up Python 
      uses: actions/setup-python@v2
      with:
        python-version: '3.7'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        python -m pip install --upgrade setuptools==58.0.4
        pip uninstall -y bigdl-friesian bigdl-friesian-spark3 bigdl-dllib bigdl-dllib-spark3 bigdl-orca pyspark bigdl-orca-spark3 bigdl-chronos bigdl-chronos-spark3 bigdl-friesian bigdl-friesian-spark3
        pip uninstall -r python/orca/dev/example/requirements-jep.txt -y
        pip install -i https://pypi.org/simple --pre --upgrade bigdl-orca
        pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r python/orca/dev/example/requirements-jep.txt
        pip uninstall -y opencv-python-headless
        pip install opencv-python-headless

    - name: Run Test
      run: |
        export SPARK_LOCAL_HOSTNAME=localhost
        chmod a+x python/orca/dev/example/run-example-tests-jep.sh
        chmod a+x apps/run-app-tests-pytorch-pip.sh
        if [ -f /root/.cache/torch/hub/checkpoints/celebaHQ16_december_s7_i96000-9c72988c.pth ]
        then
          rm /root/.cache/torch/hub/checkpoints/celebaHQ16_december_s7_i96000-9c72988c.pth
        fi
        wget -P /root/.cache/torch/hub/checkpoints/ $HTTP_URI/analytics-zoo-models/face-generation/celebaHQ16_december_s7_i96000-9c72988c.pth

        bash python/orca/dev/example/run-example-tests-jep.sh
        bash apps/run-app-tests-pytorch-pip.sh
      env:
        BIGDL_ROOT: ${{ github.workspace }}
        ANALYTICS_ZOO_ROOT: ${{ github.workspace }}

  Scala-App:

    runs-on: [self-hosted, Gondolin, ubuntu-20.04-lts]

    steps:
    - uses: actions/checkout@v3
    - name: Set up JDK8
      uses: ./.github/actions/jdk-setup-action
    - name: Set up maven
      uses: ./.github/actions/maven-setup-action
      with:
        arda_nexus: ${{ secrets.ARDA_NEXUS }}
    - name: Set up Python 
      uses: actions/setup-python@v2
      with:
        python-version: '3.7'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install numpy
        pip install tensorflow==1.15.0
        pip install jupyter
        apt-get update
        apt-get install wget 

        wget https://downloads.lightbend.com/scala/2.11.8/scala-2.11.8.tgz
        gunzip scala-2.11.8.tgz
        tar -xf scala-2.11.8.tar -C /opt
        rm scala-2.11.8.tar
        ln -s /opt/scala-2.11.8 /opt/scala
    - name: Run Test
      run: |
          export SCALA_HOME=/opt/scala
          chmod a+x apps/run-scala-app-test.sh
          apps/run-scala-app-test.sh

  Dllib-Scala-UT:

    runs-on: [ self-hosted, Gondolin, ubuntu-20.04-lts ]

    steps:
      - uses: actions/checkout@v3
      - name: Set up JDK8
        uses: ./.github/actions/jdk-setup-action
      - name: Set up maven
        uses: ./.github/actions/maven-setup-action
        with:
          arda_nexus: ${{ secrets.ARDA_NEXUS }}
      - name: Run tests
        run: |
          export SPARK_LOCAL_HOSTNAME=localhost
          export KERAS_BACKEND=tensorflow
          cd scala
          mvn "-DwildcardSuites=com.intel.analytics.bigdl.dllib.optim" "-Dtest=com.intel.analytics.bigdl.dllib.optim.*Test" test -P spark_3.x -Dspark.version=3.1.2 
          mvn "-DwildcardSuites=com.intel.analytics.bigdl.dllib.models" "-Dtest=com.intel.analytics.bigdl.dllib.models.*Test" test -P spark_3.x -Dspark.version=3.1.2 
          mvn "-DwildcardSuites=com.intel.analytics.bigdl.dllib.estimator" "-Dtest=com.intel.analytics.bigdl.dllib.estimator.*Test" test -P spark_3.x -Dspark.version=3.1.2  
          mvn "-DwildcardSuites=com.intel.analytics.bigdl.dllib.nnframes" "-Dtest=com.intel.analytics.bigdl.dllib.nnframes.*Test" test -P spark_3.x -Dspark.version=3.1.2 
          mvn "-DwildcardSuites=com.intel.analytics.bigdl.dllib.feature" "-Dtest=com.intel.analytics.bigdl.dllib.feature.*Test" test -P spark_3.x -Dspark.version=3.1.2
          mvn "-DwildcardSuites=com.intel.analytics.bigdl.dllib.utils.intermediate" "-Dtest=com.intel.analytics.bigdl.dllib.utils.intermediate.*Test" test -P spark_3.x -Dspark.version=3.1.2
          mvn "-DwildcardSuites=com.intel.analytics.bigdl.dllib.utils.tf" "-Dtest=com.intel.analytics.bigdl.dllib.utils.tf.*Test" test -P spark_3.x -Dspark.version=3.1.2
          mvn "-DwildcardSuites=com.intel.analytics.bigdl.dllib.utils.python.api" "-Dtest=com.intel.analytics.bigdl.dllib.utils.python.api.*Test" test -P spark_3.x -Dspark.version=3.1.2
          #need python requirements
          #mvn "-DwildcardSuites=com.intel.analytics.bigdl.dllib.keras" "-Dtest=com.intel.analytics.bigdl.dllib.keras.*Test" test -P spark_3.x -Dspark.version=3.1.2 
          #mvn "-DwildcardSuites=com.intel.analytics.bigdl.dllib.nn.mkldnn" "-Dtest=com.intel.analytics.bigdl.dllib.nn.mkldnn.*Test" test -P spark_3.x -Dspark.version=3.1.2 

  Friesian-Scala-UT:
    runs-on: [ self-hosted, ubuntu-20.04-lts, CLX, AVX512, Ettenmoors ]

    steps:
      - uses: actions/checkout@v3
      - name: Set up JDK8
        uses: ./.github/actions/jdk-setup-action
      - name: Set up maven
        uses: ./.github/actions/maven-setup-action
        with:
          arda_nexus: ${{ secrets.ARDA_NEXUS }}
      - name: Set up redis
        run: |
          sudo mkdir -p /usr/share/keyrings
          curl -fsSL https://packages.redis.io/gpg | sudo -E gpg --yes --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/redis.list
          sudo -E apt-get update
          sudo -E apt-get install -y redis redis-tools
          redis-server --daemonize yes
          redis-cli ping

      - name: Set up mkl
        run: |
          cd /tmp
          curl -O http://10.239.45.10:8081/repository/raw/analytics-zoo-data/faiss-lib.zip
          sudo unzip -o faiss-lib.zip -d /lib
          sudo ln -fs /lib/libmkl_core.so /lib/libmkl_core.so.2
          sudo ln -fs /lib/libmkl_gnu_thread.so /lib/libmkl_gnu_thread.so.2
          sudo ln -fs /lib/libmkl_intel_lp64.so /lib/libmkl_intel_lp64.so.2

      - name: Prepare data
        run: |
          mkdir -p /tmp/friesian-unittest
          cd /tmp/friesian-unittest
          curl -O http://10.239.45.10:8081/repository/raw/analytics-zoo-data/friesian-serving-upload.tar.gz 
          tar -zxf friesian-serving-upload.tar.gz

      - name: Run tests
        run: |
          export SPARK_LOCAL_HOSTNAME=localhost
          export KERAS_BACKEND=tensorflow
          cd scala
          mvn "-DwildcardSuites=com.intel.analytics.bigdl.friesian" "-Dtest=com.intel.analytics.bigdl.friesian.*Test" test -P spark_2.x -Dspark.version=2.4.6 "-Dspark.master=local[*]"
          mvn "-DwildcardSuites=com.intel.analytics.bigdl.friesian" "-Dtest=com.intel.analytics.bigdl.friesian.*Test" test -P spark_3.x -Dspark.version=3.1.2 "-Dspark.master=local[*]"

  PPML-Scala-UT:

    runs-on: [ self-hosted, Gondolin, ubuntu-20.04-lts ]

    steps:
      - uses: actions/checkout@v3
      - name: Set up JDK8
        uses: ./.github/actions/jdk-setup-action
      - name: Set up maven
        uses: ./.github/actions/maven-setup-action
        with:
          arda_nexus: ${{ secrets.ARDA_NEXUS }}
      - name: Run tests
        run: |
          export SPARK_LOCAL_HOSTNAME=localhost
          export KERAS_BACKEND=tensorflow
          cd scala
          mvn "-DwildcardSuites=com.intel.analytics.bigdl.ppml" "-Dtest=com.intel.analytics.bigdl.ppml.*Test" test -P spark_3.x -Dspark.version=3.1.2 -Ddata-store-url=http://10.239.45.10:8081/repository/raw
















