name: Nightly Build Example Tests PPML Spark Local on Gramine

on:
  schedule:
    - cron: '0 20 * * *'
  workflow_dispatch:
    inputs:
      sgx_mem_size:
        description: 'memeory size limit'
        required: true
        default: 32G
        type: choice
        options:
        - 16G
        - 32G
        - 64G
        - 128G
      image:
        description: 'docker image version'
        required: true
        default: 10.239.45.10/arda/intelanalytics/bigdl-ppml-trusted-big-data-ml-python-gramine:test
        type: string

  
jobs:
  example-tests-ppml:
    runs-on: [self-hosted, SGX, Wilwarin]
    permissions:
      contents: read
      packages: write

    steps:
    - uses: actions/checkout@bigdl55
    - name: set variable
      env:
        DEFAULT_SGX_MEM_SIZE: 32G
        DEFAULT_IMAGE: 10.239.45.10/arda/intelanalytics/bigdl-ppml-trusted-big-data-ml-python-graphene:latest
      run: |
        echo "CONTAINER_NAME=spark-exmaples-test-gramine" >> $GITHUB_ENV
        echo "SGX_MEM_SIZE=${{ github.event.inputs.sgx_mem_size || env.DEFAULT_MEM_SIZE }}" >> $GITHUB_ENV
        echo "IMAGE=${{ github.event.inputs.image || env.DEFAULT_IMAGE }}" >>$GITHUB_ENV
    - name: start container
      run: |
        set -x
        docker pull ${IMAGE}
        docker rm -f ${CONTAINER_NAME}
        docker run -id --privileged --net=host --name ${CONTAINER_NAME} \
        --cpuset-cpus=$CPUSET \
        --oom-kill-disable \
        --device=/dev/sgx/enclave \
        --device=/dev/sgx/provision \
        -v ~/glorysdj/kuberconfig:/root/.kube/config \
        -v /var/run/aesmd/aesm.socket:/var/run/aesmd/aesm.socket \
        -v $ENCLAVE_KEY:/graphene/Pal/src/host/Linux-SGX/signer/enclave-key.pem \
        -v $DATA_PATH:/ppml/trusted-big-data-ml/work/data \
        -v $KEYS_PATH:/ppml/trusted-big-data-ml/work/keys \
        -e LOCAL_IP=$LOCAL_IP \
        -e SGX_MEM_SIZE=$SGX_MEM_SIZE \
        -e RUNTIME_SPARK_MASTER=k8s://https://192.168.0.112:6443 \
        -e RUNTIME_K8S_SERVICE_ACCOUNT=spark \
        -e RUNTIME_K8S_SPARK_IMAGE=$IMAGE \
        -e RUNTIME_DRIVER_HOST=$LOCAL_IP \
        -e RUNTIME_DRIVER_PORT=54321 \
        -e RUNTIME_EXECUTOR_INSTANCES=1 \
        -e RUNTIME_EXECUTOR_CORES=4 \
        -e RUNTIME_EXECUTOR_MEMORY=80g \
        -e RUNTIME_TOTAL_EXECUTOR_CORES=4 \
        -e RUNTIME_DRIVER_CORES=4 \
        -e RUNTIME_DRIVER_MEMORY=10g \
        $IMAGE bash
    - name: Spark Examples Test
      run: |
        bash /ppml/trusted-big-data-ml/work/test-suites/spark-examples.sh
        bash /ppml/trusted-big-data-ml/work/test-suites/spark-sql-examples.sh
        bash /ppml/trusted-big-data-ml/work/test-suites/pyspark-simple-examples.sh
        bash /ppml/trusted-big-data-ml/work/test-suites/pyspark-sql-examples.sh
        bash /ppml/trusted-big-data-ml/work/test-suites/pyspark-sql-api-examples.sh
