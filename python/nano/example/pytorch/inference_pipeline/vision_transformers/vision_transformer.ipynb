{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer Examples for InferenceOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 0 : Prepare Dataset\n",
    "\n",
    "As InferenceOptimizer needs validation data to calculate accuracy metric, we need to download [ImageNet validation dataset](https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar) and [development kit](https://image-net.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz), and place them under directory `./img_data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageNet\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def create_imagenet_val_dataset(limit_num_samples=None):\n",
    "    dataset = ImageNet(root=\"img_data\", split=\"val\")\n",
    "    if limit_num_samples is not None:\n",
    "        indices = np.random.permutation(len(dataset))[:limit_num_samples]\n",
    "        dataset = Subset(dataset, indices)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1 : Import related package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-06 16:04:21.133763: I tensorflow/core/util/util.cc:159] Experimental oneDNN custom operations are on. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-06 16:04:21.137674: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-06 16:04:21.137687: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from bigdl.nano.pytorch import InferenceOptimizer\n",
    "import timm\n",
    "from torchmetrics import Accuracy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2 : Define model and optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. mobilevit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import Interpolation\n",
    "from timm.data.loader import create_loader\n",
    "\n",
    "fake_train_dataset = create_imagenet_val_dataset()\n",
    "val_dataset = create_imagenet_val_dataset(limit_num_samples=320)\n",
    "faked_train_dataloader = create_loader(fake_train_dataset,\n",
    "                               input_size=256,\n",
    "                               batch_size=1,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.0, 0.0, 0.0),\n",
    "                               std=(1.0, 1.0, 1.0))\n",
    "val_dataloader = create_loader(val_dataset,\n",
    "                               input_size=256,\n",
    "                               batch_size=32,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.0, 0.0, 0.0),\n",
    "                               std=(1.0, 1.0, 1.0))\n",
    "val_dataloader.dataset.dataset.transform = val_dataloader.dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-06 12:35:46,775 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpged5nexs\n",
      "2022-09-06 12:35:46,779 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpged5nexs/_remote_module_non_scriptable.py\n",
      "/opt/anaconda3/envs/nano/lib/python3.7/site-packages/intel_extension_for_pytorch/frontend.py:262: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\"Conv BatchNorm folding failed during the optimize process.\")\n",
      "2022-09-06 12:35:58,398 - bigdl.nano.utils.log4Error - ERROR - \n",
      "\n",
      "****************************Usage Error************************\n",
      "Your machine or OS doesn't support BF16 instructions.\n",
      "2022-09-06 12:35:58,401 - bigdl.nano.utils.log4Error - ERROR - \n",
      "\n",
      "**************************How to fix***********************\n",
      "Please check your machine and OS to make sure BF16 support is available.\n",
      "2022-09-06 12:35:58,402 - bigdl.nano.utils.log4Error - ERROR - \n",
      "\n",
      "****************************Call Stack*************************\n",
      "/opt/anaconda3/envs/nano/lib/python3.7/site-packages/intel_extension_for_pytorch/frontend.py:262: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\"Conv BatchNorm folding failed during the optimize process.\")\n",
      "[W LegacyTypeDispatch.h:74] Warning: AutoNonVariableTypeMode is deprecated and will be removed in 1.10 release. For kernel implementations please use AutoDispatchBelowADInplaceOrView instead, If you are looking for a user facing API to enable running your inference-only workload, please use c10::InferenceMode. Using AutoDispatchBelowADInplaceOrView in user code is under risk of producing silent wrong result in some edge cases. See Note [AutoDispatchBelowAutograd] for more details. (function operator())\n",
      "/opt/anaconda3/envs/nano/lib/python3.7/site-packages/torch/nn/quantized/_reference/modules/utils.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(weight_qparams[\"scale\"], dtype=torch.float, device=device))\n",
      "/opt/anaconda3/envs/nano/lib/python3.7/site-packages/torch/nn/quantized/_reference/modules/utils.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(weight_qparams[\"zero_point\"], dtype=zero_point_dtype, device=device))\n",
      "/opt/anaconda3/envs/nano/lib/python3.7/site-packages/timm/models/mobilevit.py:296: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  new_h, new_w = math.ceil(H / patch_h) * patch_h, math.ceil(W / patch_w) * patch_w\n",
      "/opt/anaconda3/envs/nano/lib/python3.7/site-packages/timm/models/mobilevit.py:300: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if new_h != H or new_w != W:\n",
      "/opt/anaconda3/envs/nano/lib/python3.7/site-packages/timm/models/vision_transformer.py:201: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
      "/opt/anaconda3/envs/nano/lib/python3.7/site-packages/intel_extension_for_pytorch/frontend.py:262: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\"Conv BatchNorm folding failed during the optimize process.\")\n",
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnumpy: installed: 1.21.6, required: < 1.20\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/tmph8bivt4w/tmp.xml\n",
      "[ SUCCESS ] BIN file: /tmp/tmph8bivt4w/tmp.bin\n",
      "[ SUCCESS ] Total execution time: 0.71 seconds. \n",
      "[ SUCCESS ] Memory consumed: 119 MB. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnumpy: installed: 1.21.6, required: < 1.20\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/tmp8djui2ig/tmp.xml\n",
      "[ SUCCESS ] BIN file: /tmp/tmp8djui2ig/tmp.bin\n",
      "[ SUCCESS ] Total execution time: 0.71 seconds. \n",
      "[ SUCCESS ] Memory consumed: 119 MB. \n",
      "('{} cannot be pickled', '_MultiProcessingDataLoaderIter')\n",
      "('{} cannot be pickled', '_MultiProcessingDataLoaderIter')\n",
      "==========================Optimization Results==========================\n",
      "accleration option: original, latency: 33.2929ms, accuracy : 0.6719\n",
      "accleration option: fp32_ipex, latency: 37.0083ms, accuracy : 0.6719\n",
      "accleration option: bf16_ipex, latency: 210.7912ms, accuracy : 0.6781\n",
      "accleration option: int8, latency: 35.7670ms, accuracy : 0.0031\n",
      "accleration option: jit_fp32, latency: 20.0340ms, accuracy : 0.6719\n",
      "accleration option: jit_fp32_ipex, latency: 19.7864ms, accuracy : 0.6719\n",
      "accleration option: jit_fp32_ipex_clast, latency: 15.4676ms, accuracy : 0.6719\n",
      "accleration option: openvino_fp32, latency: 10.9643ms, accuracy : 0.6719\n",
      "accleration option: openvino_int8, latency: 11.1145ms, accuracy : 0.6594\n",
      "accleration option: onnxruntime_fp32, latency: 33.4490ms, accuracy : 0.6719\n",
      "optimization cost 256.7454s\n",
      "best option is  openvino \n",
      "tensor(11113)\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model(\"mobilevit_xxs\", pretrained=True)\n",
    "\n",
    "optimizer = InferenceOptimizer()\n",
    "st = time.perf_counter()\n",
    "optimizer.optimize(model,\n",
    "                   training_data=faked_train_dataloader,\n",
    "                   validation_data=val_dataloader,\n",
    "                   metric=Accuracy(),\n",
    "                   direction=\"max\",\n",
    "                   cpu_num=1)\n",
    "end = time.perf_counter()\n",
    "print(\"optimization cost {:.4f}s\".format(end-st))\n",
    "acc_model, option = optimizer.get_best_model()\n",
    "print(\"best option is \", option)\n",
    "print(acc_model(next(iter(val_dataloader))[0]).argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. poolformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import Interpolation\n",
    "from timm.data.loader import create_loader\n",
    "\n",
    "fake_train_dataset = create_imagenet_val_dataset()\n",
    "val_dataset = create_imagenet_val_dataset(limit_num_samples=320)\n",
    "faked_train_dataloader = create_loader(fake_train_dataset,\n",
    "                               input_size=224,\n",
    "                               batch_size=1,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.485, 0.456, 0.406),\n",
    "                               std=(0.229, 0.224, 0.225))\n",
    "val_dataloader = create_loader(val_dataset,\n",
    "                               input_size=224,\n",
    "                               batch_size=32,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.485, 0.456, 0.406),\n",
    "                               std=(0.229, 0.224, 0.225))\n",
    "val_dataloader.dataset.dataset.transform = val_dataloader.dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-06 12:40:16 [ERROR] \n",
      "\n",
      "****************************Usage Error************************\n",
      "Your machine or OS doesn't support BF16 instructions.\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Usage Error************************\n",
      "Your machine or OS doesn't support BF16 instructions.\n",
      "2022-09-06 12:40:16 [ERROR] \n",
      "\n",
      "**************************How to fix***********************\n",
      "Please check your machine and OS to make sure BF16 support is available.\n",
      "[ ERROR ]  \n",
      "\n",
      "**************************How to fix***********************\n",
      "Please check your machine and OS to make sure BF16 support is available.\n",
      "2022-09-06 12:40:16 [ERROR] \n",
      "\n",
      "****************************Call Stack*************************\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Call Stack*************************\n",
      "2022-09-06 12:41:00 [ERROR] Unexpected exception AttributeError(\"'GraphModule' object has no attribute 'network.0.0.layer_scale_1'\") happened during tuning.\n",
      "[ ERROR ]  Unexpected exception AttributeError(\"'GraphModule' object has no attribute 'network.0.0.layer_scale_1'\") happened during tuning.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/experimental/quantization.py\", line 148, in execute\n",
      "    self.strategy.traverse()\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/strategy/strategy.py\", line 402, in traverse\n",
      "    tune_cfg, self.model, self.calib_dataloader, self.q_func)\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/utils/utility.py\", line 262, in fi\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/pytorch.py\", line 2658, in quantize\n",
      "    self._get_scale_zeropoint(q_model._model, q_model.q_config)\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/pytorch.py\", line 3036, in _get_scale_zeropoint\n",
      "    self._get_module_scale_zeropoint(model, tune_cfg)\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/pytorch.py\", line 2996, in _get_module_scale_zeropoint\n",
      "    tune_cfg['get_attr'][sub_name] = float(getattr(model, node.target))\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1208, in __getattr__\n",
      "    type(self).__name__, name))\n",
      "AttributeError: 'GraphModule' object has no attribute 'network.0.0.layer_scale_1'\n",
      "2022-09-06 12:41:00 [ERROR] Specified timeout or max trials is reached! Not found any quantized model which meet accuracy goal. Exit.\n",
      "[ ERROR ]  Specified timeout or max trials is reached! Not found any quantized model which meet accuracy goal. Exit.\n",
      "2022-09-06 12:41:00 [ERROR] \n",
      "\n",
      "****************************Usage Error************************\n",
      "Found no quantized model satisfying accuracy criterion.\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Usage Error************************\n",
      "Found no quantized model satisfying accuracy criterion.\n",
      "2022-09-06 12:41:00 [ERROR] \n",
      "\n",
      "****************************Call Stack*************************\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Call Stack*************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found no quantized model satisfying accuracy criterion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnumpy: installed: 1.21.6, required: < 1.20\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/tmp562kdxjy/tmp.xml\n",
      "[ SUCCESS ] BIN file: /tmp/tmp562kdxjy/tmp.bin\n",
      "[ SUCCESS ] Total execution time: 0.71 seconds. \n",
      "[ SUCCESS ] Memory consumed: 176 MB. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnumpy: installed: 1.21.6, required: < 1.20\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/tmpsjbjl_vl/tmp.xml\n",
      "[ SUCCESS ] BIN file: /tmp/tmpsjbjl_vl/tmp.bin\n",
      "[ SUCCESS ] Total execution time: 0.74 seconds. \n",
      "[ SUCCESS ] Memory consumed: 177 MB. \n",
      "('{} cannot be pickled', '_MultiProcessingDataLoaderIter')\n",
      "('{} cannot be pickled', '_MultiProcessingDataLoaderIter')\n",
      "==========================Optimization Results==========================\n",
      "accleration option: original, latency: 58.6403ms, accuracy : 0.7469\n",
      "accleration option: fp32_ipex, latency: 65.9670ms, accuracy : 0.7469\n",
      "accleration option: bf16_ipex, latency: 746.6169ms, accuracy : 0.7469\n",
      "accleration option: jit_fp32, latency: 60.0695ms, accuracy : 0.7469\n",
      "accleration option: jit_fp32_ipex, latency: 53.1404ms, accuracy : 0.7469\n",
      "accleration option: jit_fp32_ipex_clast, latency: 54.2720ms, accuracy : 0.7469\n",
      "accleration option: openvino_fp32, latency: 24.3597ms, accuracy : 0.7469\n",
      "accleration option: openvino_int8, latency: 14.7782ms, accuracy : 0.7344\n",
      "accleration option: onnxruntime_fp32, latency: 63.9340ms, accuracy : 0.7469\n",
      "optimization cost 255.0830s\n",
      "best option is  openvino + pot \n",
      "tensor(10395)\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model(\"poolformer_s12\", pretrained=True)\n",
    "\n",
    "optimizer = InferenceOptimizer()\n",
    "st = time.perf_counter()\n",
    "optimizer.optimize(model,\n",
    "                   training_data=faked_train_dataloader,\n",
    "                   validation_data=val_dataloader,\n",
    "                   metric=Accuracy(),\n",
    "                   direction=\"max\",\n",
    "                   cpu_num=1)\n",
    "end = time.perf_counter()\n",
    "print(\"optimization cost {:.4f}s\".format(end-st))\n",
    "acc_model, option = optimizer.get_best_model()\n",
    "print(\"best option is \", option)\n",
    "print(acc_model(next(iter(val_dataloader))[0]).argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. swin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import Interpolation\n",
    "from timm.data.loader import create_loader\n",
    "\n",
    "fake_train_dataset = create_imagenet_val_dataset()\n",
    "val_dataset = create_imagenet_val_dataset(limit_num_samples=320)\n",
    "faked_train_dataloader = create_loader(fake_train_dataset,\n",
    "                               input_size=224,\n",
    "                               batch_size=1,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.485, 0.456, 0.406),\n",
    "                               std=(0.229, 0.224, 0.225))\n",
    "val_dataloader = create_loader(val_dataset,\n",
    "                               input_size=224,\n",
    "                               batch_size=32,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.485, 0.456, 0.406),\n",
    "                               std=(0.229, 0.224, 0.225))\n",
    "val_dataloader.dataset.dataset.transform = val_dataloader.dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-06 17:17:55 [ERROR] \n",
      "\n",
      "****************************Usage Error************************\n",
      "Your machine or OS doesn't support BF16 instructions.\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Usage Error************************\n",
      "Your machine or OS doesn't support BF16 instructions.\n",
      "2022-09-06 17:17:55 [ERROR] \n",
      "\n",
      "**************************How to fix***********************\n",
      "Please check your machine and OS to make sure BF16 support is available.\n",
      "[ ERROR ]  \n",
      "\n",
      "**************************How to fix***********************\n",
      "Please check your machine and OS to make sure BF16 support is available.\n",
      "2022-09-06 17:17:55 [ERROR] \n",
      "\n",
      "****************************Call Stack*************************\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Call Stack*************************\n",
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnumpy: installed: 1.21.6, required: < 1.20\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/tmpnb4793_5/tmp.xml\n",
      "[ SUCCESS ] BIN file: /tmp/tmpnb4793_5/tmp.bin\n",
      "[ SUCCESS ] Total execution time: 4.85 seconds. \n",
      "[ SUCCESS ] Memory consumed: 800 MB. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnumpy: installed: 1.21.6, required: < 1.20\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/tmp8xdvlkgn/tmp.xml\n",
      "[ SUCCESS ] BIN file: /tmp/tmp8xdvlkgn/tmp.bin\n",
      "[ SUCCESS ] Total execution time: 4.80 seconds. \n",
      "[ SUCCESS ] Memory consumed: 801 MB. \n",
      "('{} cannot be pickled', '_MultiProcessingDataLoaderIter')\n",
      "('{} cannot be pickled', '_MultiProcessingDataLoaderIter')\n",
      "==========================Optimization Results==========================\n",
      "accleration option: original, latency: 411.2000ms, accuracy : 0.8625\n",
      "accleration option: fp32_ipex, latency: 397.5534ms, accuracy : 0.8625\n",
      "accleration option: bf16_ipex, latency: 2133.6425ms, accuracy : 0.8625\n",
      "accleration option: int8, latency: 224.6975ms, accuracy : 0.8594\n",
      "accleration option: jit_fp32, latency: 317.4087ms, accuracy : 0.0000\n",
      "accleration option: jit_fp32_ipex, latency: 320.1967ms, accuracy : 0.0000\n",
      "accleration option: jit_fp32_ipex_clast, latency: 314.8059ms, accuracy : 0.0000\n",
      "accleration option: openvino_fp32, latency: 178.8095ms, accuracy : 0.0000\n",
      "accleration option: openvino_int8, latency: 185.3657ms, accuracy : 0.0000\n",
      "accleration option: onnxruntime_fp32, latency: 427.2581ms, accuracy : 0.8625\n",
      "optimization cost 1169.6606s\n",
      "best option is  inc \n",
      "tensor(26149)\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model(\"swin_base_patch4_window7_224\", pretrained=True)\n",
    "\n",
    "optimizer = InferenceOptimizer()\n",
    "st = time.perf_counter()\n",
    "optimizer.optimize(model,\n",
    "                   training_data=faked_train_dataloader,\n",
    "                   validation_data=val_dataloader,\n",
    "                   metric=Accuracy(),\n",
    "                   direction=\"max\",\n",
    "                   cpu_num=1)\n",
    "end = time.perf_counter()\n",
    "print(\"optimization cost {:.4f}s\".format(end-st))\n",
    "acc_model, option = optimizer.get_best_model(accuracy_criterion=0.05)\n",
    "print(\"best option is \", option)\n",
    "print(acc_model(next(iter(val_dataloader))[0]).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "75c4387adfc215da0f2d9d02c27ad9a4df553a9f0187eec0365fe565a2e50216"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
