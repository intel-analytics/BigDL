{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer Examples for InferenceOptimizer\n",
    "\n",
    "Today, vison Transformer is becoming more and more popular among computer vision community. On the one hand, people are constantly searching for larger pre-training corpus and pre-training model, on the other hand, how to land the vision transformer in the industrial scene is also a very concerned issue.\n",
    "\n",
    "Here we take several popular vision Transformer architectures as examples to demonstrate how to use InferenceOptimizer in BigDL-Nano to accelerate inference pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  step 0 : Prepare the environment\n",
    "We recommend you to use [Anaconda](https://www.anaconda.com/distribution/#linux) to prepare the environment.\n",
    "\n",
    "**Note**: during your installation, there may be some warnings or errors about version, just ignore them.\n",
    "```bash\n",
    "conda create -n nano python=3.7  # \"nano\" is conda environment name, you can use any name you like.\n",
    "conda activate nano\n",
    "pip install jsonargparse[signatures]\n",
    "pip install --pre --upgrade bigdl-nano[pytorch]\n",
    "\n",
    "# bf16 is available only on torch1.12\n",
    "pip install torch==1.12.0 torchvision --extra-index-url https://download.pytorch.org/whl/cpu \n",
    "# Necessary packages for inference accelaration\n",
    "pip install --upgrade intel-extension-for-pytorch\n",
    "pip install onnx==1.12.0 onnxruntime==1.12.1 onnxruntime-extensions\n",
    "pip install openvino-dev\n",
    "pip install neural-compressor==1.12\n",
    "pip install --upgrade numpy==1.21.6\n",
    "```\n",
    "\n",
    "Initialize environment variables with script `bigdl-nano-init` installed with bigdl-nano, then unset environment variable `KMP_AFFINITY`.\n",
    "\n",
    "```bash\n",
    "source bigdl-nano-init\n",
    "unset KMP_AFFINITY\n",
    "``` \n",
    "\n",
    "You may find environment variables set like follows:\n",
    "\n",
    "```\n",
    "Setting OMP_NUM_THREADS...\n",
    "Setting OMP_NUM_THREADS specified for pytorch...\n",
    "Setting KMP_AFFINITY...\n",
    "Setting KMP_BLOCKTIME...\n",
    "Setting MALLOC_CONF...\n",
    "+++++ Env Variables +++++\n",
    "LD_PRELOAD=./../lib/libjemalloc.so\n",
    "MALLOC_CONF=oversize_threshold:1,background_thread:true,metadata_thp:auto,dirty_decay_ms:-1,muzzy_decay_ms:-1\n",
    "OMP_NUM_THREADS=112\n",
    "KMP_AFFINITY=granularity=fine,compact,1,0\n",
    "KMP_BLOCKTIME=1\n",
    "TF_ENABLE_ONEDNN_OPTS=\n",
    "+++++++++++++++++++++++++\n",
    "Complete.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1 : Prepare Dataset\n",
    "\n",
    "As InferenceOptimizer needs validation data to calculate accuracy metric, we need to download [ImageNet validation dataset](https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar) and [development kit](https://image-net.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz), and place them under directory `./img_data`.\n",
    "\n",
    "Here we provide a helper function `create_imagenet_val_dataset` to help users create a subset of ImageNet validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageNet\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def create_imagenet_val_dataset(limit_num_samples=None):\n",
    "    dataset = ImageNet(root=\"img_data\", split=\"val\")\n",
    "    if limit_num_samples is not None:\n",
    "        indices = np.random.permutation(len(dataset))[:limit_num_samples]\n",
    "        dataset = Subset(dataset, indices)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2 : Import related package\n",
    "\n",
    "[PyTorch Image Models (timm)](https://github.com/rwightman/pytorch-image-models) provides a collection of image models. Here we use some vision Transformer models with pre-trained weights provided by timm to demonstrate acceleration of InferenceOptimizer in BigDL-Nano. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigdl.nano.pytorch import InferenceOptimizer\n",
    "import timm\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3 : Define dataloader, model then optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MobileViT\n",
    "\n",
    "[MobileViT](https://arxiv.org/abs/2110.02178) is a light-weight, general-purpose, and mobile-friendly vision Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import Interpolation\n",
    "from timm.data.loader import create_loader\n",
    "\n",
    "fake_train_dataset = create_imagenet_val_dataset()\n",
    "val_dataset = create_imagenet_val_dataset(limit_num_samples=320)\n",
    "faked_train_dataloader = create_loader(fake_train_dataset,\n",
    "                                       input_size=256,\n",
    "                                       # in case we want to evaluate single sample latency, so set batch_size to 1\n",
    "                                       batch_size=1,\n",
    "                                       use_prefetcher=False,\n",
    "                                       no_aug=True,\n",
    "                                       crop_pct=0.9,\n",
    "                                       interpolation=\"bicubic\",\n",
    "                                       mean=(0.0, 0.0, 0.0),\n",
    "                                       std=(1.0, 1.0, 1.0),\n",
    "                                       persistent_workers=False)\n",
    "val_dataloader = create_loader(val_dataset,\n",
    "                               input_size=256,\n",
    "                               batch_size=32,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.0, 0.0, 0.0),\n",
    "                               std=(1.0, 1.0, 1.0),\n",
    "                               persistent_workers=False)\n",
    "val_dataloader.dataset.dataset.transform = val_dataloader.dataset.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "Actually we highly recommand users pass real training dataloader to `training_data` for calibration of quantization.\n",
    "But as ImageNet training set is too large to download, here we just use validation dataset as faked training dataset.\n",
    "\n",
    "If you want to get real performance on ImageNet validation set, you can just set `limit_num_samples=None`. Here we choose a subset to make inference pipeline faster and we just want to get a rough metric to evaluate the effect of quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================Start Optimization==========================\n",
      "----------Start test original model (1/13)----------\n",
      "----------Finish test original model (1/13)----------\n",
      "----------Start test fp32_ipex model (2/13)----------\n",
      "----------Finish test fp32_ipex model (2/13)----------\n",
      "----------Start test bf16 model (3/13)----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 10:03:10 [ERROR] \n",
      "\n",
      "****************************Usage Error************************\n",
      "Your machine or OS doesn't support BF16 instructions.\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Usage Error************************\n",
      "Your machine or OS doesn't support BF16 instructions.\n",
      "2022-09-14 10:03:10 [ERROR] \n",
      "\n",
      "**************************How to fix***********************\n",
      "Please check your machine and OS to make sure BF16 support is available.\n",
      "[ ERROR ]  \n",
      "\n",
      "**************************How to fix***********************\n",
      "Please check your machine and OS to make sure BF16 support is available.\n",
      "2022-09-14 10:03:10 [ERROR] \n",
      "\n",
      "****************************Call Stack*************************\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Call Stack*************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Start test bf16_ipex model (4/13)----------\n",
      "----------Start test int8 model (5/13)----------\n",
      "----------Finish test int8 model (5/13)----------\n",
      "----------Start test jit_fp32 model (6/13)----------\n",
      "----------Finish test jit_fp32 model (6/13)----------\n",
      "----------Start test jit_fp32_ipex model (7/13)----------\n",
      "----------Finish test jit_fp32_ipex model (7/13)----------\n",
      "----------Start test jit_fp32_ipex_channels_last model (8/13)----------\n",
      "----------Finish test jit_fp32_ipex_channels_last model (8/13)----------\n",
      "----------Start test openvino_fp32 model (9/13)----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnumpy: installed: 1.21.6, required: < 1.20\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/tmps802xcxh/tmp.xml\n",
      "[ SUCCESS ] BIN file: /tmp/tmps802xcxh/tmp.bin\n",
      "[ SUCCESS ] Total execution time: 0.77 seconds. \n",
      "[ SUCCESS ] Memory consumed: 120 MB. \n",
      "----------Finish test openvino_fp32 model (9/13)----------\n",
      "----------Start test openvino_int8 model (10/13)----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnumpy: installed: 1.21.6, required: < 1.20\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/tmpgw2wys7v/tmp.xml\n",
      "[ SUCCESS ] BIN file: /tmp/tmpgw2wys7v/tmp.bin\n",
      "[ SUCCESS ] Total execution time: 0.79 seconds. \n",
      "[ SUCCESS ] Memory consumed: 119 MB. \n",
      "----------Finish test openvino_int8 model (10/13)----------\n",
      "----------Start test onnxruntime_fp32 model (11/13)----------\n",
      "----------Finish test onnxruntime_fp32 model (11/13)----------\n",
      "----------Start test onnxruntime_int8_qlinear model (12/13)----------\n",
      "----------Finish test onnxruntime_int8_qlinear model (12/13)----------\n",
      "----------Start test onnxruntime_int8_integer model (13/13)----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 10:06:04 [ERROR] Unexpected exception IndexError('list index (2) out of range') happened during tuning.\n",
      "[ ERROR ]  Unexpected exception IndexError('list index (2) out of range') happened during tuning.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/experimental/quantization.py\", line 148, in execute\n",
      "    self.strategy.traverse()\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/strategy/strategy.py\", line 402, in traverse\n",
      "    tune_cfg, self.model, self.calib_dataloader, self.q_func)\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/utils/utility.py\", line 262, in fi\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/onnxrt.py\", line 168, in quantize\n",
      "    quantizer.quantize_model()\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/ox_utils/quantizer.py\", line 133, in quantize_model\n",
      "    self.convert_qdq_to_operator_oriented()\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/ox_utils/quantizer.py\", line 240, in convert_qdq_to_operator_oriented\n",
      "    op_converter.convert()\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/ox_utils/operators/conv.py\", line 46, in convert\n",
      "    inputs.append(parents[0].output[2])\n",
      "IndexError: list index (2) out of range\n",
      "2022-09-14 10:06:04 [ERROR] Specified timeout or max trials is reached! Not found any quantized model which meet accuracy goal. Exit.\n",
      "[ ERROR ]  Specified timeout or max trials is reached! Not found any quantized model which meet accuracy goal. Exit.\n",
      "2022-09-14 10:06:04 [ERROR] \n",
      "\n",
      "****************************Usage Error************************\n",
      "Found no quantized model satisfying accuracy criterion.\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Usage Error************************\n",
      "Found no quantized model satisfying accuracy criterion.\n",
      "2022-09-14 10:06:04 [ERROR] \n",
      "\n",
      "****************************Call Stack*************************\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Call Stack*************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found no quantized model satisfying accuracy criterion.\n",
      "----------Failed to convert to onnxruntime_int8_integer----------\n",
      "\n",
      "\n",
      "==========================Optimization Results==========================\n",
      " -------------------------------- ---------------------- -------------- ------------\n",
      "|             method             |        status        | latency(ms)  |  accuracy  |\n",
      " -------------------------------- ---------------------- -------------- ------------\n",
      "|            original            |      successful      |    25.371    |    0.7     |\n",
      "|           fp32_ipex            |      successful      |    27.616    |    0.7     |\n",
      "|              bf16              |   fail to forward    |     None     |    None    |\n",
      "|           bf16_ipex            |        pruned        |   741.684    |    None    |\n",
      "|              int8              |      successful      |    26.445    |   0.003    |\n",
      "|            jit_fp32            |      successful      |    20.644    |    0.7     |\n",
      "|         jit_fp32_ipex          |      successful      |    21.271    |    0.7     |\n",
      "|  jit_fp32_ipex_channels_last   |      successful      |    16.247    |    0.7     |\n",
      "|         openvino_fp32          |      successful      |    10.857    |    0.7     |\n",
      "|         openvino_int8          |      successful      |    54.911    |   0.675    |\n",
      "|        onnxruntime_fp32        |      successful      |    12.888    |    0.7     |\n",
      "|    onnxruntime_int8_qlinear    |      successful      |    11.648    |    0.0     |\n",
      "|    onnxruntime_int8_integer    |   fail to convert    |     None     |    None    |\n",
      " -------------------------------- ---------------------- -------------- ------------\n",
      "\n",
      "Optimization cost 1.83e+02s at all.\n",
      "===========================Stop Optimization===========================\n",
      "best option is  openvino \n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model(\"mobilevit_xxs\", pretrained=True)\n",
    "\n",
    "optimizer = InferenceOptimizer()\n",
    "optimizer.optimize(model,\n",
    "                   training_data=faked_train_dataloader,\n",
    "                   validation_data=val_dataloader,\n",
    "                   metric=Accuracy(),\n",
    "                   direction=\"max\",\n",
    "                   thread_num=1)\n",
    "acc_model, option = optimizer.get_best_model(accuracy_criterion=0.05)\n",
    "print(\"best option is \", option)\n",
    "# print(acc_model(next(iter(val_dataloader))[0]).argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PoolFormer\n",
    "\n",
    "[PoolFormer](https://arxiv.org/abs/2111.11418) verifys that the general architecture of the Transformers, instead of the specific token mixer module, is more essential to the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import Interpolation\n",
    "from timm.data.loader import create_loader\n",
    "\n",
    "fake_train_dataset = create_imagenet_val_dataset()\n",
    "val_dataset = create_imagenet_val_dataset(limit_num_samples=320)\n",
    "faked_train_dataloader = create_loader(fake_train_dataset,\n",
    "                               input_size=224,\n",
    "                               batch_size=1,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.485, 0.456, 0.406),\n",
    "                               std=(0.229, 0.224, 0.225),\n",
    "                               persistent_workers=False)\n",
    "val_dataloader = create_loader(val_dataset,\n",
    "                               input_size=224,\n",
    "                               batch_size=32,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.485, 0.456, 0.406),\n",
    "                               std=(0.229, 0.224, 0.225),\n",
    "                               persistent_workers=False)\n",
    "val_dataloader.dataset.dataset.transform = val_dataloader.dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================Start Optimization==========================\n",
      "----------Start test original model (1/13)----------\n",
      "----------Finish test original model (1/13)----------\n",
      "----------Start test fp32_ipex model (2/13)----------\n",
      "----------Finish test fp32_ipex model (2/13)----------\n",
      "----------Start test bf16 model (3/13)----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 09:54:02 [ERROR] \n",
      "\n",
      "****************************Usage Error************************\n",
      "Your machine or OS doesn't support BF16 instructions.\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Usage Error************************\n",
      "Your machine or OS doesn't support BF16 instructions.\n",
      "2022-09-14 09:54:02 [ERROR] \n",
      "\n",
      "**************************How to fix***********************\n",
      "Please check your machine and OS to make sure BF16 support is available.\n",
      "[ ERROR ]  \n",
      "\n",
      "**************************How to fix***********************\n",
      "Please check your machine and OS to make sure BF16 support is available.\n",
      "2022-09-14 09:54:02 [ERROR] \n",
      "\n",
      "****************************Call Stack*************************\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Call Stack*************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Start test bf16_ipex model (4/13)----------\n",
      "----------Start test int8 model (5/13)----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 09:54:17 [ERROR] Unexpected exception AttributeError(\"'GraphModule' object has no attribute 'network.0.0.layer_scale_1'\") happened during tuning.\n",
      "[ ERROR ]  Unexpected exception AttributeError(\"'GraphModule' object has no attribute 'network.0.0.layer_scale_1'\") happened during tuning.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/experimental/quantization.py\", line 148, in execute\n",
      "    self.strategy.traverse()\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/strategy/strategy.py\", line 402, in traverse\n",
      "    tune_cfg, self.model, self.calib_dataloader, self.q_func)\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/utils/utility.py\", line 262, in fi\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/pytorch.py\", line 2658, in quantize\n",
      "    self._get_scale_zeropoint(q_model._model, q_model.q_config)\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/pytorch.py\", line 3036, in _get_scale_zeropoint\n",
      "    self._get_module_scale_zeropoint(model, tune_cfg)\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/pytorch.py\", line 2996, in _get_module_scale_zeropoint\n",
      "    tune_cfg['get_attr'][sub_name] = float(getattr(model, node.target))\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1208, in __getattr__\n",
      "    type(self).__name__, name))\n",
      "AttributeError: 'GraphModule' object has no attribute 'network.0.0.layer_scale_1'\n",
      "2022-09-14 09:54:17 [ERROR] Specified timeout or max trials is reached! Not found any quantized model which meet accuracy goal. Exit.\n",
      "[ ERROR ]  Specified timeout or max trials is reached! Not found any quantized model which meet accuracy goal. Exit.\n",
      "2022-09-14 09:54:17 [ERROR] \n",
      "\n",
      "****************************Usage Error************************\n",
      "Found no quantized model satisfying accuracy criterion.\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Usage Error************************\n",
      "Found no quantized model satisfying accuracy criterion.\n",
      "2022-09-14 09:54:17 [ERROR] \n",
      "\n",
      "****************************Call Stack*************************\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Call Stack*************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found no quantized model satisfying accuracy criterion.\n",
      "----------Failed to convert to int8----------\n",
      "----------Start test jit_fp32 model (6/13)----------\n",
      "----------Start test jit_fp32_ipex model (7/13)----------\n",
      "----------Start test jit_fp32_ipex_channels_last model (8/13)----------\n",
      "----------Start test openvino_fp32 model (9/13)----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnumpy: installed: 1.21.6, required: < 1.20\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/tmpk2abopzq/tmp.xml\n",
      "[ SUCCESS ] BIN file: /tmp/tmpk2abopzq/tmp.bin\n",
      "[ SUCCESS ] Total execution time: 0.70 seconds. \n",
      "[ SUCCESS ] Memory consumed: 176 MB. \n",
      "----------Finish test openvino_fp32 model (9/13)----------\n",
      "----------Start test openvino_int8 model (10/13)----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnumpy: installed: 1.21.6, required: < 1.20\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/tmpttu1d3xz/tmp.xml\n",
      "[ SUCCESS ] BIN file: /tmp/tmpttu1d3xz/tmp.bin\n",
      "[ SUCCESS ] Total execution time: 0.70 seconds. \n",
      "[ SUCCESS ] Memory consumed: 177 MB. \n",
      "----------Finish test openvino_int8 model (10/13)----------\n",
      "----------Start test onnxruntime_fp32 model (11/13)----------\n",
      "----------Finish test onnxruntime_fp32 model (11/13)----------\n",
      "----------Start test onnxruntime_int8_qlinear model (12/13)----------\n",
      "----------Finish test onnxruntime_int8_qlinear model (12/13)----------\n",
      "----------Start test onnxruntime_int8_integer model (13/13)----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 09:56:26 [ERROR] Unexpected exception IndexError('list index (2) out of range') happened during tuning.\n",
      "[ ERROR ]  Unexpected exception IndexError('list index (2) out of range') happened during tuning.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/experimental/quantization.py\", line 148, in execute\n",
      "    self.strategy.traverse()\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/strategy/strategy.py\", line 402, in traverse\n",
      "    tune_cfg, self.model, self.calib_dataloader, self.q_func)\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/utils/utility.py\", line 262, in fi\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/onnxrt.py\", line 168, in quantize\n",
      "    quantizer.quantize_model()\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/ox_utils/quantizer.py\", line 133, in quantize_model\n",
      "    self.convert_qdq_to_operator_oriented()\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/ox_utils/quantizer.py\", line 240, in convert_qdq_to_operator_oriented\n",
      "    op_converter.convert()\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/ox_utils/operators/conv.py\", line 46, in convert\n",
      "    inputs.append(parents[0].output[2])\n",
      "IndexError: list index (2) out of range\n",
      "2022-09-14 09:56:26 [ERROR] Specified timeout or max trials is reached! Not found any quantized model which meet accuracy goal. Exit.\n",
      "[ ERROR ]  Specified timeout or max trials is reached! Not found any quantized model which meet accuracy goal. Exit.\n",
      "2022-09-14 09:56:26 [ERROR] \n",
      "\n",
      "****************************Usage Error************************\n",
      "Found no quantized model satisfying accuracy criterion.\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Usage Error************************\n",
      "Found no quantized model satisfying accuracy criterion.\n",
      "2022-09-14 09:56:26 [ERROR] \n",
      "\n",
      "****************************Call Stack*************************\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Call Stack*************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found no quantized model satisfying accuracy criterion.\n",
      "----------Failed to convert to onnxruntime_int8_integer----------\n",
      "\n",
      "\n",
      "==========================Optimization Results==========================\n",
      " -------------------------------- ---------------------- -------------- ------------\n",
      "|             method             |        status        | latency(ms)  |  accuracy  |\n",
      " -------------------------------- ---------------------- -------------- ------------\n",
      "|            original            |      successful      |    47.666    |   0.753    |\n",
      "|           fp32_ipex            |      successful      |    47.772    |   0.753    |\n",
      "|              bf16              |   fail to forward    |     None     |    None    |\n",
      "|           bf16_ipex            |        pruned        |   1273.455   |    None    |\n",
      "|              int8              |   fail to convert    |     None     |    None    |\n",
      "|            jit_fp32            |        pruned        |   446.669    |    None    |\n",
      "|         jit_fp32_ipex          |        pruned        |    453.32    |    None    |\n",
      "|  jit_fp32_ipex_channels_last   |        pruned        |    893.98    |    None    |\n",
      "|         openvino_fp32          |      successful      |    24.426    |   0.753    |\n",
      "|         openvino_int8          |      successful      |    36.097    |   0.731    |\n",
      "|        onnxruntime_fp32        |      successful      |    34.13     |   0.753    |\n",
      "|    onnxruntime_int8_qlinear    |      successful      |    31.469    |   0.709    |\n",
      "|    onnxruntime_int8_integer    |   fail to convert    |     None     |    None    |\n",
      " -------------------------------- ---------------------- -------------- ------------\n",
      "\n",
      "Optimization cost 1.52e+02s at all.\n",
      "===========================Stop Optimization===========================\n",
      "best option is  openvino \n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model(\"poolformer_s12\", pretrained=True)\n",
    "\n",
    "optimizer = InferenceOptimizer()\n",
    "optimizer.optimize(model,\n",
    "                   training_data=faked_train_dataloader,\n",
    "                   validation_data=val_dataloader,\n",
    "                   metric=Accuracy(),\n",
    "                   direction=\"max\",\n",
    "                   thread_num=1)\n",
    "acc_model, option = optimizer.get_best_model(accuracy_criterion=0.05)\n",
    "print(\"best option is \", option)\n",
    "# print(acc_model(next(iter(val_dataloader))[0]).argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Swin Transformer\n",
    "\n",
    "[Swin Transformer](https://arxiv.org/abs/2103.14030) proposes hierarchical vision Transformer using shifted windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import Interpolation\n",
    "from timm.data.loader import create_loader\n",
    "\n",
    "fake_train_dataset = create_imagenet_val_dataset()\n",
    "val_dataset = create_imagenet_val_dataset(limit_num_samples=20)\n",
    "faked_train_dataloader = create_loader(fake_train_dataset,\n",
    "                               input_size=224,\n",
    "                               batch_size=1,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.485, 0.456, 0.406),\n",
    "                               std=(0.229, 0.224, 0.225),\n",
    "                               persistent_workers=False)\n",
    "# swin don't support dynamic batch, so the batch_size of faked_train_dataloader must be the same with val_dataloader\n",
    "# otherwise the accuracy will be really slow.\n",
    "val_dataloader = create_loader(val_dataset,\n",
    "                               input_size=224,\n",
    "                               batch_size=1,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.485, 0.456, 0.406),\n",
    "                               std=(0.229, 0.224, 0.225),\n",
    "                               persistent_workers=False)\n",
    "val_dataloader.dataset.dataset.transform = val_dataloader.dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================Start Optimization==========================\n",
      "----------Start test original model (1/13)----------\n",
      "----------Finish test original model (1/13)----------\n",
      "----------Start test fp32_ipex model (2/13)----------\n",
      "----------Finish test fp32_ipex model (2/13)----------\n",
      "----------Start test bf16 model (3/13)----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 09:39:24 [ERROR] \n",
      "\n",
      "****************************Usage Error************************\n",
      "Your machine or OS doesn't support BF16 instructions.\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Usage Error************************\n",
      "Your machine or OS doesn't support BF16 instructions.\n",
      "2022-09-14 09:39:24 [ERROR] \n",
      "\n",
      "**************************How to fix***********************\n",
      "Please check your machine and OS to make sure BF16 support is available.\n",
      "[ ERROR ]  \n",
      "\n",
      "**************************How to fix***********************\n",
      "Please check your machine and OS to make sure BF16 support is available.\n",
      "2022-09-14 09:39:24 [ERROR] \n",
      "\n",
      "****************************Call Stack*************************\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Call Stack*************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Start test bf16_ipex model (4/13)----------\n",
      "----------Start test int8 model (5/13)----------\n",
      "----------Finish test int8 model (5/13)----------\n",
      "----------Start test jit_fp32 model (6/13)----------\n",
      "----------Finish test jit_fp32 model (6/13)----------\n",
      "----------Start test jit_fp32_ipex model (7/13)----------\n",
      "----------Finish test jit_fp32_ipex model (7/13)----------\n",
      "----------Start test jit_fp32_ipex_channels_last model (8/13)----------\n",
      "----------Finish test jit_fp32_ipex_channels_last model (8/13)----------\n",
      "----------Start test openvino_fp32 model (9/13)----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnumpy: installed: 1.21.6, required: < 1.20\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/tmp3z67y07f/tmp.xml\n",
      "[ SUCCESS ] BIN file: /tmp/tmp3z67y07f/tmp.bin\n",
      "[ SUCCESS ] Total execution time: 3.97 seconds. \n",
      "[ SUCCESS ] Memory consumed: 801 MB. \n",
      "----------Finish test openvino_fp32 model (9/13)----------\n",
      "----------Start test openvino_int8 model (10/13)----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARNING ]  \n",
      "Detected not satisfied dependencies:\n",
      "\tnumpy: installed: 1.21.6, required: < 1.20\n",
      "\n",
      "Please install required versions of components or run pip installation\n",
      "pip install openvino-dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /tmp/tmprvdjr6c9/tmp.xml\n",
      "[ SUCCESS ] BIN file: /tmp/tmprvdjr6c9/tmp.bin\n",
      "[ SUCCESS ] Total execution time: 4.00 seconds. \n",
      "[ SUCCESS ] Memory consumed: 800 MB. \n",
      "----------Finish test openvino_int8 model (10/13)----------\n",
      "----------Start test onnxruntime_fp32 model (11/13)----------\n",
      "----------Finish test onnxruntime_fp32 model (11/13)----------\n",
      "----------Start test onnxruntime_int8_qlinear model (12/13)----------\n",
      "----------Finish test onnxruntime_int8_qlinear model (12/13)----------\n",
      "----------Start test onnxruntime_int8_integer model (13/13)----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 09:51:12 [ERROR] Unexpected exception IndexError('list index (2) out of range') happened during tuning.\n",
      "[ ERROR ]  Unexpected exception IndexError('list index (2) out of range') happened during tuning.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/experimental/quantization.py\", line 148, in execute\n",
      "    self.strategy.traverse()\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/strategy/strategy.py\", line 402, in traverse\n",
      "    tune_cfg, self.model, self.calib_dataloader, self.q_func)\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/utils/utility.py\", line 262, in fi\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/onnxrt.py\", line 168, in quantize\n",
      "    quantizer.quantize_model()\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/ox_utils/quantizer.py\", line 133, in quantize_model\n",
      "    self.convert_qdq_to_operator_oriented()\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/ox_utils/quantizer.py\", line 240, in convert_qdq_to_operator_oriented\n",
      "    op_converter.convert()\n",
      "  File \"/opt/anaconda3/envs/nano/lib/python3.7/site-packages/neural_compressor/adaptor/ox_utils/operators/conv.py\", line 46, in convert\n",
      "    inputs.append(parents[0].output[2])\n",
      "IndexError: list index (2) out of range\n",
      "2022-09-14 09:51:12 [ERROR] Specified timeout or max trials is reached! Not found any quantized model which meet accuracy goal. Exit.\n",
      "[ ERROR ]  Specified timeout or max trials is reached! Not found any quantized model which meet accuracy goal. Exit.\n",
      "2022-09-14 09:51:12 [ERROR] \n",
      "\n",
      "****************************Usage Error************************\n",
      "Found no quantized model satisfying accuracy criterion.\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Usage Error************************\n",
      "Found no quantized model satisfying accuracy criterion.\n",
      "2022-09-14 09:51:12 [ERROR] \n",
      "\n",
      "****************************Call Stack*************************\n",
      "[ ERROR ]  \n",
      "\n",
      "****************************Call Stack*************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found no quantized model satisfying accuracy criterion.\n",
      "----------Failed to convert to onnxruntime_int8_integer----------\n",
      "\n",
      "\n",
      "==========================Optimization Results==========================\n",
      " -------------------------------- ---------------------- -------------- ------------\n",
      "|             method             |        status        | latency(ms)  |  accuracy  |\n",
      " -------------------------------- ---------------------- -------------- ------------\n",
      "|            original            |      successful      |   297.254    |    1.0     |\n",
      "|           fp32_ipex            |      successful      |   308.671    |    1.0     |\n",
      "|              bf16              |   fail to forward    |     None     |    None    |\n",
      "|           bf16_ipex            |        pruned        |    705.62    |    None    |\n",
      "|              int8              |      successful      |   178.878    |    0.95    |\n",
      "|            jit_fp32            |      successful      |    273.09    |    1.0     |\n",
      "|         jit_fp32_ipex          |      successful      |   285.691    |    1.0     |\n",
      "|  jit_fp32_ipex_channels_last   |      successful      |   287.069    |    1.0     |\n",
      "|         openvino_fp32          |      successful      |   176.311    |    1.0     |\n",
      "|         openvino_int8          |      successful      |   295.461    |    0.0     |\n",
      "|        onnxruntime_fp32        |      successful      |   279.095    |    1.0     |\n",
      "|    onnxruntime_int8_qlinear    |      successful      |   134.355    |    0.75    |\n",
      "|    onnxruntime_int8_integer    |   fail to convert    |     None     |    None    |\n",
      " -------------------------------- ---------------------- -------------- ------------\n",
      "\n",
      "Optimization cost 7.17e+02s at all.\n",
      "===========================Stop Optimization===========================\n",
      "best option is  openvino \n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model(\"swin_base_patch4_window7_224\", pretrained=True)\n",
    "\n",
    "optimizer = InferenceOptimizer()\n",
    "optimizer.optimize(model,\n",
    "                   training_data=faked_train_dataloader,\n",
    "                   validation_data=val_dataloader,\n",
    "                   metric=Accuracy(),\n",
    "                   direction=\"max\",\n",
    "                   thread_num=1)\n",
    "acc_model, option = optimizer.get_best_model(accuracy_criterion=0.05)\n",
    "print(\"best option is \", option)\n",
    "# print(acc_model(next(iter(val_dataloader))[0]).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "75c4387adfc215da0f2d9d02c27ad9a4df553a9f0187eec0365fe565a2e50216"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
