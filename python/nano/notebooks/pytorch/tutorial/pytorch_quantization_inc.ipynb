{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantize Model with Intel Neural Compressor\n",
    "### Prepare Environment\n",
    "Before you start with Apis delivered by bigdl-nano, you have to make sure BigDL-Nano is correctly installed for PyTorch. If not, please follow [this](../../../../../docs/readthedocs/source/doc/Nano/Overview/nano.md) to set up your environment.<br><br>\n",
    "By default, Intel Neural Compressor is not installed with BigDL-Nano. So if you determine to use it as your quantization backend, you'll need to install it first:\n",
    "```shell\n",
    "pip install neural-compressor==1.11.0\n",
    "```\n",
    "It's also required to install onnxruntime-extensions as a dependency of INC when using ONNXRuntime as backend as well as the dependencies of onnxruntime\n",
    "```bash\n",
    "pip install onnx onnxruntime\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "We used the [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/) for demo, which contains 37 categories with roughly 200 images for each classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.RandomCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ColorJitter(brightness=.5, hue=.3),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "val_transform = transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "# Apply data augmentation to the tarin_dataset\n",
    "train_dataset = OxfordIIITPet(root = \".\", transform=train_transform)\n",
    "val_dataset = OxfordIIITPet(root=\".\", transform=val_transform)\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "indices = torch.randperm(len(train_dataset))\n",
    "val_size = len(train_dataset) // 4\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, indices[:-val_size])\n",
    "val_dataset = torch.utils.data.Subset(val_dataset, indices[-val_size:])\n",
    "\n",
    "# prepare data loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Model\n",
    "Regarding the model, we used pretrained torchvision.models.resnet18. More details, please refer to [here](https://pytorch.org/vision/0.12/generated/torchvision.models.resnet18.html?highlight=resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:532: LightningDeprecationWarning: `trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.fit(train_dataloaders)` instead. HINT: added 's'\n",
      "  \"`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\"\n",
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/pytorch_lightning/trainer/configuration_validator.py:101: UserWarning: you defined a validation_step but have no val_dataloader. Skipping val loop\n",
      "  rank_zero_warn(f\"you defined a {step_name} but have no {loader_name}. Skipping {stage} loop\")\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | ResNet           | 11.2 M\n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.782    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:106: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 96 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 87/87 [01:09<00:00,  1.26it/s, loss=0.261, v_num=0]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([10, 16])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "from bigdl.nano.pytorch import Trainer\n",
    "from torchmetrics import Accuracy\n",
    "model_ft = resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# Here the size of each output sample is set to 37.\n",
    "model_ft.fc = torch.nn.Linear(num_ftrs, 37)\n",
    "loss_ft = torch.nn.CrossEntropyLoss()\n",
    "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Compile our model with loss function, optimizer.\n",
    "model = Trainer.compile(model_ft, loss_ft, optimizer_ft, metrics=[Accuracy])\n",
    "trainer = Trainer(max_epochs=5)\n",
    "trainer.fit(model, train_dataloader=train_dataloader)\n",
    "\n",
    "# Inference/Prediction\n",
    "x = torch.stack([val_dataset[0][0], val_dataset[1][0]])\n",
    "model_ft.eval()\n",
    "y_hat = model_ft(x)\n",
    "y_hat.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization without extra accelerator\n",
    "To use INC as your quantization engine, you can choose accelerator as None or 'onnxruntime'.<br>\n",
    "Without extra accelerator, `Trainer.quantize()` returns a pytorch module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 08:55:30 [WARNING] Override the value of `metric` field defined in yaml file as user defines the value of `metric` attribute by code.\n",
      "2022-06-30 08:55:30 [INFO] Pass query framework capability elapsed time: 181.87 ms\n",
      "2022-06-30 08:55:30 [INFO] Get FP32 model baseline.\n",
      "2022-06-30 08:56:00 [INFO] Save tuning history to /home/projects/BigDL/python/nano/notebooks/pytorch/tutorial/nc_workspace/2022-06-30_08-55-29/./history.snapshot.\n",
      "2022-06-30 08:56:00 [INFO] FP32 baseline is: [Accuracy: 0.8826, Duration (seconds): 29.4115]\n",
      "2022-06-30 08:56:00 [WARNING] Please note that calibration sampling size 100 isn't divisible exactly by batch size 32. So the real sampling size is 128.\n",
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/torch/nn/quantized/_reference/modules/conv.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(weight_qparams[\"scale\"], dtype=torch.float, device=device))\n",
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/torch/nn/quantized/_reference/modules/conv.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(weight_qparams[\"zero_point\"], dtype=torch.int, device=device))\n",
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/torch/nn/quantized/_reference/modules/linear.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(weight_qparams[\"scale\"], dtype=torch.float, device=device))\n",
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/torch/nn/quantized/_reference/modules/linear.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dtype=torch.int, device=device))\n",
      "2022-06-30 08:56:02 [INFO] |********Mixed Precision Statistics*******|\n",
      "2022-06-30 08:56:02 [INFO] +------------------------+--------+-------+\n",
      "2022-06-30 08:56:02 [INFO] |        Op Type         | Total  |  INT8 |\n",
      "2022-06-30 08:56:02 [INFO] +------------------------+--------+-------+\n",
      "2022-06-30 08:56:02 [INFO] |  quantize_per_tensor   |   1    |   1   |\n",
      "2022-06-30 08:56:02 [INFO] |       ConvReLU2d       |   9    |   9   |\n",
      "2022-06-30 08:56:02 [INFO] |       MaxPool2d        |   1    |   1   |\n",
      "2022-06-30 08:56:02 [INFO] |         Conv2d         |   11   |   11  |\n",
      "2022-06-30 08:56:02 [INFO] |        add_relu        |   8    |   8   |\n",
      "2022-06-30 08:56:02 [INFO] |   AdaptiveAvgPool2d    |   1    |   1   |\n",
      "2022-06-30 08:56:02 [INFO] |        flatten         |   1    |   1   |\n",
      "2022-06-30 08:56:02 [INFO] |         Linear         |   1    |   1   |\n",
      "2022-06-30 08:56:02 [INFO] |       dequantize       |   1    |   1   |\n",
      "2022-06-30 08:56:02 [INFO] +------------------------+--------+-------+\n",
      "2022-06-30 08:56:02 [INFO] Pass quantize model elapsed time: 2215.05 ms\n",
      "2022-06-30 08:56:29 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 0.8790|0.8826, Duration (seconds) (int8|fp32): 26.6568|29.4115], Best tune result is: [Accuracy: 0.8790, Duration (seconds): 26.6568]\n",
      "2022-06-30 08:56:29 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2022-06-30 08:56:29 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-06-30 08:56:29 [INFO] |     Info Type      | Baseline | Tune 1 result | Best tune result |\n",
      "2022-06-30 08:56:29 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-06-30 08:56:29 [INFO] |      Accuracy      | 0.8826   |    0.8790     |     0.8790       |\n",
      "2022-06-30 08:56:29 [INFO] | Duration (seconds) | 29.4115  |    26.6568    |     26.6568      |\n",
      "2022-06-30 08:56:29 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-06-30 08:56:29 [INFO] Save tuning history to /home/projects/BigDL/python/nano/notebooks/pytorch/tutorial/nc_workspace/2022-06-30_08-55-29/./history.snapshot.\n",
      "2022-06-30 08:56:29 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2022-06-30 08:56:29 [INFO] Save deploy yaml to /home/projects/BigDL/python/nano/notebooks/pytorch/tutorial/nc_workspace/2022-06-30_08-55-29/deploy.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([10, 16])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.functional import accuracy\n",
    "q_model = trainer.quantize(model, calib_dataloader=train_dataloader, metric=accuracy)\n",
    "y_hat = q_model(x)\n",
    "y_hat.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization with ONNXRuntime accelerator\n",
    "With the ONNXRuntime accelerator, `Trainer.quantize()` will return a model with compressed precision but running inference in the ONNXRuntime engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 08:57:27 [WARNING] Override the value of `metric` field defined in yaml file as user defines the value of `metric` attribute by code.\n",
      "2022-06-30 08:57:27 [INFO] Get FP32 model baseline.\n",
      "2022-06-30 08:58:02 [INFO] Save tuning history to /home/projects/BigDL/python/nano/notebooks/pytorch/tutorial/nc_workspace/2022-06-30_08-55-29/./history.snapshot.\n",
      "2022-06-30 08:58:02 [INFO] FP32 baseline is: [Accuracy: 0.8797, Duration (seconds): 34.5989]\n",
      "2022-06-30 08:58:02 [WARNING] Please note that calibration sampling size 100 isn't divisible exactly by batch size 32. So the real sampling size is 128.\n",
      "tcmalloc: large alloc 1073741824 bytes == 0x562c52ac6000 @  0x7fc88f388d3f 0x7fc88f3bf0c0 0x7fc88f3c2082 0x7fc88f3c2243 0x7fc7e91d416c 0x7fc7e93a28d4 0x7fc7e91ec1df 0x7fc7e92363c6 0x7fc7e922e9e4 0x7fc7e8e50cce 0x7fc7e8e514e2 0x7fc7e8dfe3d4 0x7fc7e8dca6e2 0x562bc0d93e74 0x562bc0df2507 0x562bc0daa591 0x562bc0dc16d5 0x562bc0d5f6ad 0x562bc0d8daf1 0x562bc0daa3a5 0x562bc0dbe11a 0x562bc0d5fe03 0x562bc0d8da40 0x562bc0daa3a5 0x562bc0dbe11a 0x562bc0d5f6ad 0x562bc0d8daf1 0x562bc0daa3a5 0x562bc0dbe11a 0x562bc0d5fd04 0x562bc0d8da40\n",
      "2022-06-30 08:58:07 [INFO] |*******Mixed Precision Statistics******|\n",
      "2022-06-30 08:58:07 [INFO] +----------------------+--------+-------+\n",
      "2022-06-30 08:58:07 [INFO] |       Op Type        | Total  |  INT8 |\n",
      "2022-06-30 08:58:07 [INFO] +----------------------+--------+-------+\n",
      "2022-06-30 08:58:07 [INFO] |         Conv         |   20   |   20  |\n",
      "2022-06-30 08:58:07 [INFO] |        MatMul        |   1    |   1   |\n",
      "2022-06-30 08:58:07 [INFO] |       MaxPool        |   1    |   1   |\n",
      "2022-06-30 08:58:07 [INFO] |  GlobalAveragePool   |   1    |   1   |\n",
      "2022-06-30 08:58:07 [INFO] |         Add          |   9    |   9   |\n",
      "2022-06-30 08:58:07 [INFO] |    QuantizeLinear    |   3    |   3   |\n",
      "2022-06-30 08:58:07 [INFO] |   DequantizeLinear   |   3    |   3   |\n",
      "2022-06-30 08:58:07 [INFO] +----------------------+--------+-------+\n",
      "2022-06-30 08:58:07 [INFO] Pass quantize model elapsed time: 5535.98 ms\n",
      "2022-06-30 08:58:48 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 0.8826|0.8797, Duration (seconds) (int8|fp32): 40.7413|34.5989], Best tune result is: [Accuracy: 0.8826, Duration (seconds): 40.7413]\n",
      "2022-06-30 08:58:48 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2022-06-30 08:58:48 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-06-30 08:58:48 [INFO] |     Info Type      | Baseline | Tune 1 result | Best tune result |\n",
      "2022-06-30 08:58:48 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-06-30 08:58:48 [INFO] |      Accuracy      | 0.8797   |    0.8826     |     0.8826       |\n",
      "2022-06-30 08:58:48 [INFO] | Duration (seconds) | 34.5989  |    40.7413    |     40.7413      |\n",
      "2022-06-30 08:58:48 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-06-30 08:58:48 [INFO] Save tuning history to /home/projects/BigDL/python/nano/notebooks/pytorch/tutorial/nc_workspace/2022-06-30_08-55-29/./history.snapshot.\n",
      "2022-06-30 08:58:48 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2022-06-30 08:58:48 [INFO] Save deploy yaml to /home/projects/BigDL/python/nano/notebooks/pytorch/tutorial/nc_workspace/2022-06-30_08-55-29/deploy.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([10, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_q_model = trainer.quantize(model, accelerator='onnxruntime', calib_dataloader=train_dataloader, metric=accuracy)\n",
    "y_hat = ort_q_model(x)\n",
    "y_hat.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('testVscode')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e4962c53c6ef7ea4348d410747e78580ab0e1631d139dfbe170b5701abbb022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
