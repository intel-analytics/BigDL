{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantize Model with Intel Neural Compressor\n",
    "### Prepare Environment\n",
    "Before you start with Apis delivered by bigdl-nano, you have to make sure BigDL-Nano is correctly installed for PyTorch. If not, please follow [this](../../../../../docs/readthedocs/source/doc/Nano/Overview/nano.md) to set up your environment.<br><br>\n",
    "By default, Intel Neural Compressor is not installed with BigDL-Nano. So if you determine to use it as your quantization backend, you'll need to install it first:\n",
    "```shell\n",
    "pip install neural-compressor==1.11.0\n",
    "```\n",
    "It's also required to install onnxruntime-extensions as a dependency of INC when using ONNXRuntime as backend as well as the dependencies of onnxruntime\n",
    "```bash\n",
    "pip install onnx onnxruntime\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "We used the [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/) for demo, which contains 37 categories with roughly 200 images for each classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=.5, hue=.3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "data_set = OxfordIIITPet(root=\"./data/\", transform=data_transforms)\n",
    "data_loader = DataLoader(data_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Model\n",
    "Regarding the model, we used pretrained torchvision.models.resnet18. More details, please refer to [here](https://pytorch.org/vision/0.12/generated/torchvision.models.resnet18.html?highlight=resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:532: LightningDeprecationWarning: `trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.fit(train_dataloaders)` instead. HINT: added 's'\n",
      "  \"`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\"\n",
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/pytorch_lightning/trainer/configuration_validator.py:101: UserWarning: you defined a validation_step but have no val_dataloader. Skipping val loop\n",
      "  rank_zero_warn(f\"you defined a {step_name} but have no {loader_name}. Skipping {stage} loop\")\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | ResNet           | 11.2 M\n",
      "1 | loss  | CrossEntropyLoss | 0     \n",
      "-------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.782    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:106: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 96 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 115/115 [00:56<00:00,  2.07it/s, loss=0.453, v_num=37] \n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# define your own model\n",
    "model_ft = resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(data_set.classes))\n",
    "loss_ft = nn.CrossEntropyLoss()\n",
    "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "from bigdl.nano.pytorch import Trainer\n",
    "model = Trainer.compile(model_ft, loss_ft, optimizer_ft)\n",
    "# (Optional) Something else, like training ...\n",
    "trainer = Trainer(max_epochs=5)\n",
    "trainer.fit(model, train_dataloader=data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization without extra accelerator\n",
    "To use INC as your quantization engine, you can choose accelerator as None or 'onnxruntime'.<br>\n",
    "Without extra accelerator, `Trainer.quantize()` returns a pytorch module with desired precision and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 03:37:50 [WARNING] Override the value of `metric` field defined in yaml file as user defines the value of `metric` attribute by code.\n",
      "2022-06-28 03:37:50 [INFO] Pass query framework capability elapsed time: 192.36 ms\n",
      "2022-06-28 03:37:50 [INFO] Get FP32 model baseline.\n",
      "2022-06-28 03:38:29 [INFO] Save tuning history to /home/projects/BigDL/python/nano/notebooks/pytorch/tutorial/nc_workspace/2022-06-28_03-37-49/./history.snapshot.\n",
      "2022-06-28 03:38:30 [INFO] FP32 baseline is: [Accuracy: 0.8446, Duration (seconds): 38.6896]\n",
      "2022-06-28 03:38:30 [WARNING] Please note that calibration sampling size 100 isn't divisible exactly by batch size 32. So the real sampling size is 128.\n",
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/torch/nn/quantized/_reference/modules/conv.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(weight_qparams[\"scale\"], dtype=torch.float, device=device))\n",
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/torch/nn/quantized/_reference/modules/conv.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(weight_qparams[\"zero_point\"], dtype=torch.int, device=device))\n",
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/torch/nn/quantized/_reference/modules/linear.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(weight_qparams[\"scale\"], dtype=torch.float, device=device))\n",
      "/opt/conda/envs/testVscode/lib/python3.7/site-packages/torch/nn/quantized/_reference/modules/linear.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dtype=torch.int, device=device))\n",
      "2022-06-28 03:38:32 [INFO] |********Mixed Precision Statistics*******|\n",
      "2022-06-28 03:38:32 [INFO] +------------------------+--------+-------+\n",
      "2022-06-28 03:38:32 [INFO] |        Op Type         | Total  |  INT8 |\n",
      "2022-06-28 03:38:32 [INFO] +------------------------+--------+-------+\n",
      "2022-06-28 03:38:32 [INFO] |  quantize_per_tensor   |   1    |   1   |\n",
      "2022-06-28 03:38:32 [INFO] |       ConvReLU2d       |   9    |   9   |\n",
      "2022-06-28 03:38:32 [INFO] |       MaxPool2d        |   1    |   1   |\n",
      "2022-06-28 03:38:32 [INFO] |         Conv2d         |   11   |   11  |\n",
      "2022-06-28 03:38:32 [INFO] |        add_relu        |   8    |   8   |\n",
      "2022-06-28 03:38:32 [INFO] |   AdaptiveAvgPool2d    |   1    |   1   |\n",
      "2022-06-28 03:38:32 [INFO] |        flatten         |   1    |   1   |\n",
      "2022-06-28 03:38:32 [INFO] |         Linear         |   1    |   1   |\n",
      "2022-06-28 03:38:32 [INFO] |       dequantize       |   1    |   1   |\n",
      "2022-06-28 03:38:32 [INFO] +------------------------+--------+-------+\n",
      "2022-06-28 03:38:32 [INFO] Pass quantize model elapsed time: 2207.83 ms\n",
      "2022-06-28 03:39:08 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 0.8481|0.8446, Duration (seconds) (int8|fp32): 35.4077|38.6896], Best tune result is: [Accuracy: 0.8481, Duration (seconds): 35.4077]\n",
      "2022-06-28 03:39:08 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2022-06-28 03:39:08 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-06-28 03:39:08 [INFO] |     Info Type      | Baseline | Tune 1 result | Best tune result |\n",
      "2022-06-28 03:39:08 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-06-28 03:39:08 [INFO] |      Accuracy      | 0.8446   |    0.8481     |     0.8481       |\n",
      "2022-06-28 03:39:08 [INFO] | Duration (seconds) | 38.6896  |    35.4077    |     35.4077      |\n",
      "2022-06-28 03:39:08 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-06-28 03:39:08 [INFO] Save tuning history to /home/projects/BigDL/python/nano/notebooks/pytorch/tutorial/nc_workspace/2022-06-28_03-37-49/./history.snapshot.\n",
      "2022-06-28 03:39:08 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2022-06-28 03:39:08 [INFO] Save deploy yaml to /home/projects/BigDL/python/nano/notebooks/pytorch/tutorial/nc_workspace/2022-06-28_03-37-49/deploy.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[12.9424, -3.7575, -2.7833, -3.4791,  0.1392,  9.8807, -2.3658,  4.1750,\n",
       "         -0.1392,  1.2525,  0.9742,  6.8191, -1.9483, -1.2525, -0.8350, -4.5924,\n",
       "         -3.4791, -4.0358, -2.9225, -2.6441,  7.6541,  2.0875, -5.2883, -2.5050,\n",
       "         -1.2525, -2.6441,  3.2008,  4.1750, -3.8966, -4.1750, -0.9742,  3.7575,\n",
       "          1.3917,  1.2525, -4.0358,  0.6958,  0.4175],\n",
       "        [ 9.8807,  0.8350, -2.0875, -3.0616,  0.8350,  5.0099, -2.7833,  2.7833,\n",
       "          2.5050,  2.5050,  2.9225,  4.3141, -3.4791, -1.5308, -0.1392, -5.2883,\n",
       "         -2.0875, -2.6441, -3.8966, -4.1750,  0.8350,  5.1491, -4.7316, -2.3658,\n",
       "         -2.2266, -1.2525,  0.4175,  2.7833, -3.7575, -4.1750, -0.4175,  3.7575,\n",
       "          2.5050,  9.8807, -2.6441, -0.8350,  0.0000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.functional import accuracy\n",
    "q_model = trainer.quantize(model, calib_dataloader=data_loader, metric=accuracy)\n",
    "batch = torch.stack([data_set[0][0], data_set[1][0]])\n",
    "q_model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization with ONNXRuntime accelerator\n",
    "With the ONNXRuntime accelerator, `Trainer.quantize()` will return a model with compressed precision but running inference in the ONNXRuntime engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 03:39:10 [WARNING] Override the value of `metric` field defined in yaml file as user defines the value of `metric` attribute by code.\n",
      "2022-06-28 03:39:10 [INFO] Get FP32 model baseline.\n",
      "2022-06-28 03:39:56 [INFO] Save tuning history to /home/projects/BigDL/python/nano/notebooks/pytorch/tutorial/nc_workspace/2022-06-28_03-37-49/./history.snapshot.\n",
      "2022-06-28 03:39:56 [INFO] FP32 baseline is: [Accuracy: 0.8470, Duration (seconds): 45.8410]\n",
      "2022-06-28 03:39:56 [WARNING] Please note that calibration sampling size 100 isn't divisible exactly by batch size 32. So the real sampling size is 128.\n",
      "tcmalloc: large alloc 1073741824 bytes == 0x557ae7548000 @  0x7f6f50fc5d3f 0x7f6f50ffc0c0 0x7f6f50fff082 0x7f6f50fff243 0x7f6eac41116c 0x7f6eac5df8d4 0x7f6eac4291df 0x7f6eac4733c6 0x7f6eac46b9e4 0x7f6eac08dcce 0x7f6eac08e4e2 0x7f6eac03b3d4 0x7f6eac0076e2 0x557a5837ee74 0x557a583dd507 0x557a58395591 0x557a583ac6d5 0x557a5834a6ad 0x557a58378af1 0x557a583953a5 0x557a583a911a 0x557a5834ae03 0x557a58378a40 0x557a583953a5 0x557a583a911a 0x557a5834a6ad 0x557a58378af1 0x557a583953a5 0x557a583a911a 0x557a5834ad04 0x557a58378a40\n",
      "2022-06-28 03:40:01 [INFO] |*******Mixed Precision Statistics******|\n",
      "2022-06-28 03:40:01 [INFO] +----------------------+--------+-------+\n",
      "2022-06-28 03:40:01 [INFO] |       Op Type        | Total  |  INT8 |\n",
      "2022-06-28 03:40:01 [INFO] +----------------------+--------+-------+\n",
      "2022-06-28 03:40:01 [INFO] |         Conv         |   20   |   20  |\n",
      "2022-06-28 03:40:01 [INFO] |        MatMul        |   1    |   1   |\n",
      "2022-06-28 03:40:01 [INFO] |       MaxPool        |   1    |   1   |\n",
      "2022-06-28 03:40:01 [INFO] |  GlobalAveragePool   |   1    |   1   |\n",
      "2022-06-28 03:40:01 [INFO] |         Add          |   9    |   9   |\n",
      "2022-06-28 03:40:01 [INFO] |    QuantizeLinear    |   3    |   3   |\n",
      "2022-06-28 03:40:01 [INFO] |   DequantizeLinear   |   3    |   3   |\n",
      "2022-06-28 03:40:01 [INFO] +----------------------+--------+-------+\n",
      "2022-06-28 03:40:01 [INFO] Pass quantize model elapsed time: 5545.39 ms\n",
      "2022-06-28 03:40:56 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 0.8397|0.8470, Duration (seconds) (int8|fp32): 54.1832|45.8410], Best tune result is: [Accuracy: 0.8397, Duration (seconds): 54.1832]\n",
      "2022-06-28 03:40:56 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2022-06-28 03:40:56 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-06-28 03:40:56 [INFO] |     Info Type      | Baseline | Tune 1 result | Best tune result |\n",
      "2022-06-28 03:40:56 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-06-28 03:40:56 [INFO] |      Accuracy      | 0.8470   |    0.8397     |     0.8397       |\n",
      "2022-06-28 03:40:56 [INFO] | Duration (seconds) | 45.8410  |    54.1832    |     54.1832      |\n",
      "2022-06-28 03:40:56 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-06-28 03:40:56 [INFO] Save tuning history to /home/projects/BigDL/python/nano/notebooks/pytorch/tutorial/nc_workspace/2022-06-28_03-37-49/./history.snapshot.\n",
      "2022-06-28 03:40:56 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2022-06-28 03:40:56 [INFO] Save deploy yaml to /home/projects/BigDL/python/nano/notebooks/pytorch/tutorial/nc_workspace/2022-06-28_03-37-49/deploy.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[12.8406, -3.8216, -2.9044, -3.5159, -0.1529,  9.9362, -2.2930,  4.2802,\n",
       "         -0.3057,  1.3758,  0.4586,  7.0318, -1.9872, -1.0701, -0.6115, -4.4331,\n",
       "         -3.3630, -4.2802, -2.9044, -2.4458,  7.9490,  1.9872, -5.1974, -2.4458,\n",
       "         -1.3758, -2.7516,  3.3630,  4.1273, -3.8216, -3.9745, -0.9172,  3.6688,\n",
       "          1.3758,  0.7643, -3.9745,  0.9172,  0.1529],\n",
       "        [10.0891,  0.9172, -2.1401, -3.2102,  0.9172,  5.3503, -2.7516,  2.5987,\n",
       "          2.5987,  2.5987,  3.2102,  4.2802, -3.6688, -1.6815, -0.3057, -5.3503,\n",
       "         -2.1401, -2.5987, -4.1273, -4.2802,  0.7643,  5.1974, -4.8917, -2.4458,\n",
       "         -2.1401, -1.0701,  0.4586,  2.7516, -3.8216, -4.2802, -0.4586,  3.8216,\n",
       "          2.5987,  9.9362, -2.5987, -0.9172,  0.1529]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_q_model = trainer.quantize(model, accelerator='onnxruntime', calib_dataloader=data_loader, metric=accuracy)\n",
    "ort_q_model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('testVscode')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e4962c53c6ef7ea4348d410747e78580ab0e1631d139dfbe170b5701abbb022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
