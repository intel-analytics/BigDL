{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we'll demonstrate how to use BigDL-Nano to accelerate custom train loop easily with very few changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Environment\n",
    "\n",
    "Before you start with APIs delivered by BigDL-Nano, you have to make sure BigDL-Nano is correctly installed for PyTorch. If not, please follow [this](../../../../../docs/readthedocs/source/doc/Nano/Overview/nano.md) to setup your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cifar10 Dataset\n",
    "\n",
    "Import Cifar10 dataset from torch_vision and modify the train transform. You could access [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) for a view of the whole dataset.\n",
    "\n",
    "Leveraging OpenCV and libjpeg-turbo, BigDL-Nano can accelerate computer vision data pipelines by providing a drop-in replacement of torch_vision's `datasets` and `transforms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from bigdl.nano.pytorch.vision import transforms\n",
    "from bigdl.nano.pytorch.vision.datasets import CIFAR10\n",
    "\n",
    "def create_dataloader(data_path, batch_size):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize(128),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    full_dataset = CIFAR10(root=data_path, train=True,\n",
    "                           download=True, transform=train_transform)\n",
    "\n",
    "    # use a subset of full dataset to shorten the training time\n",
    "    train_dataset = Subset(dataset=full_dataset, indices=list(range(len(full_dataset) // 20)))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                              shuffle=True, num_workers=0)\n",
    "\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Model\n",
    "\n",
    "We use the Resnet18 module but add a Linear layer to change its output size to 10, because the CIFAR10 dataset has 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "from bigdl.nano.pytorch.vision.models import vision\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True, include_top=False, freeze=True):\n",
    "        super().__init__()\n",
    "        backbone = vision.resnet18(pretrained=pretrained, include_top=include_top, freeze=freeze)\n",
    "        output_size = backbone.get_output_size()\n",
    "        head = nn.Linear(output_size, num_classes)\n",
    "        self.model = nn.Sequential(backbone, head)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Train Loop\n",
    "\n",
    "Suppose the custom train loop is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "avg_loss: 3.4890761375427246\n",
      "avg_loss: 2.6124730110168457\n",
      "avg_loss: 2.3601737022399902\n",
      "avg_loss: 2.2400059700012207\n",
      "avg_loss: 2.140841484069824\n",
      "avg_loss: 2.0801239013671875\n",
      "avg_loss: 2.0631775856018066\n",
      "avg_loss: 2.008615493774414\n",
      "avg_loss: 1.989851951599121\n",
      "avg_loss: 1.9810504913330078\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "data_path = os.environ.get(\"DATA_PATH\", \".\")\n",
    "batch_size = 256\n",
    "max_epochs = 10\n",
    "lr = 0.01\n",
    "\n",
    "model = ResNet18(10, pretrained=False, include_top=False, freeze=True)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train_loader = create_dataloader(data_path, batch_size)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for _i in range(max_epochs):\n",
    "    total_loss, num = 0, 0\n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        l = loss(model(X), y)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += l.sum()\n",
    "        num += 1\n",
    "    print(f'avg_loss: {total_loss / num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LightningLite` (`bigdl.nano.pytorch.lite.LightningLite`) class is the place where we integrate most optimizations. It extends PyTorch Lightning's `LightningLite` class and has a few more parameters and methods specific to BigDL-Nano.\n",
    "\n",
    "We can accelerate the train loop above by the following steps:\n",
    "\n",
    "- define a class `Lite` derived from our `LightningLite`\n",
    "- copy all codes into the `run` method of `Lite`\n",
    "- add two extra lines to setup model, optimizer and dataloader\n",
    "- change the backward call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from bigdl.nano.pytorch.lite import LightningLite\n",
    "\n",
    "class Lite(LightningLite):\n",
    "    def run(self):\n",
    "        # copy all codes into this method\n",
    "        data_path = os.environ.get(\"DATA_PATH\", \".\")\n",
    "        batch_size = 256\n",
    "        max_epochs = 10\n",
    "        lr = 0.01\n",
    "\n",
    "        model = ResNet18(10, pretrained=False, include_top=False, freeze=True)\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        train_loader = create_dataloader(data_path, batch_size)\n",
    "\n",
    "        model, optimizer = self.setup(model, optimizer)      # add this line to setup model and optimizer\n",
    "        train_loader = self.setup_dataloaders(train_loader)  # add this line to setup dataloader\n",
    "        model.train()\n",
    "\n",
    "        for _i in range(max_epochs):\n",
    "            total_loss, num = 0, 0\n",
    "            for X, y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                l = loss(model(X), y)\n",
    "                self.backward(l)  # change the backward call\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += l.sum()\n",
    "                num += 1\n",
    "            print(f'avg_loss: {total_loss / num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train in Non-distributed Mode\n",
    "\n",
    "To run the train loop, we only need to create an instance of `LightningLite` and call its `run` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "avg_loss: 3.367298126220703\n",
      "avg_loss: 2.558518886566162\n",
      "avg_loss: 2.347032070159912\n",
      "avg_loss: 2.122859477996826\n",
      "avg_loss: 2.083937883377075\n",
      "avg_loss: 2.042186737060547\n",
      "avg_loss: 2.0038819313049316\n",
      "avg_loss: 1.9734426736831665\n",
      "avg_loss: 1.972240686416626\n",
      "avg_loss: 1.9732662439346313\n"
     ]
    }
   ],
   "source": [
    "Lite().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intel Extension for Pytorch (a.k.a [IPEX](https://github.com/intel/intel-extension-for-pytorch)) extends Pytorch with optimizations on intel hardware. BigDL-Nano also integrates IPEX into the `LightningLite`, you can turn on IPEX optimization by setting `use_ipex=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/nano-dev-ipex111/lib/python3.7/site-packages/intel_extension_for_pytorch/optim/_optimizer_utils.py:207: UserWarning: Does not suport fused step for <class 'torch.optim.adam.Adam'>, will use non-fused step\n",
      "  warnings.warn(\"Does not suport fused step for \" + str(type(optimizer)) + \", will use non-fused step\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 3.6688168048858643\n",
      "avg_loss: 2.7911651134490967\n",
      "avg_loss: 2.3961710929870605\n",
      "avg_loss: 2.2255048751831055\n",
      "avg_loss: 2.1438281536102295\n",
      "avg_loss: 2.08095121383667\n",
      "avg_loss: 2.044187068939209\n",
      "avg_loss: 2.0520944595336914\n",
      "avg_loss: 2.0577313899993896\n",
      "avg_loss: 2.0262503623962402\n"
     ]
    }
   ],
   "source": [
    "Lite(use_ipex=True).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train in Distributed Mode\n",
    "\n",
    "You can set the number of processes to enable distributed training to acclerate training. You can also set different distributed strategies, now BigDL-Nano supports 'spawn', 'subprocess' and 'ray', the default strategy is 'subprocess'.\n",
    "\n",
    "- Note: only the 'subprocess' strategy can be used in interactive environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "avg_loss: 3.551307201385498\n",
      "avg_loss: 3.5610828399658203\n",
      "avg_loss: 2.8926703929901123\n",
      "avg_loss: 2.9128172397613525\n",
      "avg_loss: 2.4087586402893066\n",
      "avg_loss: 2.458486557006836\n",
      "avg_loss: 2.3466358184814453avg_loss: 2.3318121433258057\n",
      "\n",
      "avg_loss: 2.183196544647217\n",
      "avg_loss: 2.2092738151550293\n",
      "avg_loss: 2.1372807025909424\n",
      "avg_loss: 2.129611015319824\n",
      "avg_loss: 2.079845905303955\n",
      "avg_loss: 2.0982301235198975\n",
      "avg_loss: 2.0651657581329346\n",
      "avg_loss: 2.0590758323669434\n",
      "avg_loss: 2.0040674209594727avg_loss: 2.0231480598449707\n",
      "\n",
      "avg_loss: 1.9930778741836548\n",
      "avg_loss: 1.9897146224975586\n"
     ]
    }
   ],
   "source": [
    "Lite(num_processes=2, strategy=\"subprocess\").run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course you can enable both distributed training and IPEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/nano-dev-ipex111/lib/python3.7/site-packages/intel_extension_for_pytorch/optim/_optimizer_utils.py:207: UserWarning: Does not suport fused step for <class 'torch.optim.adam.Adam'>, will use non-fused step\n",
      "  warnings.warn(\"Does not suport fused step for \" + str(type(optimizer)) + \", will use non-fused step\")\n",
      "/root/miniconda3/envs/nano-dev-ipex111/lib/python3.7/site-packages/intel_extension_for_pytorch/optim/_optimizer_utils.py:207: UserWarning: Does not suport fused step for <class 'torch.optim.adam.Adam'>, will use non-fused step\n",
      "  warnings.warn(\"Does not suport fused step for \" + str(type(optimizer)) + \", will use non-fused step\")\n",
      "2022-07-20 15:12:28,746 - root - INFO - Reducer buckets have been rebuilt in this iteration.\n",
      "2022-07-20 15:12:28,746 - root - INFO - Reducer buckets have been rebuilt in this iteration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 3.7563118934631348\n",
      "avg_loss: 3.6480026245117188\n",
      "avg_loss: 3.02734637260437\n",
      "avg_loss: 3.014892101287842\n",
      "avg_loss: 2.8125622272491455\n",
      "avg_loss: 2.8375699520111084\n",
      "avg_loss: 2.434741497039795\n",
      "avg_loss: 2.4648845195770264\n",
      "avg_loss: 2.283917188644409\n",
      "avg_loss: 2.327892780303955\n",
      "avg_loss: 2.189699411392212\n",
      "avg_loss: 2.1382477283477783\n",
      "avg_loss: 2.1003966331481934\n",
      "avg_loss: 2.1151137351989746\n",
      "avg_loss: 2.056234836578369\n",
      "avg_loss: 2.065807342529297\n",
      "avg_loss: 2.0304946899414062\n",
      "avg_loss: 2.0351834297180176\n",
      "avg_loss: 1.9886785745620728\n",
      "avg_loss: 1.9950816631317139\n"
     ]
    }
   ],
   "source": [
    "Lite(use_ipex=True, num_processes=2, strategy=\"subprocess\").run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nano-dev-ipex111': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f6a3eaf2cc2504ef934de1eb229f6bd843dfd7ee99a93fc255e030415a94b5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
