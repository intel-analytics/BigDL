{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10284b3f",
   "metadata": {},
   "source": [
    "## Bigdl-nano Resnet example on CIFAR10 dataset\n",
    "---\n",
    "This example illustrates how to apply bigdl-nano optimizations on a image recognition case based on Tensorflow Keras framework. The basic image recognition module is implemented with tf.keras and trained on [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) image recognition Benchmark dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52401226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from bigdl.nano.tf.keras import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c132d",
   "metadata": {},
   "source": [
    "### CIFAR10 Data Module\n",
    "---\n",
    "Import the existing data module from keras.datasets and Normalize the images.\n",
    "You could access [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) for a view of the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01236c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = keras.datasets.cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "train_labels = keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = keras.utils.to_categorical(test_labels, 10)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d3b850",
   "metadata": {},
   "source": [
    "### Implement ResNet-18 model\n",
    "---\n",
    "Implement the resnet18 model for CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "659f2f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(Model):\n",
    "    \"\"\"\n",
    "        A standard resnet block\n",
    "    \"\"\"\n",
    "    def __init__(self, channels:int, downsample = False):\n",
    "        super().__init__()\n",
    "        self.downsample = downsample\n",
    "        self.conv1 = layers.Conv2D(filters=channels, strides=2 if downsample else 1, kernel_size=(3, 3),\n",
    "                                         padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        self.conv2 = layers.Conv2D(filters=channels, strides=1, kernel_size=(3, 3), \n",
    "                                         padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        if downsample:\n",
    "            self.downsample = keras.Sequential([\n",
    "                keras.layers.Conv2D(filters=channels, strides=2, kernel_size=(1, 1),\n",
    "                                    padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "                keras.layers.BatchNormalization()\n",
    "            ])\n",
    "    def call(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98fb0fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18(Model):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        \"\"\"\n",
    "            num_classes: number of classes in specific classification task.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=(3, 3), strides=1, padding=\"same\")\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "        self.layer1 = keras.Sequential([\n",
    "            BasicBlock(64),\n",
    "            BasicBlock(64)\n",
    "        ])\n",
    "        self.layer2 = keras.Sequential([\n",
    "            BasicBlock(128, downsample=True),\n",
    "            BasicBlock(128)\n",
    "        ])\n",
    "        self.layer3 = keras.Sequential([\n",
    "            BasicBlock(256, downsample=True),\n",
    "            BasicBlock(256)\n",
    "        ])\n",
    "        self.layer4 = keras.Sequential([\n",
    "            BasicBlock(512, downsample=True),\n",
    "            BasicBlock(512)\n",
    "        ])\n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.flat = layers.Flatten()\n",
    "        self.fc = layers.Dense(num_classes)\n",
    "        self.activate = layers.Softmax()\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        out = self.avgpool(out)\n",
    "        out = self.flat(out)\n",
    "        out = self.fc(out)\n",
    "        out = self.activate(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689ccd7",
   "metadata": {},
   "source": [
    "### Create tf.data.Dataset\n",
    "---\n",
    "The Dataset from tf.data supports writing descriptive and efficient input pipelines.<br>\n",
    "You could access more details from [tf.data.Dataset](https://tensorflow.google.cn/api_docs/python/tf/data/Dataset)\n",
    "\n",
    "- Note<br>\n",
    "You can also call keras.model.fit with Numpy array, TensorFlow tensor or data with other types as input data.<br>\n",
    "But for multi-process training, the input data must be a tf.data.Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f66318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 02:43:36.089136: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "train_dataset = train_dataset.batch(64)\n",
    "val_dataset = val_dataset.batch(64)\n",
    "STEPS = len(train_images)/64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4510aa",
   "metadata": {},
   "source": [
    "### Train\n",
    "---\n",
    "Use Model.fit from bigdl.nano.tf.keras for BigDl-Nano tf.keras.\n",
    "\n",
    "This function override tf.keras.Model.fit to add more parameters.\n",
    "\n",
    "\n",
    "Additional parameters:\n",
    "```\n",
    "        :param num_processes:  when num_processes is not None, it specifies how many sub-processes\n",
    "                               to launch to run pseudo-distributed training; when num_processes is None,\n",
    "                               training will run in the current process.\n",
    "                               \n",
    "        :param backend: Use backend 'multiprocessing', 'horovod', 'ray', defaults to None.\n",
    "                        when num_processes is not None, it specifies which backend to use when\n",
    "                       launching sub-processes to run psedu-distributed training; \n",
    "                       when num_processes is None, this parameter takes no effect.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba6200da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet18_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          multiple                  1792      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  multiple                 256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_9 (ReLU)              multiple                  0         \n",
      "                                                                 \n",
      " sequential_7 (Sequential)   (None, 32, 32, 64)        148736    \n",
      "                                                                 \n",
      " sequential_9 (Sequential)   (None, 16, 16, 128)       527488    \n",
      "                                                                 \n",
      " sequential_11 (Sequential)  (None, 8, 8, 256)         2103552   \n",
      "                                                                 \n",
      " sequential_13 (Sequential)  (None, 4, 4, 512)         8401408   \n",
      "                                                                 \n",
      " global_average_pooling2d_1   multiple                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  5130      \n",
      "                                                                 \n",
      " softmax_1 (Softmax)         multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,188,362\n",
      "Trainable params: 11,178,762\n",
      "Non-trainable params: 9,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "single_none_model = Resnet18(10)\n",
    "single_none_model.build(input_shape=(None, 32, 32, 3))\n",
    "\n",
    "optimer = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "#use categorical_crossentropy since the label is one-hot encoded\n",
    "single_none_model.compile(optimizer=optimer,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "single_none_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91ef1a1",
   "metadata": {},
   "source": [
    "### Single Process\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c33120cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 87s 135ms/step - loss: 1.2771 - accuracy: 0.5393 - val_loss: 1.4283 - val_accuracy: 0.5114\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1073741824 bytes == 0x555742c54000 @  0x7fe2cf049d3f 0x7fe2cf0800c0 0x7fe2cf083082 0x7fe2cf083243 0x7fe2bf6b5402 0x7fe2b3a4feb0 0x7fe2b3a700b5 0x7fe2b3a739ea 0x7fe2b3a73f69 0x7fe2b3a742d1 0x7fe2b3a68ce3 0x7fe2af12e051 0x7fe2aef8a16a 0x7fe2bb29a73f 0x7fe2baa41216 0x7fe2baa4329d 0x7fe2baa23a59 0x7fe2ba904b0d 0x7fe2ba904d7e 0x7fe2ba8ffb11 0x7fe2af12fd7c 0x7fe2babd8efd 0x7fe2b499b829 0x7fe2b499c2c1 0x7fe2bafdb2aa 0x7fe2b499927e 0x7fe2b4999d10 0x7fe2b46639b9 0x7fe2babe88bf 0x7fe2b44239f5 0x7fe2b4394d5f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 82s 131ms/step - loss: 0.7884 - accuracy: 0.7222 - val_loss: 1.1598 - val_accuracy: 0.6256\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 82s 130ms/step - loss: 0.5543 - accuracy: 0.8084 - val_loss: 1.4040 - val_accuracy: 0.6029\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 81s 130ms/step - loss: 0.3831 - accuracy: 0.8664 - val_loss: 1.2877 - val_accuracy: 0.6380\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 81s 129ms/step - loss: 0.2783 - accuracy: 0.9027 - val_loss: 1.6015 - val_accuracy: 0.6413\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 81s 129ms/step - loss: 0.1971 - accuracy: 0.9298 - val_loss: 2.0681 - val_accuracy: 0.5911\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 80s 128ms/step - loss: 0.1447 - accuracy: 0.9491 - val_loss: 1.1178 - val_accuracy: 0.7331\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 80s 128ms/step - loss: 0.1100 - accuracy: 0.9607 - val_loss: 2.2233 - val_accuracy: 0.6408\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 80s 128ms/step - loss: 0.0878 - accuracy: 0.9687 - val_loss: 1.6582 - val_accuracy: 0.6888\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 80s 128ms/step - loss: 0.0725 - accuracy: 0.9749 - val_loss: 1.4153 - val_accuracy: 0.7271\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.4491 - accuracy: 0.7170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4491106271743774, 0.7170000076293945]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "single_none_model.fit(train_dataset,\n",
    "          epochs=10,\n",
    "          steps_per_epoch=STEPS,\n",
    "          validation_data=val_dataset)\n",
    "single_none_train_time = time() - start\n",
    "single_none_model.evaluate(test_images, test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa4067",
   "metadata": {},
   "source": [
    "### Multiple Processes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "947a8a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 01:25:40.549124: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfa6yulm1/temp_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 01:25:47.838756: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-18 01:25:47.846586: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:52264}\n",
      "2022-05-18 01:25:47.846760: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:427] Started server with target: grpc://localhost:52264\n",
      "tcmalloc: large alloc 1073741824 bytes == 0x55fd0737e000 @  0x7f78e9ac0d3f 0x7f78e9af70c0 0x7f78e9afa082 0x7f78e9afa243 0x7f78e3a9d402 0x7f78d7e37eb0 0x7f78d7e580b5 0x7f78d7e5b9ea 0x7f78d7e5bf69 0x7f78d7e5c2d1 0x7f78d7e50ce3 0x7f78d3516051 0x7f78d337216a 0x7f78df68273f 0x7f78dee29216 0x7f78dee2b29d 0x7f78dee22a0a 0x7f78d307e8f0 0x7f78d3089496 0x7f78d3517d7c 0x7f78defc0efd 0x7f78d8d83829 0x7f78d8d842c1 0x7f78df3c32aa 0x7f78d8d8127e 0x7f78d8d81d10 0x7f78d8a4b9b9 0x7f78defd08bf 0x7f78d880b9f5 0x7f78d877cd5f 0x7f78c375b2dc\n",
      "2022-05-18 01:25:53.692811: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 40000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 32\n",
      "        }\n",
      "        dim {\n",
      "          size: 32\n",
      "        }\n",
      "        dim {\n",
      "          size: 3\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 10\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-05-18 01:25:53.826667: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.2817 - accuracy: 0.5365"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 01:27:15.317409: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 10000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:1\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 32\n",
      "        }\n",
      "        dim {\n",
      "          size: 32\n",
      "        }\n",
      "        dim {\n",
      "          size: 3\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 10\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-05-18 01:27:15.381875: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 88s 135ms/step - loss: 1.2817 - accuracy: 0.5365 - val_loss: 1.2937 - val_accuracy: 0.5622\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.7875 - accuracy: 0.7209"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 01:28:39.352539: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 82s 132ms/step - loss: 0.7875 - accuracy: 0.7209 - val_loss: 1.1002 - val_accuracy: 0.6351\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5497 - accuracy: 0.8103"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 01:30:01.547212: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 82s 131ms/step - loss: 0.5497 - accuracy: 0.8103 - val_loss: 1.0575 - val_accuracy: 0.6772\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8648"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 01:31:23.702996: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 82s 131ms/step - loss: 0.3866 - accuracy: 0.8648 - val_loss: 1.0650 - val_accuracy: 0.7015\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2816 - accuracy: 0.9005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 01:32:45.505063: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 82s 131ms/step - loss: 0.2816 - accuracy: 0.9005 - val_loss: 1.2368 - val_accuracy: 0.6892\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2033 - accuracy: 0.9277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 01:34:07.164693: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 81s 130ms/step - loss: 0.2033 - accuracy: 0.9277 - val_loss: 1.2371 - val_accuracy: 0.7183\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.9499"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 01:35:28.824157: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 82s 131ms/step - loss: 0.1427 - accuracy: 0.9499 - val_loss: 1.2270 - val_accuracy: 0.7165\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9629"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 01:36:50.424715: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 81s 130ms/step - loss: 0.1040 - accuracy: 0.9629 - val_loss: 1.3506 - val_accuracy: 0.7269\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9693"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 01:38:12.173148: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 82s 131ms/step - loss: 0.0898 - accuracy: 0.9693 - val_loss: 1.4482 - val_accuracy: 0.7025\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 01:39:33.623068: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "625/625 [==============================] - 81s 130ms/step - loss: 0.0844 - accuracy: 0.9702 - val_loss: 1.1149 - val_accuracy: 0.7608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 01:39:41.306684: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as conv2d_20_layer_call_fn, conv2d_20_layer_call_and_return_conditional_losses, re_lu_9_layer_call_fn, re_lu_9_layer_call_and_return_conditional_losses, flatten_1_layer_call_fn while saving (showing 5 of 145). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 23ms/step - loss: 1.1732 - accuracy: 0.7611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.173243522644043, 0.7610999941825867]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_default_model = Resnet18(10)\n",
    "optimer = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "multi_default_model.compile(optimizer=optimer,\n",
    "                        loss=\"categorical_crossentropy\",\n",
    "                        metrics=['accuracy'])\n",
    "start = time()\n",
    "multi_default_model.fit(train_dataset, \n",
    "                      epochs=10, \n",
    "                      steps_per_epoch=STEPS,\n",
    "                      validation_data=val_dataset,\n",
    "                      num_processes=1,\n",
    "                      backend=\"multiprocessing\")\n",
    "multi_default_train_time = time() - start\n",
    "multi_default_model.evaluate(test_images, test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06c53db",
   "metadata": {},
   "source": [
    "### Multiple Processes with horovod\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb058dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).signatures\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root)._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).conv1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).bn1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).relu._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).avgpool._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).flat._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).fc._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).activate._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer1.layer_with_weights-0._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer1.layer_with_weights-1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-0._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-0._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-0._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer1.layer_with_weights-0.conv1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer1.layer_with_weights-0.bn1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer1.layer_with_weights-0.relu._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer1.layer_with_weights-0.conv2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer1.layer_with_weights-0.bn2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer1.layer_with_weights-1.conv1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer1.layer_with_weights-1.bn1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer1.layer_with_weights-1.relu._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer1.layer_with_weights-1.conv2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer1.layer_with_weights-1.bn2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-0.conv1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-0.bn1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-0.relu._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-0.conv2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-0.bn2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-0.downsample._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-1.conv1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-1.bn1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-1.relu._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-1.conv2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-1.bn2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-0.conv1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-0.bn1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-0.relu._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-0.conv2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-0.bn2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-0.downsample._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-1.conv1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-1.bn1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-1.relu._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-1.conv2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-1.bn2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-0.conv1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-0.bn1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-0.relu._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-0.conv2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-0.bn2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-0.downsample._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-1.conv1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-1.bn1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-1.relu._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-1.conv2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-1.bn2._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-0.downsample.layer_with_weights-0._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer2.layer_with_weights-0.downsample.layer_with_weights-1._self_saveable_object_factories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-0.downsample.layer_with_weights-0._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer3.layer_with_weights-0.downsample.layer_with_weights-1._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-0.downsample.layer_with_weights-0._self_saveable_object_factories\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer4.layer_with_weights-0.downsample.layer_with_weights-1._self_saveable_object_factories\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp00wo9m33/temp_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]<stderr>:2022-05-18 02:06:31.839981: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "[0]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[0]<stderr>:tcmalloc: large alloc 1073741824 bytes == 0x55f1612c0000 @  0x7fc63a2a7d3f 0x7fc63a2de0c0 0x7fc63a2e1082 0x7fc63a2e1243 0x7fc634298402 0x7fc628632eb0 0x7fc6286530b5 0x7fc6286569ea 0x7fc628656f69 0x7fc6286572d1 0x7fc62864bce3 0x7fc623d11051 0x7fc623b6d16a 0x7fc62fe7d73f 0x7fc62f624216 0x7fc62f62629d 0x7fc62f61da0a 0x7fc6238798f0 0x7fc623884496 0x7fc623d12d7c 0x7fc62f7bbefd 0x7fc62957e829 0x7fc62957f2c1 0x7fc62fbbe2aa 0x7fc62957c27e 0x7fc62957cd10 0x7fc6292469b9 0x7fc62f7cb8bf 0x7fc6290069f5 0x7fc628f77d5f 0x7fc613f422dc\n",
      "[0]<stderr>:2022-05-18 02:06:37.437377: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "[0]<stderr>:op: \"TensorSliceDataset\"\n",
      "[0]<stderr>:input: \"Placeholder/_0\"\n",
      "[0]<stderr>:input: \"Placeholder/_1\"\n",
      "[0]<stderr>:attr {\n",
      "[0]<stderr>:  key: \"Toutput_types\"\n",
      "[0]<stderr>:  value {\n",
      "[0]<stderr>:    list {\n",
      "[0]<stderr>:      type: DT_FLOAT\n",
      "[0]<stderr>:      type: DT_FLOAT\n",
      "[0]<stderr>:    }\n",
      "[0]<stderr>:  }\n",
      "[0]<stderr>:}\n",
      "[0]<stderr>:attr {\n",
      "[0]<stderr>:  key: \"_cardinality\"\n",
      "[0]<stderr>:  value {\n",
      "[0]<stderr>:    i: 40000\n",
      "[0]<stderr>:  }\n",
      "[0]<stderr>:}\n",
      "[0]<stderr>:attr {\n",
      "[0]<stderr>:  key: \"is_files\"\n",
      "[0]<stderr>:  value {\n",
      "[0]<stderr>:    b: false\n",
      "[0]<stderr>:  }\n",
      "[0]<stderr>:}\n",
      "[0]<stderr>:attr {\n",
      "[0]<stderr>:  key: \"metadata\"\n",
      "[0]<stderr>:  value {\n",
      "[0]<stderr>:    s: \"\\n\\025TensorSliceDataset:56\"\n",
      "[0]<stderr>:  }\n",
      "[0]<stderr>:}\n",
      "[0]<stderr>:attr {\n",
      "[0]<stderr>:  key: \"output_shapes\"\n",
      "[0]<stderr>:  value {\n",
      "[0]<stderr>:    list {\n",
      "[0]<stderr>:      shape {\n",
      "[0]<stderr>:        dim {\n",
      "[0]<stderr>:          size: 32\n",
      "[0]<stderr>:        }\n",
      "[0]<stderr>:        dim {\n",
      "[0]<stderr>:          size: 32\n",
      "[0]<stderr>:        }\n",
      "[0]<stderr>:        dim {\n",
      "[0]<stderr>:          size: 3\n",
      "[0]<stderr>:        }\n",
      "[0]<stderr>:      }\n",
      "[0]<stderr>:      shape {\n",
      "[0]<stderr>:        dim {\n",
      "[0]<stderr>:          size: 10\n",
      "[0]<stderr>:        }\n",
      "[0]<stderr>:      }\n",
      "[0]<stderr>:    }\n",
      "[0]<stderr>:  }\n",
      "[0]<stderr>:}\n",
      "[0]<stderr>:\n",
      "[0]<stderr>:2022-05-18 02:06:37.463347: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "[0]<stderr>:op: \"TensorSliceDataset\"\n",
      "[0]<stderr>:input: \"Placeholder/_0\"\n",
      "[0]<stderr>:input: \"Placeholder/_1\"\n",
      "[0]<stderr>:attr {\n",
      "[0]<stderr>:  key: \"Toutput_types\"\n",
      "[0]<stderr>:  value {\n",
      "[0]<stderr>:    list {\n",
      "[0]<stderr>:      type: DT_FLOAT\n",
      "[0]<stderr>:      type: DT_FLOAT\n",
      "[0]<stderr>:    }\n",
      "[0]<stderr>:  }\n",
      "[0]<stderr>:}\n",
      "[0]<stderr>:attr {\n",
      "[0]<stderr>:  key: \"_cardinality\"\n",
      "[0]<stderr>:  value {\n",
      "[0]<stderr>:    i: 10000\n",
      "[0]<stderr>:  }\n",
      "[0]<stderr>:}\n",
      "[0]<stderr>:attr {\n",
      "[0]<stderr>:  key: \"is_files\"\n",
      "[0]<stderr>:  value {\n",
      "[0]<stderr>:    b: false\n",
      "[0]<stderr>:  }\n",
      "[0]<stderr>:}\n",
      "[0]<stderr>:attr {\n",
      "[0]<stderr>:  key: \"metadata\"\n",
      "[0]<stderr>:  value {\n",
      "[0]<stderr>:    s: \"\\n\\024TensorSliceDataset:1\"\n",
      "[0]<stderr>:  }\n",
      "[0]<stderr>:}\n",
      "[0]<stderr>:attr {\n",
      "[0]<stderr>:  key: \"output_shapes\"\n",
      "[0]<stderr>:  value {\n",
      "[0]<stderr>:    list {\n",
      "[0]<stderr>:      shape {\n",
      "[0]<stderr>:        dim {\n",
      "[0]<stderr>:          size: 32\n",
      "[0]<stderr>:        }\n",
      "[0]<stderr>:        dim {\n",
      "[0]<stderr>:          size: 32\n",
      "[0]<stderr>:        }\n",
      "[0]<stderr>:        dim {\n",
      "[0]<stderr>:          size: 3\n",
      "[0]<stderr>:        }\n",
      "[0]<stderr>:      }\n",
      "[0]<stderr>:      shape {\n",
      "[0]<stderr>:        dim {\n",
      "[0]<stderr>:          size: 10\n",
      "[0]<stderr>:        }\n",
      "[0]<stderr>:      }\n",
      "[0]<stderr>:    }\n",
      "[0]<stderr>:  }\n",
      "[0]<stderr>:}\n",
      "[0]<stderr>:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]<stdout>:Epoch 1/10\n",
      "[0]<stdout>:625/625 [==============================] - 87s 131ms/step - loss: 1.2856 - accuracy: 0.5361 - val_loss: 1.5657 - val_accuracy: 0.5063\n",
      "[0]<stdout>:Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]<stderr>:WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 6250.0 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]<stdout>:\r",
      "[0]<stdout>:625/625 [==============================] - 6s 9ms/step - loss: 1.2856 - accuracy: 0.5361 - val_loss: 1.5657 - val_accuracy: 0.5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]<stderr>:2022-05-18 02:08:11.761784: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "[0]<stderr>:WARNING:absl:Found untraced functions such as conv2d_120_layer_call_fn, conv2d_120_layer_call_and_return_conditional_losses, re_lu_54_layer_call_fn, re_lu_54_layer_call_and_return_conditional_losses, flatten_6_layer_call_fn while saving (showing 5 of 145). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 23ms/step - loss: 1.5420 - accuracy: 0.5123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5419765710830688, 0.5123000144958496]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "multi_horovod_model = Resnet18(10)\n",
    "optimer = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "multi_horovod_model.compile(optimizer=optimer,\n",
    "                            loss=\"categorical_crossentropy\",\n",
    "                            metrics=['accuracy'])\n",
    "start = time()\n",
    "multi_horovod_model.fit(train_dataset, \n",
    "                        epochs=10, \n",
    "                        validation_data=val_dataset,\n",
    "                        steps_per_epoch=STEPS,\n",
    "                        num_processes=1,\n",
    "                        backend=\"horovod\")\n",
    "multi_horovod_train_time = time() - start\n",
    "multi_horovod_model.evaluate(test_images, test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add22230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
