{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b169f608",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bigdl-Nano Keras Inference Example\n",
    "---\n",
    "This example shows the usage of bigdl-nano tf.keras inference pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16885330",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from bigdl.nano.tf.keras import Model, Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640ab0f3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### CIFAR10 Data Module\n",
    "---\n",
    "Import the existing data module from keras.datasets and Normalize the images.<br>\n",
    "You could access [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) for a view of the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f6648b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cifar10 = keras.datasets.cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "train_labels = keras.utils.to_categorical(train_labels, 10)\n",
    "y_test = test_labels\n",
    "test_labels = keras.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2478a09",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Implement ResNet-18 model and load model weights from hdf5 file\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad09735",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BasicBlock(Model):\n",
    "    def __init__(self, channels:int, downsample = False):\n",
    "        super().__init__()\n",
    "        self.downsample = downsample\n",
    "        self.conv1 = layers.Conv2D(filters=channels, strides=2 if downsample else 1, kernel_size=(3, 3),\n",
    "                                         padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        self.conv2 = layers.Conv2D(filters=channels, strides=1, kernel_size=(3, 3), \n",
    "                                         padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        if downsample:\n",
    "            self.downsample = keras.Sequential([\n",
    "                keras.layers.Conv2D(filters=channels, strides=2, kernel_size=(1, 1),\n",
    "                                    padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "                keras.layers.BatchNormalization()\n",
    "            ])\n",
    "    def call(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aefa9e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getModel(num_classes):\n",
    "    inputs = keras.Input(shape=(32, 32, 3), dtype=tf.float32)\n",
    "    conv1 = layers.Conv2D(64, kernel_size=(3, 3), strides=1, padding=\"same\")(inputs)\n",
    "    bn1 = layers.BatchNormalization()(conv1)\n",
    "    relu = layers.ReLU()(bn1)\n",
    "    \n",
    "    layer1 = keras.Sequential([\n",
    "            BasicBlock(64),\n",
    "            BasicBlock(64)\n",
    "        ])(relu)\n",
    "    \n",
    "    layer2 = keras.Sequential([\n",
    "            BasicBlock(128, downsample=True),\n",
    "            BasicBlock(128)\n",
    "        ])(layer1)\n",
    "    \n",
    "    layer3 = keras.Sequential([\n",
    "            BasicBlock(256, downsample=True),\n",
    "            BasicBlock(256)\n",
    "        ])(layer2)\n",
    "    \n",
    "    layer4 = keras.Sequential([\n",
    "            BasicBlock(512, downsample=True),\n",
    "            BasicBlock(512)\n",
    "        ])(layer3)\n",
    "    \n",
    "    avgpool = layers.GlobalAveragePooling2D()(layer4)\n",
    "    flat = layers.Flatten()(avgpool)\n",
    "    fc = layers.Dense(num_classes)(flat)\n",
    "    activate = layers.Softmax()(fc)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=activate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c281d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 03:30:48.941007: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 32, 32, 64)        148736    \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 16, 16, 128)       527488    \n",
      "                                                                 \n",
      " sequential_4 (Sequential)   (None, 8, 8, 256)         2103552   \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   (None, 4, 4, 512)         8401408   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                5130      \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,188,362\n",
      "Trainable params: 11,178,762\n",
      "Non-trainable params: 9,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = getModel(10)\n",
    "\n",
    "model.load_weights(\"checkpoints/basic_resnet18.hdf5\")\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d0adb7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Measure basic model inference time and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caa2d54d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 17s 53ms/step - loss: 0.4191 - accuracy: 0.8784\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model.predict(test_images, batch_size=64)\n",
    "infer_time_model_basic = time() - start\n",
    "acc_model_basic = model.evaluate(test_images, test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32dfdb1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Quantize Model\n",
    "---\n",
    "Use Model.quantize from bigdl.nano.tf.keras to calibrate a keras model for post-training quantization.<br>\n",
    "Here are the parameters used in the notebook:\n",
    "```\n",
    "    :param calib_dataset:  A tf.data.Dataset object for calibration. Required for\n",
    "                            static quantization.\n",
    "    :param val_dataset:    A tf.data.Dataset object for evaluation.\n",
    "    :param batch:          Batch size of dataloader for both calib_dataset and val_dataset.\n",
    "    :param metric:         A Metric object for evaluation.\n",
    "    \n",
    "    :param tuning_strategy:    'bayesian', 'basic', 'mse', 'sigopt'. Default: 'bayesian'.\n",
    "    \n",
    "```\n",
    "Access more details from [Source](https://github.com/intel-analytics/BigDL/blob/main/python/nano/src/bigdl/nano/tf/quantization.py#L22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9ccaf4c",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 03:31:15 [WARNING] Override the value of `metric` field defined in yaml file as user defines the value of `metric` attribute by code.\n",
      "2022-05-19 03:31:15.416102: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-05-19 03:31:15.416231: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-05-19 03:31:15.423254: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.005ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2022-05-19 03:31:15.911786: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-05-19 03:31:15.911928: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-05-19 03:31:16.062058: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: tf_graph\n",
      "  constant_folding: Graph size after: 217 nodes (-122), 346 edges (-122), time = 57.769ms.\n",
      "  constant_folding: Graph size after: 217 nodes (0), 346 edges (0), time = 35.94ms.\n",
      "\n",
      "2022-05-19 03:31:16 [INFO] ConvertLayoutOptimizer elapsed time: 0.26 ms\n",
      "2022-05-19 03:31:18.145856: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-05-19 03:31:18.145992: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-05-19 03:31:18.273075: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  model_pruner: Graph size after: 217 nodes (0), 346 edges (0), time = 15.916ms.\n",
      "  shape_optimizer: shape_optimizer did nothing. time = 0.283ms.\n",
      "  dependency_optimizer: Graph size after: 216 nodes (-1), 223 edges (-123), time = 12.302ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.209ms.\n",
      "  loop_optimizer: Graph size after: 216 nodes (0), 223 edges (0), time = 9.061ms.\n",
      "  model_pruner: Graph size after: 216 nodes (0), 223 edges (0), time = 9.101ms.\n",
      "  shape_optimizer: shape_optimizer did nothing. time = 0.165ms.\n",
      "  dependency_optimizer: Graph size after: 216 nodes (0), 223 edges (0), time = 9.929ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.181ms.\n",
      "\n",
      "2022-05-19 03:31:18 [INFO] Pass GrapplerOptimizer elapsed time: 2000.71 ms\n",
      "2022-05-19 03:31:18 [INFO] Pass SwitchOptimizer elapsed time: 601.81 ms\n",
      "2022-05-19 03:31:19 [INFO] Pass RemoveTrainingNodesOptimizer elapsed time: 670.19 ms\n",
      "2022-05-19 03:31:19 [INFO] Pass SplitSharedInputOptimizer elapsed time: 10.49 ms\n",
      "2022-05-19 03:31:20 [INFO] Pass GraphFoldConstantOptimizer elapsed time: 669.91 ms\n",
      "2022-05-19 03:31:20 [INFO] Pass FuseColumnWiseMulOptimizer elapsed time: 677.24 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/nanoWithTf/lib/python3.7/site-packages/neural_compressor/adaptor/tf_utils/util.py:322: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 03:31:21 [WARNING] From /opt/conda/envs/nanoWithTf/lib/python3.7/site-packages/neural_compressor/adaptor/tf_utils/util.py:322: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2022-05-19 03:31:23 [INFO] Pass StripUnusedNodesOptimizer elapsed time: 2723.78 ms\n",
      "2022-05-19 03:31:24 [INFO] Pass GraphCseOptimizer elapsed time: 706.19 ms\n",
      "2022-05-19 03:31:26 [INFO] Pass FoldBatchNormNodesOptimizer elapsed time: 1892.39 ms\n",
      "2022-05-19 03:31:26 [INFO] Pass UpdateEnterOptimizer elapsed time: 2.23 ms\n",
      "2022-05-19 03:31:26 [INFO] Pass ConvertLeakyReluOptimizer elapsed time: 4.12 ms\n",
      "2022-05-19 03:31:26 [INFO] Pass ConvertAddToBiasAddOptimizer elapsed time: 4.32 ms\n",
      "2022-05-19 03:31:26 [INFO] Pass FuseTransposeReshapeOptimizer elapsed time: 4.55 ms\n",
      "2022-05-19 03:31:26 [INFO] Pass FuseConvWithMathOptimizer elapsed time: 4.48 ms\n",
      "2022-05-19 03:31:26 [INFO] Pass ExpandDimsOptimizer elapsed time: 3.5 ms\n",
      "2022-05-19 03:31:26 [INFO] Pass InjectDummyBiasAddOptimizer elapsed time: 2.9 ms\n",
      "2022-05-19 03:31:26 [INFO] Pass MoveSqueezeAfterReluOptimizer elapsed time: 1.8 ms\n",
      "2022-05-19 03:31:26 [INFO] Pass Pre Optimization elapsed time: 10358.16 ms\n",
      "2022-05-19 03:31:26 [INFO] Get FP32 model baseline.\n",
      "2022-05-19 03:31:26 [INFO] Start to evaluate the TensorFlow model.\n",
      "2022-05-19 03:31:42 [INFO] Model inference elapsed time: 15892.71 ms\n",
      "2022-05-19 03:31:42 [INFO] Save tuning history to /home/projects/notebooks/nc_workspace/2022-05-19_03-31-14/./history.snapshot.\n",
      "2022-05-19 03:31:42 [INFO] FP32 baseline is: [Accuracy: 2.2458, Duration (seconds): 15.8979]\n",
      "2022-05-19 03:31:42 [WARNING] Reset `calibration.dataloader.batch_size` field to 50 to make sure the sampling_size is divisible exactly by batch size\n",
      "2022-05-19 03:31:43 [WARNING] Found possible input node names: ['input_1'], output node names: ['softmax'].\n",
      "2022-05-19 03:31:43 [WARNING] Found possible input node names: ['input_1'], output node names: ['softmax'].\n",
      "2022-05-19 03:31:43.781079: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-05-19 03:31:43.781375: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-05-19 03:31:43.796212: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.017ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "\n",
      "2022-05-19 03:31:44.712898: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-05-19 03:31:44.713122: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-05-19 03:31:44.951882: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: tf_graph\n",
      "  constant_folding: Graph size after: 217 nodes (-122), 346 edges (-122), time = 104.249ms.\n",
      "  constant_folding: Graph size after: 217 nodes (0), 346 edges (0), time = 50.503ms.\n",
      "\n",
      "2022-05-19 03:31:45 [INFO] Pass Quantization elapsed time: 513.38 ms\n",
      "2022-05-19 03:31:46 [INFO] Start sampling on calibration dataset.\n",
      ";model/conv2d/Conv2D_eightbit_min_input_1__print__;__min:[0]\n",
      ";model/conv2d/Conv2D_eightbit_max_input_1__print__;__max:[1]\n",
      ";model/sequential/basic_block/conv2d_1/Conv2D_eightbit_min_model/re_lu/Relu__print__;__min:[0]\n",
      ";model/conv2d/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential/basic_block/conv2d_1/Conv2D_eightbit_max_model/re_lu/Relu__print__;__max:[11.1612606]\n",
      ";model/conv2d/Conv2D_eightbit_requant_range__print__;__requant_max:[11.1612606]\n",
      ";model/sequential/basic_block/conv2d_2/Conv2D_eightbit_min_model/sequential/basic_block/re_lu_1/Relu__print__;__min:[0]\n",
      ";model/sequential/basic_block/conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential/basic_block/conv2d_2/Conv2D_eightbit_max_model/sequential/basic_block/re_lu_1/Relu__print__;__max:[16.74123]\n",
      ";model/sequential/basic_block/conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_max:[16.74123]\n",
      ";model/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_min_model/sequential/basic_block/re_lu_1/Relu_1__print__;__min:[0]\n",
      ";model/sequential/basic_block/conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_max_model/sequential/basic_block/re_lu_1/Relu_1__print__;__max:[18.2626801]\n",
      ";model/sequential/basic_block/conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_max:[18.2626801]\n",
      ";model/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_min_model/sequential/basic_block_1/re_lu_2/Relu__print__;__min:[0]\n",
      ";model/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_max_model/sequential/basic_block_1/re_lu_2/Relu__print__;__max:[9.76859283]\n",
      ";model/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_max:[9.76859283]\n",
      ";model/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_min_model/sequential/basic_block_1/re_lu_2/Relu_1__print__;__min:[0]\n",
      ";model/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_min_model/sequential/basic_block_1/re_lu_2/Relu_1__print__;__min:[0]\n",
      ";model/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_max_model/sequential/basic_block_1/re_lu_2/Relu_1__print__;__max:[22.4159622]\n",
      ";model/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_max_model/sequential/basic_block_1/re_lu_2/Relu_1__print__;__max:[22.4159622]\n",
      ";model/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_max:[22.4159622]\n",
      ";model/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min:[-10.1294727]\n",
      ";model/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_max:[9.88350868]\n",
      ";model/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_min_model/sequential_2/basic_block_2/re_lu_3/Relu__print__;__min:[0]\n",
      ";model/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_max_model/sequential_2/basic_block_2/re_lu_3/Relu__print__;__max:[12.2209377]\n",
      ";model/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_max:[12.2209377]\n",
      ";model/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_min_model/sequential_2/basic_block_2/re_lu_3/Relu_1__print__;__min:[0]\n",
      ";model/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_max_model/sequential_2/basic_block_2/re_lu_3/Relu_1__print__;__max:[13.8876419]\n",
      ";model/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_max:[13.8876419]\n",
      ";model/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_min_model/sequential_2/basic_block_3/re_lu_4/Relu__print__;__min:[0]\n",
      ";model/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_max_model/sequential_2/basic_block_3/re_lu_4/Relu__print__;__max:[7.40132189]\n",
      ";model/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_max:[7.40132189]\n",
      ";model/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_min_model/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__min:[0]\n",
      ";model/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_min_model/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__min:[0]\n",
      ";model/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_max_model/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__max:[19.5631084]\n",
      ";model/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_max_model/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__max:[19.5631084]\n",
      ";model/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_max:[19.5631084]\n",
      ";model/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min:[-6.5698595]\n",
      ";model/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_max:[5.57459354]\n",
      ";model/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_min_model/sequential_4/basic_block_4/re_lu_5/Relu__print__;__min:[0]\n",
      ";model/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_max_model/sequential_4/basic_block_4/re_lu_5/Relu__print__;__max:[8.40939]\n",
      ";model/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_max:[8.40939]\n",
      ";model/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_min_model/sequential_4/basic_block_4/re_lu_5/Relu_1__print__;__min:[0]\n",
      ";model/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_max_model/sequential_4/basic_block_4/re_lu_5/Relu_1__print__;__max:[12.386837]\n",
      ";model/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_max:[12.386837]\n",
      ";model/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_min_model/sequential_4/basic_block_5/re_lu_6/Relu__print__;__min:[0]\n",
      ";model/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_max_model/sequential_4/basic_block_5/re_lu_6/Relu__print__;__max:[6.40167093]\n",
      ";model/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_max:[6.40167093]\n",
      ";model/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_min_model/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__min:[0]\n",
      ";model/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_min_model/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__min:[0]\n",
      ";model/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_max_model/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__max:[15.8724537]\n",
      ";model/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_max_model/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__max:[15.8724537]\n",
      ";model/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_max:[15.8724537]\n",
      ";model/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min:[-5.72582912]\n",
      ";model/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_max:[6.52874804]\n",
      ";model/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_min_model/sequential_6/basic_block_6/re_lu_7/Relu__print__;__min:[0]\n",
      ";model/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_max_model/sequential_6/basic_block_6/re_lu_7/Relu__print__;__max:[7.82672596]\n",
      ";model/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_max:[7.82672596]\n",
      ";model/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_min_model/sequential_6/basic_block_6/re_lu_7/Relu_1__print__;__min:[0]\n",
      ";model/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_max_model/sequential_6/basic_block_6/re_lu_7/Relu_1__print__;__max:[13.2797775]\n",
      ";model/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_max:[13.2797775]\n",
      ";model/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_min_model/sequential_6/basic_block_7/re_lu_8/Relu__print__;__min:[0]\n",
      ";model/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_max_model/sequential_6/basic_block_7/re_lu_8/Relu__print__;__max:[9.01873684]\n",
      ";model/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_max:[9.01873684]\n",
      ";model/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_max:[16.7508545]\n",
      ";model/dense/MatMul_eightbit_min_model/flatten/Reshape__print__;__min:[0]\n",
      ";model/dense/MatMul_eightbit_max_model/flatten/Reshape__print__;__max:[4.74937201]\n",
      ";model/dense/MatMul_eightbit_requant_range__print__;__requant_min:[-22.0720081]\n",
      ";model/dense/MatMul_eightbit_requant_range__print__;__requant_max:[28.8185577]\n",
      ";model/conv2d/Conv2D_eightbit_min_input_1__print__;__min:[0]\n",
      ";model/conv2d/Conv2D_eightbit_max_input_1__print__;__max:[1]\n",
      ";model/sequential/basic_block/conv2d_1/Conv2D_eightbit_min_model/re_lu/Relu__print__;__min:[0]\n",
      ";model/conv2d/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential/basic_block/conv2d_1/Conv2D_eightbit_max_model/re_lu/Relu__print__;__max:[10.9765253]\n",
      ";model/conv2d/Conv2D_eightbit_requant_range__print__;__requant_max:[10.9765253]\n",
      ";model/sequential/basic_block/conv2d_2/Conv2D_eightbit_min_model/sequential/basic_block/re_lu_1/Relu__print__;__min:[0]\n",
      ";model/sequential/basic_block/conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential/basic_block/conv2d_2/Conv2D_eightbit_max_model/sequential/basic_block/re_lu_1/Relu__print__;__max:[16.2410831]\n",
      ";model/sequential/basic_block/conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_max:[16.2410831]\n",
      ";model/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_min_model/sequential/basic_block/re_lu_1/Relu_1__print__;__min:[0]\n",
      ";model/sequential/basic_block/conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_max_model/sequential/basic_block/re_lu_1/Relu_1__print__;__max:[18.8361473]\n",
      ";model/sequential/basic_block/conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_max:[18.8361473]\n",
      ";model/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_min_model/sequential/basic_block_1/re_lu_2/Relu__print__;__min:[0]\n",
      ";model/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_max_model/sequential/basic_block_1/re_lu_2/Relu__print__;__max:[9.49592876]\n",
      ";model/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_max:[9.49592876]\n",
      ";model/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_min_model/sequential/basic_block_1/re_lu_2/Relu_1__print__;__min:[0]\n",
      ";model/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_min_model/sequential/basic_block_1/re_lu_2/Relu_1__print__;__min:[0]\n",
      ";model/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_max_model/sequential/basic_block_1/re_lu_2/Relu_1__print__;__max:[20.8172016]\n",
      ";model/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_max_model/sequential/basic_block_1/re_lu_2/Relu_1__print__;__max:[20.8172016]\n",
      ";model/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_max:[20.8172016]\n",
      ";model/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min:[-9.45641708]\n",
      ";model/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_max:[10.6748495]\n",
      ";model/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_min_model/sequential_2/basic_block_2/re_lu_3/Relu__print__;__min:[0]\n",
      ";model/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_max_model/sequential_2/basic_block_2/re_lu_3/Relu__print__;__max:[9.56314659]\n",
      ";model/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_max:[9.56314659]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ";model/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_min_model/sequential_2/basic_block_2/re_lu_3/Relu_1__print__;__min:[0]\n",
      ";model/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_max_model/sequential_2/basic_block_2/re_lu_3/Relu_1__print__;__max:[15.5657043]\n",
      ";model/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_max:[15.5657043]\n",
      ";model/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_min_model/sequential_2/basic_block_3/re_lu_4/Relu__print__;__min:[0]\n",
      ";model/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_max_model/sequential_2/basic_block_3/re_lu_4/Relu__print__;__max:[7.74928427]\n",
      ";model/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_max:[7.74928427]\n",
      ";model/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_min_model/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__min:[0]\n",
      ";model/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_min_model/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__min:[0]\n",
      ";model/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_max_model/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__max:[21.698349]\n",
      ";model/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_max_model/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__max:[21.698349]\n",
      ";model/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_max:[21.698349]\n",
      ";model/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min:[-7.64842367]\n",
      ";model/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_max:[6.29270363]\n",
      ";model/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_min_model/sequential_4/basic_block_4/re_lu_5/Relu__print__;__min:[0]\n",
      ";model/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_max_model/sequential_4/basic_block_4/re_lu_5/Relu__print__;__max:[8.38469219]\n",
      ";model/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_max:[8.38469219]\n",
      ";model/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_min_model/sequential_4/basic_block_4/re_lu_5/Relu_1__print__;__min:[0]\n",
      ";model/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_max_model/sequential_4/basic_block_4/re_lu_5/Relu_1__print__;__max:[10.440155]\n",
      ";model/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_max:[10.440155]\n",
      ";model/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_min_model/sequential_4/basic_block_5/re_lu_6/Relu__print__;__min:[0]\n",
      ";model/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_max_model/sequential_4/basic_block_5/re_lu_6/Relu__print__;__max:[5.75058079]\n",
      ";model/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_max:[5.75058079]\n",
      ";model/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_min_model/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__min:[0]\n",
      ";model/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_min_model/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__min:[0]\n",
      ";model/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_max_model/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__max:[11.9365082]\n",
      ";model/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_max_model/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__max:[11.9365082]\n",
      ";model/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_max:[11.9365082]\n",
      ";model/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min:[-5.55768251]\n",
      ";model/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_max:[6.12790155]\n",
      ";model/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_min_model/sequential_6/basic_block_6/re_lu_7/Relu__print__;__min:[0]\n",
      ";model/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_max_model/sequential_6/basic_block_6/re_lu_7/Relu__print__;__max:[5.96297121]\n",
      ";model/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_max:[5.96297121]\n",
      ";model/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_min_model/sequential_6/basic_block_6/re_lu_7/Relu_1__print__;__min:[0]\n",
      ";model/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_max_model/sequential_6/basic_block_6/re_lu_7/Relu_1__print__;__max:[11.1043968]\n",
      ";model/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_max:[11.1043968]\n",
      ";model/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_min_model/sequential_6/basic_block_7/re_lu_8/Relu__print__;__min:[0]\n",
      ";model/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_max_model/sequential_6/basic_block_7/re_lu_8/Relu__print__;__max:[6.91692877]\n",
      ";model/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_max:[6.91692877]\n",
      ";model/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_max:[13.6326027]\n",
      ";model/dense/MatMul_eightbit_min_model/flatten/Reshape__print__;__min:[0]\n",
      ";model/dense/MatMul_eightbit_max_model/flatten/Reshape__print__;__max:[3.50767684]\n",
      ";model/dense/MatMul_eightbit_requant_range__print__;__requant_min:[-20.6411324]\n",
      ";model/dense/MatMul_eightbit_requant_range__print__;__requant_max:[20.0204334]\n",
      "2022-05-19 03:31:47 [INFO] Pass QuantizedRNNConverter elapsed time: 10.22 ms\n",
      "2022-05-19 03:31:47 [INFO] Pass StripUnusedNodesOptimizer elapsed time: 13.59 ms\n",
      "2022-05-19 03:31:47 [INFO] Pass RemoveTrainingNodesOptimizer elapsed time: 5.51 ms\n",
      "2022-05-19 03:31:47 [INFO] Pass FoldBatchNormNodesOptimizer elapsed time: 4.65 ms\n",
      "2022-05-19 03:31:47 [INFO] Pass MetaOpOptimizer elapsed time: 2.6 ms\n",
      "2022-05-19 03:31:47 [INFO] Pass PostCseOptimizer elapsed time: 335.55 ms\n",
      "2022-05-19 03:31:48 [INFO] |******Mixed Precision Statistics*****|\n",
      "2022-05-19 03:31:48 [INFO] +-----------------+----------+--------+\n",
      "2022-05-19 03:31:48 [INFO] |     Op Type     |  Total   |  INT8  |\n",
      "2022-05-19 03:31:48 [INFO] +-----------------+----------+--------+\n",
      "2022-05-19 03:31:48 [INFO] |      Conv2D     |    20    |   20   |\n",
      "2022-05-19 03:31:48 [INFO] |      MatMul     |    1     |   1    |\n",
      "2022-05-19 03:31:48 [INFO] |    QuantizeV2   |    2     |   2    |\n",
      "2022-05-19 03:31:48 [INFO] |    Dequantize   |    2     |   2    |\n",
      "2022-05-19 03:31:48 [INFO] +-----------------+----------+--------+\n",
      "2022-05-19 03:31:48 [INFO] Pass quantize model elapsed time: 5179.45 ms\n",
      "2022-05-19 03:31:48 [INFO] Start to evaluate the TensorFlow model.\n",
      "2022-05-19 03:31:56 [INFO] Model inference elapsed time: 8047.18 ms\n",
      "2022-05-19 03:31:56 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 2.2449|2.2458, Duration (seconds) (int8|fp32): 8.0481|15.8979], Best tune result is: [Accuracy: 2.2449, Duration (seconds): 8.0481]\n",
      "2022-05-19 03:31:56 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2022-05-19 03:31:56 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-05-19 03:31:56 [INFO] |     Info Type      | Baseline | Tune 1 result | Best tune result |\n",
      "2022-05-19 03:31:56 [INFO] +--------------------+----------+---------------+------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 03:31:56 [INFO] |      Accuracy      | 2.2458   |    2.2449     |     2.2449       |\n",
      "2022-05-19 03:31:56 [INFO] | Duration (seconds) | 15.8979  |    8.0481     |     8.0481       |\n",
      "2022-05-19 03:31:56 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-05-19 03:31:56 [INFO] Save tuning history to /home/projects/notebooks/nc_workspace/2022-05-19_03-31-14/./history.snapshot.\n",
      "2022-05-19 03:31:56 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2022-05-19 03:31:56 [INFO] Save deploy yaml to /home/projects/notebooks/nc_workspace/2022-05-19_03-31-14/deploy.yaml\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "model_quantized = model.quantize(calib_dataset=test_dataset,\n",
    "                                 val_dataset=test_dataset,\n",
    "                                 batch=64,\n",
    "                                 metric=tf.keras.metrics.CategoricalCrossentropy(),\n",
    "                                 tuning_strategy='basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "163dd93a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1073741824 bytes == 0x5584e0b98000 @  0x7fbf54de6680 0x7fbf54e07824 0x7fbf54e07b8a 0x7fbf45486402 0x7fbf39820eb0 0x7fbf39840a93 0x7fbf398449ea 0x7fbf39844f69 0x7fbf398452d1 0x7fbf39839ce3 0x7fbf34eff051 0x7fbf34d5a1d5 0x7fbf34aed087 0x7fbf34aed91e 0x7fbf34aedb1d 0x7fbf3da40c92 0x7fbf3da557f0 0x7fbf3daf954d 0x7fbf3dafb1b7 0x7fbf34f00d7c 0x7fbf34e8acec 0x7fbf3a24d76e 0x7fbf3a24a1f3 0x7fbf355dc313 0x7fbf54db1609 0x7fbf54cd6163\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "with model_quantized.sess as sess:\n",
    "    out = sess.run(model_quantized.output_tensor,\n",
    "             feed_dict={model_quantized.input_tensor[0]: test_images})\n",
    "infer_time_model_quantized = time() - start\n",
    "acc_model_quantized = np.mean(np.equal(tf.argmax(out)[0], test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "677cb0bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|    Precision   | Inference Time(s) |\n",
      "|      FP32      |        5.21       |\n",
      "|      INT8      |        1.07       |\n",
      "| Improvement(%) |       79.46       |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "|    Precision   | Inference Time(s) |\n",
    "|      FP32      |       {:5.2f}       |\n",
    "|      INT8      |       {:5.2f}       |\n",
    "| Improvement(%) |       {:5.2f}       |\n",
    "\"\"\"\n",
    "summary = template.format(\n",
    "    infer_time_model_basic,\n",
    "    infer_time_model_quantized,\n",
    "    (1 - infer_time_model_quantized /infer_time_model_basic) * 100\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e6169",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}