{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b169f608",
   "metadata": {},
   "source": [
    "## BigDL-Nano Keras Inference Example\n",
    "---\n",
    "This example shows the usage of BigDL-Nano Tensorflow Keras inference pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16885330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from bigdl.nano.tf.keras import Model, Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640ab0f3",
   "metadata": {},
   "source": [
    "### CIFAR10 Data Module\n",
    "---\n",
    "Import the existing data module from keras.datasets and Normalize the images.<br>\n",
    "You could access [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) for a view of the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f6648b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = keras.datasets.cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "train_labels = keras.utils.to_categorical(train_labels, 10)\n",
    "y_test = test_labels\n",
    "test_labels = keras.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2478a09",
   "metadata": {},
   "source": [
    "### Implement ResNet-18 model and load model weights from hdf5 file\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad09735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(Model):\n",
    "    def __init__(self, channels:int, downsample = False):\n",
    "        super().__init__()\n",
    "        self.downsample = downsample\n",
    "        self.conv1 = layers.Conv2D(filters=channels, strides=2 if downsample else 1, kernel_size=(3, 3),\n",
    "                                         padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        self.conv2 = layers.Conv2D(filters=channels, strides=1, kernel_size=(3, 3), \n",
    "                                         padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        if downsample:\n",
    "            self.downsample = keras.Sequential([\n",
    "                keras.layers.Conv2D(filters=channels, strides=2, kernel_size=(1, 1),\n",
    "                                    padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "                keras.layers.BatchNormalization()\n",
    "            ])\n",
    "    def call(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f89985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18(Model):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        \"\"\"\n",
    "            num_classes: number of classes in specific classification task.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=(3, 3), strides=1, padding=\"same\")\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "        self.layer1 = keras.Sequential([\n",
    "            BasicBlock(64),\n",
    "            BasicBlock(64)\n",
    "        ])\n",
    "        self.layer2 = keras.Sequential([\n",
    "            BasicBlock(128, downsample=True),\n",
    "            BasicBlock(128)\n",
    "        ])\n",
    "        self.layer3 = keras.Sequential([\n",
    "            BasicBlock(256, downsample=True),\n",
    "            BasicBlock(256)\n",
    "        ])\n",
    "        self.layer4 = keras.Sequential([\n",
    "            BasicBlock(512, downsample=True),\n",
    "            BasicBlock(512)\n",
    "        ])\n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.flat = layers.Flatten()\n",
    "        self.fc = layers.Dense(num_classes)\n",
    "        self.activate = layers.Softmax()\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        out = self.avgpool(out)\n",
    "        out = self.flat(out)\n",
    "        out = self.fc(out)\n",
    "        out = self.activate(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2843baf",
   "metadata": {},
   "source": [
    "### Define Inputs and Outputs of Model\n",
    "---\n",
    "Optimization of KERAS Model using BigDL-nano quantization requires obtaining inputs and outputs of the Model. However, the two attributes of Model subclasses cannot be set directly at present, so we need to call keras.Model() to set them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c281d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 00:38:31.624950: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " resnet18 (Resnet18)         (None, 10)                11188362  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,188,362\n",
      "Trainable params: 11,178,762\n",
      "Non-trainable params: 9,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Resnet18(10)\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.load_weights(\"checkpoints/basic_resnet18.hdf5\")\n",
    "inputs=keras.Input(shape=(32, 32, 3))\n",
    "outputs = model(inputs)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d0adb7",
   "metadata": {},
   "source": [
    "### Measure basic model inference time and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caa2d54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 21ms/step - loss: 0.4191 - accuracy: 0.8784\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model.predict(test_images, batch_size=64)\n",
    "infer_time_model_basic = time() - start\n",
    "acc_model_basic = model.evaluate(test_images, test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32dfdb1",
   "metadata": {},
   "source": [
    "### Quantize Model\n",
    "---\n",
    "Use Model.quantize from bigdl.nano.tf.keras to calibrate a keras model for post-training quantization.<br>\n",
    "Here are the parameters used in the notebook:\n",
    "```\n",
    "    :param calib_dataset:  A tf.data.Dataset object for calibration. Required for\n",
    "                            static quantization.\n",
    "    :param val_dataset:    A tf.data.Dataset object for evaluation.\n",
    "    :param batch:          Batch size of dataloader for both calib_dataset and val_dataset.\n",
    "    :param metric:         A Metric object for evaluation.\n",
    "    \n",
    "    :param tuning_strategy:    'bayesian', 'basic', 'mse', 'sigopt'. Default: 'bayesian'.\n",
    "    \n",
    "```\n",
    "Access more details from [Source](https://github.com/intel-analytics/BigDL/blob/main/python/nano/src/bigdl/nano/tf/quantization.py#L22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9ccaf4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 00:39:01 [WARNING] Override the value of `metric` field defined in yaml file as user defines the value of `metric` attribute by code.\n",
      "2022-05-23 00:39:02.285747: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-05-23 00:39:02.285865: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-05-23 00:39:02.295360: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.007ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "\n",
      "2022-05-23 00:39:02.830939: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-05-23 00:39:02.831076: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-05-23 00:39:02.989192: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: tf_graph\n",
      "  constant_folding: Graph size after: 217 nodes (-122), 346 edges (-122), time = 59.718ms.\n",
      "  constant_folding: Graph size after: 217 nodes (0), 346 edges (0), time = 39.885ms.\n",
      "\n",
      "2022-05-23 00:39:03 [INFO] ConvertLayoutOptimizer elapsed time: 0.34 ms\n",
      "2022-05-23 00:39:04.969933: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-05-23 00:39:04.970093: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-05-23 00:39:05.085783: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  model_pruner: Graph size after: 217 nodes (0), 346 edges (0), time = 13.676ms.\n",
      "  shape_optimizer: shape_optimizer did nothing. time = 0.491ms.\n",
      "  dependency_optimizer: Graph size after: 216 nodes (-1), 223 edges (-123), time = 10.346ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.363ms.\n",
      "  loop_optimizer: Graph size after: 216 nodes (0), 223 edges (0), time = 8.3ms.\n",
      "  model_pruner: Graph size after: 216 nodes (0), 223 edges (0), time = 8.896ms.\n",
      "  shape_optimizer: shape_optimizer did nothing. time = 0.44ms.\n",
      "  dependency_optimizer: Graph size after: 216 nodes (0), 223 edges (0), time = 9.335ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.371ms.\n",
      "\n",
      "2022-05-23 00:39:05 [INFO] Pass GrapplerOptimizer elapsed time: 1879.82 ms\n",
      "2022-05-23 00:39:05 [INFO] Pass SwitchOptimizer elapsed time: 283.41 ms\n",
      "2022-05-23 00:39:05 [INFO] Pass RemoveTrainingNodesOptimizer elapsed time: 276.39 ms\n",
      "2022-05-23 00:39:05 [INFO] Pass SplitSharedInputOptimizer elapsed time: 2.3 ms\n",
      "2022-05-23 00:39:05 [INFO] Pass GraphFoldConstantOptimizer elapsed time: 276.33 ms\n",
      "2022-05-23 00:39:06 [INFO] Pass FuseColumnWiseMulOptimizer elapsed time: 277.33 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/nanoWithTf/lib/python3.7/site-packages/neural_compressor/adaptor/tf_utils/util.py:322: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 00:39:06 [WARNING] From /opt/conda/envs/nanoWithTf/lib/python3.7/site-packages/neural_compressor/adaptor/tf_utils/util.py:322: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2022-05-23 00:39:07 [INFO] Pass StripUnusedNodesOptimizer elapsed time: 1120.48 ms\n",
      "2022-05-23 00:39:07 [INFO] Pass GraphCseOptimizer elapsed time: 276.26 ms\n",
      "2022-05-23 00:39:08 [INFO] Pass FoldBatchNormNodesOptimizer elapsed time: 696.7 ms\n",
      "2022-05-23 00:39:08 [INFO] Pass UpdateEnterOptimizer elapsed time: 0.92 ms\n",
      "2022-05-23 00:39:08 [INFO] Pass ConvertLeakyReluOptimizer elapsed time: 1.56 ms\n",
      "2022-05-23 00:39:08 [INFO] Pass ConvertAddToBiasAddOptimizer elapsed time: 1.9 ms\n",
      "2022-05-23 00:39:08 [INFO] Pass FuseTransposeReshapeOptimizer elapsed time: 1.74 ms\n",
      "2022-05-23 00:39:08 [INFO] Pass FuseConvWithMathOptimizer elapsed time: 1.74 ms\n",
      "2022-05-23 00:39:08 [INFO] Pass ExpandDimsOptimizer elapsed time: 1.58 ms\n",
      "2022-05-23 00:39:08 [INFO] Pass InjectDummyBiasAddOptimizer elapsed time: 1.81 ms\n",
      "2022-05-23 00:39:08 [INFO] Pass MoveSqueezeAfterReluOptimizer elapsed time: 1.42 ms\n",
      "2022-05-23 00:39:08 [INFO] Pass Pre Optimization elapsed time: 5345.6 ms\n",
      "2022-05-23 00:39:08 [INFO] Get FP32 model baseline.\n",
      "2022-05-23 00:39:08 [INFO] Start to evaluate the TensorFlow model.\n",
      "2022-05-23 00:39:19 [INFO] Model inference elapsed time: 10355.62 ms\n",
      "2022-05-23 00:39:19 [INFO] Save tuning history to /home/projects/notebooks/nc_workspace/2022-05-23_00-39-01/./history.snapshot.\n",
      "2022-05-23 00:39:19 [INFO] FP32 baseline is: [Accuracy: 2.2458, Duration (seconds): 10.3568]\n",
      "2022-05-23 00:39:19 [WARNING] Reset `calibration.dataloader.batch_size` field to 50 to make sure the sampling_size is divisible exactly by batch size\n",
      "2022-05-23 00:39:19 [WARNING] Found possible input node names: ['input_1'], output node names: ['resnet18'].\n",
      "2022-05-23 00:39:19 [WARNING] Found possible input node names: ['input_1'], output node names: ['resnet18'].\n",
      "2022-05-23 00:39:19.649629: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-05-23 00:39:19.649759: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-05-23 00:39:19.658682: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "\n",
      "2022-05-23 00:39:20.215560: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-05-23 00:39:20.215711: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-05-23 00:39:20.365684: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: tf_graph\n",
      "  constant_folding: Graph size after: 217 nodes (-122), 346 edges (-122), time = 58.737ms.\n",
      "  constant_folding: Graph size after: 217 nodes (0), 346 edges (0), time = 37.293ms.\n",
      "\n",
      "2022-05-23 00:39:20 [INFO] Pass Quantization elapsed time: 240.27 ms\n",
      "2022-05-23 00:39:21 [INFO] Start sampling on calibration dataset.\n",
      ";model/resnet18/conv2d/Conv2D_eightbit_min_input_1__print__;__min:[0]\n",
      ";model/resnet18/conv2d/Conv2D_eightbit_max_input_1__print__;__max:[1]\n",
      ";model/resnet18/sequential/basic_block/conv2d_1/Conv2D_eightbit_min_model/resnet18/re_lu/Relu__print__;__min:[0]\n",
      ";model/resnet18/conv2d/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential/basic_block/conv2d_1/Conv2D_eightbit_max_model/resnet18/re_lu/Relu__print__;__max:[11.1612606]\n",
      ";model/resnet18/conv2d/Conv2D_eightbit_requant_range__print__;__requant_max:[11.1612606]\n",
      ";model/resnet18/sequential/basic_block/conv2d_2/Conv2D_eightbit_min_model/resnet18/sequential/basic_block/re_lu_1/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential/basic_block/conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential/basic_block/conv2d_2/Conv2D_eightbit_max_model/resnet18/sequential/basic_block/re_lu_1/Relu__print__;__max:[16.74123]\n",
      ";model/resnet18/sequential/basic_block/conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_max:[16.74123]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_min_model/resnet18/sequential/basic_block/re_lu_1/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential/basic_block/conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_max_model/resnet18/sequential/basic_block/re_lu_1/Relu_1__print__;__max:[18.2626801]\n",
      ";model/resnet18/sequential/basic_block/conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_max:[18.2626801]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_min_model/resnet18/sequential/basic_block_1/re_lu_2/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_max_model/resnet18/sequential/basic_block_1/re_lu_2/Relu__print__;__max:[9.76859283]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_max:[9.76859283]\n",
      ";model/resnet18/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_min_model/resnet18/sequential/basic_block_1/re_lu_2/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_min_model/resnet18/sequential/basic_block_1/re_lu_2/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_max_model/resnet18/sequential/basic_block_1/re_lu_2/Relu_1__print__;__max:[22.4159622]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_max_model/resnet18/sequential/basic_block_1/re_lu_2/Relu_1__print__;__max:[22.4159622]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_max:[22.4159622]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_min_model/resnet18/sequential_2/basic_block_2/re_lu_3/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_max_model/resnet18/sequential_2/basic_block_2/re_lu_3/Relu__print__;__max:[12.2209377]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_max:[12.2209377]\n",
      ";model/resnet18/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min:[-10.1294727]\n",
      ";model/resnet18/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_max:[9.88350868]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_min_model/resnet18/sequential_2/basic_block_2/re_lu_3/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_max_model/resnet18/sequential_2/basic_block_2/re_lu_3/Relu_1__print__;__max:[13.8876419]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_max:[13.8876419]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_min_model/resnet18/sequential_2/basic_block_3/re_lu_4/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_max_model/resnet18/sequential_2/basic_block_3/re_lu_4/Relu__print__;__max:[7.40132189]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_max:[7.40132189]\n",
      ";model/resnet18/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_min_model/resnet18/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_min_model/resnet18/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_max_model/resnet18/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__max:[19.5631084]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_max_model/resnet18/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__max:[19.5631084]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_max:[19.5631084]\n",
      ";model/resnet18/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min:[-6.5698595]\n",
      ";model/resnet18/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_max:[5.57459354]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_min_model/resnet18/sequential_4/basic_block_4/re_lu_5/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_max_model/resnet18/sequential_4/basic_block_4/re_lu_5/Relu__print__;__max:[8.40939]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_max:[8.40939]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_min_model/resnet18/sequential_4/basic_block_4/re_lu_5/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_max_model/resnet18/sequential_4/basic_block_4/re_lu_5/Relu_1__print__;__max:[12.386837]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_max:[12.386837]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_min_model/resnet18/sequential_4/basic_block_5/re_lu_6/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_max_model/resnet18/sequential_4/basic_block_5/re_lu_6/Relu__print__;__max:[6.40167093]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_max:[6.40167093]\n",
      ";model/resnet18/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_min_model/resnet18/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_min_model/resnet18/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_max_model/resnet18/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__max:[15.8724537]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_max_model/resnet18/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__max:[15.8724537]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_max:[15.8724537]\n",
      ";model/resnet18/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min:[-5.72582912]\n",
      ";model/resnet18/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_max:[6.52874804]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_min_model/resnet18/sequential_6/basic_block_6/re_lu_7/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_max_model/resnet18/sequential_6/basic_block_6/re_lu_7/Relu__print__;__max:[7.82672596]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_max:[7.82672596]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_min_model/resnet18/sequential_6/basic_block_6/re_lu_7/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_max_model/resnet18/sequential_6/basic_block_6/re_lu_7/Relu_1__print__;__max:[13.2797775]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_max:[13.2797775]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_min_model/resnet18/sequential_6/basic_block_7/re_lu_8/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_max_model/resnet18/sequential_6/basic_block_7/re_lu_8/Relu__print__;__max:[9.01873684]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_max:[9.01873684]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_max:[16.7508545]\n",
      ";model/resnet18/dense/MatMul_eightbit_min_model/resnet18/flatten/Reshape__print__;__min:[0]\n",
      ";model/resnet18/dense/MatMul_eightbit_max_model/resnet18/flatten/Reshape__print__;__max:[4.74937201]\n",
      ";model/resnet18/dense/MatMul_eightbit_requant_range__print__;__requant_min:[-22.0720081]\n",
      ";model/resnet18/dense/MatMul_eightbit_requant_range__print__;__requant_max:[28.8185577]\n",
      ";model/resnet18/conv2d/Conv2D_eightbit_min_input_1__print__;__min:[0]\n",
      ";model/resnet18/conv2d/Conv2D_eightbit_max_input_1__print__;__max:[1]\n",
      ";model/resnet18/sequential/basic_block/conv2d_1/Conv2D_eightbit_min_model/resnet18/re_lu/Relu__print__;__min:[0]\n",
      ";model/resnet18/conv2d/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential/basic_block/conv2d_1/Conv2D_eightbit_max_model/resnet18/re_lu/Relu__print__;__max:[10.9765253]\n",
      ";model/resnet18/conv2d/Conv2D_eightbit_requant_range__print__;__requant_max:[10.9765253]\n",
      ";model/resnet18/sequential/basic_block/conv2d_2/Conv2D_eightbit_min_model/resnet18/sequential/basic_block/re_lu_1/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential/basic_block/conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential/basic_block/conv2d_2/Conv2D_eightbit_max_model/resnet18/sequential/basic_block/re_lu_1/Relu__print__;__max:[16.2410831]\n",
      ";model/resnet18/sequential/basic_block/conv2d_1/Conv2D_eightbit_requant_range__print__;__requant_max:[16.2410831]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_min_model/resnet18/sequential/basic_block/re_lu_1/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential/basic_block/conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_max_model/resnet18/sequential/basic_block/re_lu_1/Relu_1__print__;__max:[18.8361473]\n",
      ";model/resnet18/sequential/basic_block/conv2d_2/Conv2D_eightbit_requant_range__print__;__requant_max:[18.8361473]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_min_model/resnet18/sequential/basic_block_1/re_lu_2/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_max_model/resnet18/sequential/basic_block_1/re_lu_2/Relu__print__;__max:[9.49592876]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_3/Conv2D_eightbit_requant_range__print__;__requant_max:[9.49592876]\n",
      ";model/resnet18/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_min_model/resnet18/sequential/basic_block_1/re_lu_2/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_min_model/resnet18/sequential/basic_block_1/re_lu_2/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_max_model/resnet18/sequential/basic_block_1/re_lu_2/Relu_1__print__;__max:[20.8172016]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_max_model/resnet18/sequential/basic_block_1/re_lu_2/Relu_1__print__;__max:[20.8172016]\n",
      ";model/resnet18/sequential/basic_block_1/conv2d_4/Conv2D_eightbit_requant_range__print__;__requant_max:[20.8172016]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_min_model/resnet18/sequential_2/basic_block_2/re_lu_3/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_max_model/resnet18/sequential_2/basic_block_2/re_lu_3/Relu__print__;__max:[9.56314659]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_5/Conv2D_eightbit_requant_range__print__;__requant_max:[9.56314659]\n",
      ";model/resnet18/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_min:[-9.45641708]\n",
      ";model/resnet18/sequential_2/basic_block_2/sequential_1/conv2d_7/Conv2D_eightbit_requant_range__print__;__requant_max:[10.6748495]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_min_model/resnet18/sequential_2/basic_block_2/re_lu_3/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_max_model/resnet18/sequential_2/basic_block_2/re_lu_3/Relu_1__print__;__max:[15.5657043]\n",
      ";model/resnet18/sequential_2/basic_block_2/conv2d_6/Conv2D_eightbit_requant_range__print__;__requant_max:[15.5657043]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_min_model/resnet18/sequential_2/basic_block_3/re_lu_4/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_max_model/resnet18/sequential_2/basic_block_3/re_lu_4/Relu__print__;__max:[7.74928427]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_8/Conv2D_eightbit_requant_range__print__;__requant_max:[7.74928427]\n",
      ";model/resnet18/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_min_model/resnet18/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_min_model/resnet18/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_max_model/resnet18/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__max:[21.698349]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_max_model/resnet18/sequential_2/basic_block_3/re_lu_4/Relu_1__print__;__max:[21.698349]\n",
      ";model/resnet18/sequential_2/basic_block_3/conv2d_9/Conv2D_eightbit_requant_range__print__;__requant_max:[21.698349]\n",
      ";model/resnet18/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_min:[-7.64842367]\n",
      ";model/resnet18/sequential_4/basic_block_4/sequential_3/conv2d_12/Conv2D_eightbit_requant_range__print__;__requant_max:[6.29270363]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_min_model/resnet18/sequential_4/basic_block_4/re_lu_5/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_max_model/resnet18/sequential_4/basic_block_4/re_lu_5/Relu__print__;__max:[8.38469219]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_10/Conv2D_eightbit_requant_range__print__;__requant_max:[8.38469219]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_min_model/resnet18/sequential_4/basic_block_4/re_lu_5/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_max_model/resnet18/sequential_4/basic_block_4/re_lu_5/Relu_1__print__;__max:[10.440155]\n",
      ";model/resnet18/sequential_4/basic_block_4/conv2d_11/Conv2D_eightbit_requant_range__print__;__requant_max:[10.440155]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_min_model/resnet18/sequential_4/basic_block_5/re_lu_6/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_max_model/resnet18/sequential_4/basic_block_5/re_lu_6/Relu__print__;__max:[5.75058079]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_13/Conv2D_eightbit_requant_range__print__;__requant_max:[5.75058079]\n",
      ";model/resnet18/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_min_model/resnet18/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_min_model/resnet18/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_max_model/resnet18/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__max:[11.9365082]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_max_model/resnet18/sequential_4/basic_block_5/re_lu_6/Relu_1__print__;__max:[11.9365082]\n",
      ";model/resnet18/sequential_4/basic_block_5/conv2d_14/Conv2D_eightbit_requant_range__print__;__requant_max:[11.9365082]\n",
      ";model/resnet18/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_min:[-5.55768251]\n",
      ";model/resnet18/sequential_6/basic_block_6/sequential_5/conv2d_17/Conv2D_eightbit_requant_range__print__;__requant_max:[6.12790155]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_min_model/resnet18/sequential_6/basic_block_6/re_lu_7/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_max_model/resnet18/sequential_6/basic_block_6/re_lu_7/Relu__print__;__max:[5.96297121]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_15/Conv2D_eightbit_requant_range__print__;__requant_max:[5.96297121]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_min_model/resnet18/sequential_6/basic_block_6/re_lu_7/Relu_1__print__;__min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_max_model/resnet18/sequential_6/basic_block_6/re_lu_7/Relu_1__print__;__max:[11.1043968]\n",
      ";model/resnet18/sequential_6/basic_block_6/conv2d_16/Conv2D_eightbit_requant_range__print__;__requant_max:[11.1043968]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_min_model/resnet18/sequential_6/basic_block_7/re_lu_8/Relu__print__;__min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_max_model/resnet18/sequential_6/basic_block_7/re_lu_8/Relu__print__;__max:[6.91692877]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_18/Conv2D_eightbit_requant_range__print__;__requant_max:[6.91692877]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_min:[0]\n",
      ";model/resnet18/sequential_6/basic_block_7/conv2d_19/Conv2D_eightbit_requant_range__print__;__requant_max:[13.6326027]\n",
      ";model/resnet18/dense/MatMul_eightbit_min_model/resnet18/flatten/Reshape__print__;__min:[0]\n",
      ";model/resnet18/dense/MatMul_eightbit_max_model/resnet18/flatten/Reshape__print__;__max:[3.50767684]\n",
      ";model/resnet18/dense/MatMul_eightbit_requant_range__print__;__requant_min:[-20.6411324]\n",
      ";model/resnet18/dense/MatMul_eightbit_requant_range__print__;__requant_max:[20.0204334]\n",
      "2022-05-23 00:39:21 [INFO] Pass QuantizedRNNConverter elapsed time: 4.45 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 00:39:21 [INFO] Pass StripUnusedNodesOptimizer elapsed time: 5.79 ms\n",
      "2022-05-23 00:39:21 [INFO] Pass RemoveTrainingNodesOptimizer elapsed time: 2.24 ms\n",
      "2022-05-23 00:39:21 [INFO] Pass FoldBatchNormNodesOptimizer elapsed time: 2.04 ms\n",
      "2022-05-23 00:39:21 [INFO] Pass MetaOpOptimizer elapsed time: 1.24 ms\n",
      "2022-05-23 00:39:22 [INFO] Pass PostCseOptimizer elapsed time: 157.27 ms\n",
      "2022-05-23 00:39:22 [INFO] |******Mixed Precision Statistics*****|\n",
      "2022-05-23 00:39:22 [INFO] +-----------------+----------+--------+\n",
      "2022-05-23 00:39:22 [INFO] |     Op Type     |  Total   |  INT8  |\n",
      "2022-05-23 00:39:22 [INFO] +-----------------+----------+--------+\n",
      "2022-05-23 00:39:22 [INFO] |      Conv2D     |    20    |   20   |\n",
      "2022-05-23 00:39:22 [INFO] |      MatMul     |    1     |   1    |\n",
      "2022-05-23 00:39:22 [INFO] |    QuantizeV2   |    2     |   2    |\n",
      "2022-05-23 00:39:22 [INFO] |    Dequantize   |    2     |   2    |\n",
      "2022-05-23 00:39:22 [INFO] +-----------------+----------+--------+\n",
      "2022-05-23 00:39:22 [INFO] Pass quantize model elapsed time: 3080.94 ms\n",
      "2022-05-23 00:39:22 [INFO] Start to evaluate the TensorFlow model.\n",
      "2022-05-23 00:39:27 [INFO] Model inference elapsed time: 5587.38 ms\n",
      "2022-05-23 00:39:27 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 2.2449|2.2458, Duration (seconds) (int8|fp32): 5.5885|10.3568], Best tune result is: [Accuracy: 2.2449, Duration (seconds): 5.5885]\n",
      "2022-05-23 00:39:27 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2022-05-23 00:39:27 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-05-23 00:39:27 [INFO] |     Info Type      | Baseline | Tune 1 result | Best tune result |\n",
      "2022-05-23 00:39:27 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-05-23 00:39:27 [INFO] |      Accuracy      | 2.2458   |    2.2449     |     2.2449       |\n",
      "2022-05-23 00:39:27 [INFO] | Duration (seconds) | 10.3568  |    5.5885     |     5.5885       |\n",
      "2022-05-23 00:39:27 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2022-05-23 00:39:27 [INFO] Save tuning history to /home/projects/notebooks/nc_workspace/2022-05-23_00-39-01/./history.snapshot.\n",
      "2022-05-23 00:39:27 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2022-05-23 00:39:27 [INFO] Save deploy yaml to /home/projects/notebooks/nc_workspace/2022-05-23_00-39-01/deploy.yaml\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "model_quantized = model.quantize(calib_dataset=test_dataset,\n",
    "                                 val_dataset=test_dataset,\n",
    "                                 batch=64,\n",
    "                                 metric=tf.keras.metrics.CategoricalCrossentropy(),\n",
    "                                 tuning_strategy='basic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1186f272",
   "metadata": {},
   "source": [
    "### Inference with Quantized Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "163dd93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1073741824 bytes == 0x55e795ed6000 @  0x7fcfb5323d3f 0x7fcfb535a0c0 0x7fcfb535d082 0x7fcfb535d243 0x7fcfa598f402 0x7fcf99d29eb0 0x7fcf99d49a93 0x7fcf99d4d9ea 0x7fcf99d4df69 0x7fcf99d4e2d1 0x7fcf99d42ce3 0x7fcf95408051 0x7fcf952631d5 0x7fcf94ff6087 0x7fcf94ff691e 0x7fcf94ff6b1d 0x7fcf9df49c92 0x7fcf9df5e7f0 0x7fcf9e00254d 0x7fcf9e0041b7 0x7fcf95409d7c 0x7fcf95393cec 0x7fcf9a75676e 0x7fcf9a7531f3 0x7fcf95ae5313 0x7fcfb52ba609 0x7fcfb51df163\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "with model_quantized.sess as sess:\n",
    "    out = sess.run(model_quantized.output_tensor,\n",
    "             feed_dict={model_quantized.input_tensor[0]: test_images})\n",
    "infer_time_model_quantized = time() - start\n",
    "acc_model_quantized = np.mean(np.equal(tf.argmax(out)[0], test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "677cb0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|    Precision   | Inference Time(s) |\n",
      "|      FP32      |        5.21       |\n",
      "|      INT8      |        1.07       |\n",
      "| Improvement(%) |       79.46       |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "|    Precision   | Inference Time(s) |\n",
    "|      FP32      |       {:5.2f}       |\n",
    "|      INT8      |       {:5.2f}       |\n",
    "| Improvement(%) |       {:5.2f}       |\n",
    "\"\"\"\n",
    "summary = template.format(\n",
    "    infer_time_model_basic,\n",
    "    infer_time_model_quantized,\n",
    "    (1 - infer_time_model_quantized /infer_time_model_basic) * 100\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e6169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nanoWithTf]",
   "language": "python",
   "name": "conda-env-nanoWithTf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
