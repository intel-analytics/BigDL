# BigDL-LLM Optimization for Large Language Model on Intel GPUs

To help you quickly get started with transformers-style API to run any Huggingface Transformer model on Intel GPU, we provide lots of detailed examples demonstrating various usage, including:

- [Model Folder](Model): examples to run Huggingface Transformer models with INT4 optimizations.
- [More-Data-Types Folder](More-Data-Types): examples of how to apply other low bit optimizations.
- [Save-Load Folder](Save-Load): examples about how to save and load optimized model.
