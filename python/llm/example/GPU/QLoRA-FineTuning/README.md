## Latest update ðŸ”¥

- [2023/12] bigdl-llm now supports fineting [Mixtral-8x7B](./mixtral-finetune/) on Intel Data Center GPU
- [2023/12] bigdl-llm now supports [QA-LoRA](https://arxiv.org/abs/2309.14717) (see ["QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models"](https://arxiv.org/abs/2309.14717))
- [2023/10] QLoRA finetuning on Intel GPU is available