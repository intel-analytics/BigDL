{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_lenet_mnist.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/intel-analytics/BigDL/blob/main/python/orca/colab-notebook/quickstart/pytorch_lenet_mnist_data_creator_func.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1fvwI1q13mC"
      },
      "source": [
        "![image.png](data:image/png;base64,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)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO3ksbTR18JZ"
      },
      "source": [
        "##### Copyright 2016 The BigDL Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HZJ3OR71u23"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "#"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNTssjdw2Bpi"
      },
      "source": [
        "## **Environment Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOosIv3t2Fhp"
      },
      "source": [
        "**Install Java 8**\n",
        "\n",
        "Run the cell on the **Google Colab** to install jdk 1.8.\n",
        "\n",
        "**Note:** if you run this notebook on your computer, root permission is required when running the cell to install Java 8. (You may ignore this cell if Java 8 has already been set up in your computer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBs-RL5p2Ia2",
        "outputId": "879965b0-5985-4e81-b3dc-bde2acad26d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install jdk8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "# Set environment variable JAVA_HOME.\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_312\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS20JSbY2LCJ"
      },
      "source": [
        "**Install BigDL Orca**\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LOrK0lQHhrh"
      },
      "source": [
        "You can install the latest pre-release version using `pip install --pre --upgrade bigdl-orca[ray]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8lgWGhG2Oij",
        "outputId": "e863d261-65ad-429e-cf0a-43554d819649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Installing BigDL Orca from pip will automatically install pyspark, bigdl, and their dependencies.\n",
        "!pip install --pre --upgrade bigdl-orca[ray]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bigdl-orca[ray]\n",
            "  Downloading bigdl_orca-2.1.0b20220725-py3-none-manylinux1_x86_64.whl (23.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bigdl-orca[ray]) (21.3)\n",
            "Collecting bigdl-math==0.14.0.dev1\n",
            "  Downloading bigdl_math-0.14.0.dev1-py3-none-manylinux2010_x86_64.whl (35.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 35.4 MB 430 kB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from bigdl-orca[ray]) (3.7.1)\n",
            "Collecting bigdl-dllib==2.1.0b20220725\n",
            "  Downloading bigdl_dllib-2.1.0b20220725-py3-none-manylinux1_x86_64.whl (51.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 51.6 MB 3.5 kB/s \n",
            "\u001b[?25hCollecting bigdl-tf==0.14.0.dev1\n",
            "  Downloading bigdl_tf-0.14.0.dev1-py3-none-manylinux2010_x86_64.whl (71.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 71.0 MB 315 bytes/s \n",
            "\u001b[?25hRequirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from bigdl-orca[ray]) (23.2.0)\n",
            "Collecting async-timeout==4.0.1\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting aioredis==1.3.1\n",
            "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting ray[default]==1.9.2\n",
            "  Downloading ray-1.9.2-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 57.6 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting hiredis==2.0.0\n",
            "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting aiohttp==3.8.1\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from bigdl-orca[ray]) (5.4.8)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 58.7 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca[ray]) (4.1.1)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca[ray]) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca[ray]) (21.4.0)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting pyspark==2.4.6\n",
            "  Downloading pyspark-2.4.6.tar.gz (218.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 218.4 MB 50 kB/s \n",
            "\u001b[?25hCollecting bigdl-core==2.1.0b20220321\n",
            "  Downloading bigdl_core-2.1.0b20220321-py3-none-manylinux2010_x86_64.whl (51.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 51.0 MB 40 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from bigdl-dllib==2.1.0b20220725->bigdl-orca[ray]) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from bigdl-dllib==2.1.0b20220725->bigdl-orca[ray]) (1.21.6)\n",
            "Collecting conda-pack==0.3.1\n",
            "  Downloading conda_pack-0.3.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from conda-pack==0.3.1->bigdl-dllib==2.1.0b20220725->bigdl-orca[ray]) (57.4.0)\n",
            "Collecting py4j==0.10.7\n",
            "  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 48.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (1.0.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (4.3.3)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (1.47.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (3.13)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.3.4-py3-none-any.whl (246 kB)\n",
            "\u001b[K     |████████████████████████████████| 246 kB 44.0 MB/s \n",
            "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
            "  Downloading gpustat-1.0.0rc1.tar.gz (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (5.2.1)\n",
            "Collecting colorful\n",
            "  Downloading colorful-0.6.0a1-py2.py3-none-any.whl (202 kB)\n",
            "\u001b[K     |████████████████████████████████| 202 kB 56.0 MB/s \n",
            "\u001b[?25hCollecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.4.0_dev2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 23.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (2.23.0)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca[ray]) (0.14.1)\n",
            "Collecting opencensus\n",
            "  Downloading opencensus-0.10.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 53.2 MB/s \n",
            "\u001b[?25hCollecting nvidia-ml-py<=11.495.46,>=11.450.129\n",
            "  Downloading nvidia_ml_py-11.495.46-py3-none-any.whl (25 kB)\n",
            "Collecting psutil\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 51.0 MB/s \n",
            "\u001b[?25hCollecting blessed>=1.17.1\n",
            "  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[default]==1.9.2->bigdl-orca[ray]) (0.2.5)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]==1.9.2->bigdl-orca[ray]) (4.12.0)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.3.3-py3-none-any.whl (244 kB)\n",
            "\u001b[K     |████████████████████████████████| 244 kB 62.8 MB/s \n",
            "\u001b[?25h  Downloading redis-4.3.2-py3-none-any.whl (244 kB)\n",
            "\u001b[K     |████████████████████████████████| 244 kB 59.9 MB/s \n",
            "\u001b[?25h  Downloading redis-4.3.1-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 61.0 MB/s \n",
            "\u001b[?25h  Downloading redis-4.3.0-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 31.2 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.2-py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 75.9 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.1-py3-none-any.whl (225 kB)\n",
            "\u001b[K     |████████████████████████████████| 225 kB 73.8 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0-py3-none-any.whl (225 kB)\n",
            "\u001b[K     |████████████████████████████████| 225 kB 53.5 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0rc3-py3-none-any.whl (224 kB)\n",
            "\u001b[K     |████████████████████████████████| 224 kB 62.1 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0rc2-py3-none-any.whl (223 kB)\n",
            "\u001b[K     |████████████████████████████████| 223 kB 56.5 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0rc1-py3-none-any.whl (220 kB)\n",
            "\u001b[K     |████████████████████████████████| 220 kB 62.9 MB/s \n",
            "\u001b[?25h  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 61.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]==1.9.2->bigdl-orca[ray]) (1.14.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[default]==1.9.2->bigdl-orca[ray]) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bigdl-orca[ray]) (3.0.9)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.8.1->bigdl-orca[ray]) (2.10)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]==1.9.2->bigdl-orca[ray]) (5.8.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]==1.9.2->bigdl-orca[ray]) (0.18.1)\n",
            "Collecting opencensus-context>=0.1.2\n",
            "  Downloading opencensus_context-0.2.dev0-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (1.31.6)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (1.35.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (2022.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (1.56.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (4.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca[ray]) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca[ray]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca[ray]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca[ray]) (2022.6.15)\n",
            "Building wheels for collected packages: pyspark, gpustat\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.6-py2.py3-none-any.whl size=218814407 sha256=b94e81b6d357d3d8e883eb6724442dbb7745a1aa4280c561b766a4b03482e921\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/42/b0/ba397759613f4feb1611021a2503e60e344e546671b2ae04f8\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.0.0rc1-py3-none-any.whl size=18872 sha256=f6be21b21825f73dc4176261bff3a4569539198fa9a7536f2bfaf0c1b8a66f4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/85/03/7f87ed3a11307c5ad083829b59731788971a8411c265984409\n",
            "Successfully built pyspark gpustat\n",
            "Installing collected packages: multidict, frozenlist, yarl, py4j, deprecated, asynctest, async-timeout, aiosignal, redis, pyspark, psutil, opencensus-context, nvidia-ml-py, hiredis, conda-pack, blessed, bigdl-core, aiohttp, ray, py-spy, opencensus, gpustat, colorful, bigdl-tf, bigdl-math, bigdl-dllib, aioredis, aiohttp-cors, setproctitle, bigdl-orca\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed aiohttp-3.8.1 aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 bigdl-core-2.1.0b20220321 bigdl-dllib-2.1.0b20220725 bigdl-math-0.14.0.dev1 bigdl-orca-2.1.0b20220725 bigdl-tf-0.14.0.dev1 blessed-1.19.1 colorful-0.6.0a1 conda-pack-0.3.1 deprecated-1.2.13 frozenlist-1.3.0 gpustat-1.0.0rc1 hiredis-2.0.0 multidict-6.0.2 nvidia-ml-py-11.495.46 opencensus-0.10.0 opencensus-context-0.2.dev0 psutil-5.9.1 py-spy-0.4.0.dev2 py4j-0.10.7 pyspark-2.4.6 ray-1.9.2 redis-4.1.4 setproctitle-1.2.3 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EFkPl4I2RJG",
        "outputId": "53906e57-6efe-47f5-a99c-7d9b54127f9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install python dependencies\n",
        "!pip install torch==1.7.1 torchvision==0.8.2 torchmetrics"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 16 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2\n",
            "  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 43.9 MB/s \n",
            "\u001b[?25hCollecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 72.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.21.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (7.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torch, torchvision, torchmetrics\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.0+cu113\n",
            "    Uninstalling torchvision-0.13.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.7.1 torchmetrics-0.9.3 torchvision-0.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATJ4YPAS2TQm"
      },
      "source": [
        "## **Distributed PyTorch using Orca APIs**\n",
        "\n",
        "In this guide we will describe how to scale out PyTorch programs using `ray` package on Orca in 4 simple steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXeY_v2S24bN"
      },
      "source": [
        "# import necesary libraries and modules\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "from bigdl.orca import init_orca_context, stop_orca_context\n",
        "from bigdl.orca import OrcaContext"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn6xcsq43FRQ"
      },
      "source": [
        "### **Step 1: Init Orca Context**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXMGhKPk3GYN",
        "outputId": "8ed40ac1-2922-45bc-ace5-84ca1cb9711c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# recommended to set it to True when running BigDL in Jupyter notebook. \n",
        "OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\n",
        "\n",
        "cluster_mode = \"local\"\n",
        "\n",
        "if cluster_mode == \"local\":\n",
        "    init_orca_context(cores=1, memory=\"2g\") # run in local mode\n",
        "elif cluster_mode == \"k8s\":\n",
        "    init_orca_context(cluster_mode=\"k8s\", num_nodes=2, cores=4) # run on K8s cluster\n",
        "elif cluster_mode == \"yarn\":\n",
        "    init_orca_context(\n",
        "      cluster_mode=\"yarn-client\", cores=4, num_nodes=2, memory=\"2g\",\n",
        "      driver_memory=\"10g\", driver_cores=1) # run on Hadoop YARN cluster"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing orca context\n",
            "Current pyspark location is : /usr/local/lib/python3.7/dist-packages/pyspark/__init__.py\n",
            "Start to getOrCreate SparkContext\n",
            "pyspark_submit_args is:  --driver-class-path /usr/local/lib/python3.7/dist-packages/bigdl/share/core/lib/all-2.1.0-20220314.094552-2.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/dllib/lib/bigdl-dllib-spark_2.4.6-2.1.0-SNAPSHOT-jar-with-dependencies.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/orca/lib/bigdl-orca-spark_2.4.6-2.1.0-SNAPSHOT-jar-with-dependencies.jar pyspark-shell \n",
            "Successfully got a SparkContext\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBzXvR3LNxBP"
      },
      "source": [
        "### **Step 2: Define the Model**\n",
        "You may define your model, loss and optimizer in the same way as in any standard (single node) PyTorch program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZASG0afNWxd"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnLBs8BCthUD"
      },
      "source": [
        "After defining your model, you need to define a *Model Creator Function* that returns an instance of your model, and a *Optimizer Creator Function* that returns a PyTorch optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M805tfZnthUE"
      },
      "source": [
        "def model_creator(config):\n",
        "    model = LeNet()\n",
        "    return model\n",
        "\n",
        "def optim_creator(model, config):\n",
        "    return torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-SeParPNtK8"
      },
      "source": [
        "### **Step 3: Define Train Dataset**\n",
        "\n",
        "You can define the dataset using a *Data Creator Function* that has two parameters `config` and `batch_size` and returns a PyTorch `DataLoader`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQMxn902OBoR"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "torch.manual_seed(0)\n",
        "batch_size = 320\n",
        "test_batch_size = 320\n",
        "dir = '/tmp/dataset'\n",
        "\n",
        "def train_loader_creator(config, batch_size):\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(dir, train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=batch_size, shuffle=True)\n",
        "    return train_loader\n",
        "\n",
        "def test_loader_creator(config, batch_size):\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(dir, train=False,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=batch_size, shuffle=False)\n",
        "    return test_loader"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLSjmlkROzPr"
      },
      "source": [
        "### **Step 4: Fit with Orca Estimator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49Rq_fo2O34O"
      },
      "source": [
        "First, Create an Estimator and set its backend to `ray`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-AK6mFKO4o5",
        "outputId": "e0415ac4-2443-4c00-b488-8635094647ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from bigdl.orca.learn.pytorch import Estimator\n",
        "from bigdl.orca.learn.metrics import Accuracy\n",
        "\n",
        "est = Estimator.from_torch(model=model_creator, optimizer=optim_creator, loss=criterion, metrics=[Accuracy()],\n",
        "                           backend=\"ray\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-25 14:33:47,937\tINFO services.py:1340 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://172.28.0.2:8265\u001b[39m\u001b[22m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'node_ip_address': '172.28.0.2', 'raylet_ip_address': '172.28.0.2', 'redis_address': '172.28.0.2:6379', 'object_store_address': '/tmp/ray/session_2022-07-25_14-33-43_122148_58/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-07-25_14-33-43_122148_58/sockets/raylet', 'webui_url': '172.28.0.2:8265', 'session_dir': '/tmp/ray/session_2022-07-25_14-33-43_122148_58', 'metrics_export_port': 53297, 'node_id': '84b5e279c0a3bb4f9bec0fde0f1726f724eed66e67daead51e289680'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PEmVuGnPFBk"
      },
      "source": [
        "Next, fit and evaluate using the Estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeCoGJrGPH5M",
        "outputId": "3b037aac-a113-4430-dd3a-5fd28db41401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from bigdl.orca.learn.trigger import EveryEpoch \n",
        "\n",
        "est.fit(data=train_loader_creator, epochs=1, batch_size=batch_size)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m \r0it [00:00, ?it/s]\n",
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m \r  0%|          | 0/9912422 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m \r 40%|███▉      | 3956736/9912422 [00:00<00:00, 39564567.85it/s]\n",
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m \r9920512it [00:00, 38748024.09it/s]                             \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m Extracting /tmp/dataset/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/dataset/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m \r0it [00:00, ?it/s]\n",
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m \r32768it [00:00, 699217.82it/s]\n",
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m \r0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /tmp/dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m Extracting /tmp/dataset/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/dataset/MNIST/raw\n",
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /tmp/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m \r 55%|█████▍    | 901120/1648877 [00:00<00:00, 9001979.76it/s]\r1654784it [00:00, 14834067.09it/s]                           \n",
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m \r0it [00:00, ?it/s]\r8192it [00:00, 199956.58it/s]\n",
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m   return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m Extracting /tmp/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/dataset/MNIST/raw\n",
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m Extracting /tmp/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/dataset/MNIST/raw\n",
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m Processing...\n",
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m [2022-07-25 14:33:54] INFO     Reducer buckets have been rebuilt in this iteration.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'batch_count': 188,\n",
              "  'epoch': 1,\n",
              "  'last_train_loss': 0.11176373064517975,\n",
              "  'num_samples': 60000,\n",
              "  'train_loss': 0.24628920722007752}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFQCQwH0UBF1"
      },
      "source": [
        "Finally, evaluate using the Estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3cUxgYwUCUl",
        "outputId": "a9576a45-f2ac-412b-892c-578fd7d232c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "result = est.evaluate(data=test_loader_creator, batch_size=test_batch_size)\n",
        "for r in result:\n",
        "    print(r, \":\", result[r])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(PytorchRayWorker pid=526)\u001b[0m [2022-07-25 14:35:36] INFO     Finished training epoch 1, stats on rank 0: {'epoch': 1, 'batch_count': 188, 'num_samples': 60000, 'train_loss': 0.24628920722007752, 'last_train_loss': 0.11176373064517975}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_samples : 10000\n",
            "Accuracy : tensor(0.9806)\n",
            "val_loss : 0.064310356259346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YASrq-VzXdpJ"
      },
      "source": [
        "The accuracy of this model has reached 98%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSSReIykRPIB",
        "outputId": "e79adbb1-a600-433c-dd98-6e85bfaab6ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# stop orca context when program finishes\n",
        "stop_orca_context()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopping orca context\n"
          ]
        }
      ]
    }
  ]
}
