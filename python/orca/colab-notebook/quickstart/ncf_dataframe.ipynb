{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ncf_dataframe.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hkvision/BigDL/blob/update-colab/python/orca/colab-notebook/quickstart/ncf_dataframe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsdUyI7vKEGF"
      },
      "source": [
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQWPKGb4KNv6"
      },
      "source": [
        "## **Environment Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwxHGCOQKToI"
      },
      "source": [
        "**Install Java 8**\n",
        "\n",
        "Run the cell on the **Google Colab** to install jdk 1.8.\n",
        "\n",
        "**Note:** if you run this notebook on your computer, root permission is required when running the cell to install Java 8. (You may ignore this cell if Java 8 has already been set up in your computer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV2cU3jJIXCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c49c4c-fb2a-4665-b9d3-78ac503b2854"
      },
      "source": [
        "# Install jdk8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "# Set environment variable JAVA_HOME.\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_312\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDMnBeFSKz21"
      },
      "source": [
        "**Install BigDL Orca**\n",
        "\n",
        "You can install the latest pre-release version with spark3 using `pip install --pre --upgrade bigdl-orca-spark3[ray]`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FKTQXbDYWWr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c70179c-ac18-4ef9-a0f9-ed1f39620708"
      },
      "source": [
        "# Installing bigdl from pip will automatically install pyspark, bigdl, and their dependencies.\n",
        "!pip install --pre --upgrade bigdl-orca-spark3[ray]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bigdl-orca-spark3[ray]\n",
            "  Downloading bigdl_orca_spark3-2.1.0b20220725-py3-none-manylinux1_x86_64.whl (23.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.8 MB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from bigdl-orca-spark3[ray]) (3.7.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from bigdl-orca-spark3[ray]) (23.2.0)\n",
            "Collecting bigdl-tf==0.14.0.dev1\n",
            "  Downloading bigdl_tf-0.14.0.dev1-py3-none-manylinux2010_x86_64.whl (71.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 71.0 MB 354 bytes/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bigdl-orca-spark3[ray]) (21.3)\n",
            "Collecting bigdl-math==0.14.0.dev1\n",
            "  Downloading bigdl_math-0.14.0.dev1-py3-none-manylinux2010_x86_64.whl (35.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 35.4 MB 440 kB/s \n",
            "\u001b[?25hCollecting bigdl-dllib-spark3==2.1.0b20220725\n",
            "  Downloading bigdl_dllib_spark3-2.1.0b20220725-py3-none-manylinux1_x86_64.whl (48.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.5 MB 65 kB/s \n",
            "\u001b[?25hCollecting async-timeout==4.0.1\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting ray[default]==1.9.2\n",
            "  Downloading ray-1.9.2-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 57.6 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting hiredis==2.0.0\n",
            "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting aiohttp==3.8.1\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 32.7 MB/s \n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting aioredis==1.3.1\n",
            "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from bigdl-orca-spark3[ray]) (5.4.8)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3[ray]) (2.1.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 32.4 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 30.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3[ray]) (4.1.1)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3[ray]) (21.4.0)\n",
            "Collecting bigdl-core==2.1.0b20220321\n",
            "  Downloading bigdl_core-2.1.0b20220321-py3-none-manylinux2010_x86_64.whl (51.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 51.0 MB 41 kB/s \n",
            "\u001b[?25hCollecting pyspark==3.1.2\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 69 kB/s \n",
            "\u001b[?25hCollecting conda-pack==0.3.1\n",
            "  Downloading conda_pack-0.3.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from bigdl-dllib-spark3==2.1.0b20220725->bigdl-orca-spark3[ray]) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from bigdl-dllib-spark3==2.1.0b20220725->bigdl-orca-spark3[ray]) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from conda-pack==0.3.1->bigdl-dllib-spark3==2.1.0b20220725->bigdl-orca-spark3[ray]) (57.4.0)\n",
            "Collecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 46.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3[ray]) (3.13)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3[ray]) (4.3.3)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.3.4-py3-none-any.whl (246 kB)\n",
            "\u001b[K     |████████████████████████████████| 246 kB 61.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3[ray]) (7.1.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3[ray]) (1.0.4)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3[ray]) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3[ray]) (1.47.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3[ray]) (2.23.0)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting gpustat>=1.0.0b1\n",
            "  Downloading gpustat-1.0.0rc1.tar.gz (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.4.0_dev2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 31.7 MB/s \n",
            "\u001b[?25hCollecting colorful\n",
            "  Downloading colorful-0.6.0a1-py2.py3-none-any.whl (202 kB)\n",
            "\u001b[K     |████████████████████████████████| 202 kB 52.3 MB/s \n",
            "\u001b[?25hCollecting opencensus\n",
            "  Downloading opencensus-0.10.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3[ray]) (0.14.1)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3[ray]) (5.2.1)\n",
            "Collecting nvidia-ml-py<=11.495.46,>=11.450.129\n",
            "  Downloading nvidia_ml_py-11.495.46-py3-none-any.whl (25 kB)\n",
            "Collecting psutil\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 70.1 MB/s \n",
            "\u001b[?25hCollecting blessed>=1.17.1\n",
            "  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (4.12.0)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.3.3-py3-none-any.whl (244 kB)\n",
            "\u001b[K     |████████████████████████████████| 244 kB 54.7 MB/s \n",
            "\u001b[?25h  Downloading redis-4.3.2-py3-none-any.whl (244 kB)\n",
            "\u001b[K     |████████████████████████████████| 244 kB 73.4 MB/s \n",
            "\u001b[?25h  Downloading redis-4.3.1-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 59.8 MB/s \n",
            "\u001b[?25h  Downloading redis-4.3.0-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 70.6 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.2-py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 67.0 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.1-py3-none-any.whl (225 kB)\n",
            "\u001b[K     |████████████████████████████████| 225 kB 47.6 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0-py3-none-any.whl (225 kB)\n",
            "\u001b[K     |████████████████████████████████| 225 kB 72.2 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0rc3-py3-none-any.whl (224 kB)\n",
            "\u001b[K     |████████████████████████████████| 224 kB 68.6 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0rc2-py3-none-any.whl (223 kB)\n",
            "\u001b[K     |████████████████████████████████| 223 kB 70.5 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0rc1-py3-none-any.whl (220 kB)\n",
            "\u001b[K     |████████████████████████████████| 220 kB 73.8 MB/s \n",
            "\u001b[?25h  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 58.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (1.14.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bigdl-orca-spark3[ray]) (3.0.9)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.8.1->bigdl-orca-spark3[ray]) (2.10)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (5.8.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (0.18.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (1.31.6)\n",
            "Collecting opencensus-context>=0.1.2\n",
            "  Downloading opencensus_context-0.2.dev0-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (1.35.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (2022.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (1.56.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (0.2.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca-spark3[ray]) (2022.6.15)\n",
            "Building wheels for collected packages: pyspark, gpustat\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880769 sha256=cbfe95d84527a81995c33a3e1bdab7baed40103299fe9d835332b39a8bfb02ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.0.0rc1-py3-none-any.whl size=18872 sha256=4442cbefe590ee3a92da5e7680ab2a96bcccf895f4b4108ce97cbad3e285514a\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/85/03/7f87ed3a11307c5ad083829b59731788971a8411c265984409\n",
            "Successfully built pyspark gpustat\n",
            "Installing collected packages: multidict, frozenlist, yarl, py4j, deprecated, asynctest, async-timeout, aiosignal, redis, pyspark, psutil, opencensus-context, nvidia-ml-py, hiredis, conda-pack, blessed, bigdl-core, aiohttp, ray, py-spy, opencensus, gpustat, colorful, bigdl-tf, bigdl-math, bigdl-dllib-spark3, aioredis, aiohttp-cors, setproctitle, bigdl-orca-spark3\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed aiohttp-3.8.1 aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 bigdl-core-2.1.0b20220321 bigdl-dllib-spark3-2.1.0b20220725 bigdl-math-0.14.0.dev1 bigdl-orca-spark3-2.1.0b20220725 bigdl-tf-0.14.0.dev1 blessed-1.19.1 colorful-0.6.0a1 conda-pack-0.3.1 deprecated-1.2.13 frozenlist-1.3.0 gpustat-1.0.0rc1 hiredis-2.0.0 multidict-6.0.2 nvidia-ml-py-11.495.46 opencensus-0.10.0 opencensus-context-0.2.dev0 psutil-5.9.1 py-spy-0.4.0.dev2 py4j-0.10.9 pyspark-3.1.2 ray-1.9.2 redis-4.1.4 setproctitle-1.2.3 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy-92WBjYdx5"
      },
      "source": [
        "## **Using Spark Dataframes for Distribtued Deep Learning** \n",
        "\n",
        "In this guide we will describe how to use Spark Dataframes to process large-scale dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAy37CZkYy3p"
      },
      "source": [
        "#### **Intialization** \n",
        "\n",
        "import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mNCKlZLY5xI"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from bigdl.dllib.feature.dataset import base\n",
        "\n",
        "from bigdl.orca import init_orca_context, stop_orca_context\n",
        "from bigdl.orca import OrcaContext\n",
        "from bigdl.orca.learn.tf2 import Estimator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU0wwMFgY9hs"
      },
      "source": [
        "## **Init Orca Context** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InTPPklsZMNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da09605-06e9-4b81-9d8f-d34829b0d42b"
      },
      "source": [
        "# recommended to set it to True when running BigDL in Jupyter notebook \n",
        "OrcaContext.log_output = True # (this will display terminal's stdout and stderr in the Jupyter notebook).\n",
        "\n",
        "cluster_mode = \"local\"\n",
        "\n",
        "if cluster_mode == \"local\":  \n",
        "    init_orca_context(cluster_mode=\"local\", cores=1) # run in local mode\n",
        "elif cluster_mode == \"yarn\":  \n",
        "    init_orca_context(cluster_mode=\"yarn-client\", num_nodes=2, cores=2, driver_memory=\"6g\") # run on Hadoop YARN cluster"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing orca context\n",
            "Current pyspark location is : /usr/local/lib/python3.7/dist-packages/pyspark/__init__.py\n",
            "Start to getOrCreate SparkContext\n",
            "pyspark_submit_args is:  --driver-class-path /usr/local/lib/python3.7/dist-packages/bigdl/share/core/lib/all-2.1.0-20220314.094552-2.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/dllib/lib/bigdl-dllib-spark_3.1.2-2.1.0-SNAPSHOT-jar-with-dependencies.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/orca/lib/bigdl-orca-spark_3.1.2-2.1.0-SNAPSHOT-jar-with-dependencies.jar pyspark-shell \n",
            "Successfully got a SparkContext\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO2x4TI4ZRnq"
      },
      "source": [
        "## **Data Preprocessing with Spark Dataframes**\n",
        "\n",
        "Orca supports Spark Dataframes as the input to the distributed training, and as the input/output of the distributed inference. Consequently, the user can easily process large-scale dataset using Apache Spark, and directly apply AI models on the distributed (and possibly in-memory) Dataframes without data conversion or serialization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xyxitSDZP8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4deba90c-fc2f-4829-d991-1267fe62738e"
      },
      "source": [
        "# Download and extract movielens 1M data.\n",
        "url = 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
        "local_file = base.maybe_download('ml-1m.zip', '.', url)\n",
        "if not os.path.exists('./ml-1m'):\n",
        "        zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "        zip_ref.extractall('.')\n",
        "        zip_ref.close()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "5840896/5917549 [============================>.] - ETA: 0sSuccessfully downloaded ml-1m.zip 5917549 bytes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BVhLa-ebFTe",
        "outputId": "25879c80-e93f-4774-d014-1f8e2c7b2b35"
      },
      "source": [
        "# read csv\n",
        "rating_files=\"./ml-1m/ratings.dat\"\n",
        "spark = OrcaContext.get_spark_session()\n",
        "df = spark.read.csv(rating_files, sep='::', header=True, inferSchema=True).toDF(\"user\", \"item\", \"label\", \"timestamp\")\n",
        "\n",
        "df.show(5)\n",
        "\n",
        "user_set = df.select('user').collect()\n",
        "item_set = df.select('item').collect()\n",
        "\n",
        "min_user_id = min(user_set)[0]\n",
        "max_user_id = max(user_set)[0]\n",
        "min_item_id = min(item_set)[0]\n",
        "max_item_id = max(item_set)[0]\n",
        "print(min_user_id, max_user_id, min_item_id, max_item_id)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+-----+---------+\n",
            "|user|item|label|timestamp|\n",
            "+----+----+-----+---------+\n",
            "|   1| 661|    3|978302109|\n",
            "|   1| 914|    3|978301968|\n",
            "|   1|3408|    4|978300275|\n",
            "|   1|2355|    5|978824291|\n",
            "|   1|1197|    3|978302268|\n",
            "+----+----+-----+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "1 6040 1 3952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFLTccOlbTaa"
      },
      "source": [
        "# update label starting from 0\n",
        "df = df.withColumn('label', df.label-1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXym4BodbzwS"
      },
      "source": [
        "# split to train/test dataset\n",
        "train_data, test_data = df.randomSplit([0.8, 0.2], 100)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEgxpdYcb7oC"
      },
      "source": [
        "### **Define NCF Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnPGNXK0b8ot"
      },
      "source": [
        "def model_creator(config):\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    embedding_size=16\n",
        "    user = keras.layers.Input(dtype=tf.int32, shape=(None,))\n",
        "    item = keras.layers.Input(dtype=tf.int32, shape=(None,))\n",
        "    label = keras.layers.Input(dtype=tf.int32, shape=(None,))\n",
        "\n",
        "    with tf.name_scope(\"GMF\"):\n",
        "        user_embed_GMF = keras.layers.Embedding(max_user_id + 1, embedding_size)(user)\n",
        "        item_embed_GMF = keras.layers.Embedding(max_item_id + 1, embedding_size)(item)\n",
        "        GMF = keras.layers.Multiply()([user_embed_GMF, item_embed_GMF])\n",
        "\n",
        "    with tf.name_scope(\"MLP\"):\n",
        "        user_embed_MLP = keras.layers.Embedding(max_user_id + 1, embedding_size)(user)\n",
        "        item_embed_MLP = keras.layers.Embedding(max_item_id + 1, embedding_size)(item)\n",
        "        interaction = tf.concat([user_embed_MLP, item_embed_MLP], axis=-1)\n",
        "        layer1_MLP = keras.layers.Dense(units=embedding_size * 2, activation='relu')(interaction)\n",
        "        layer1_MLP = keras.layers.Dropout(rate=0.2)(layer1_MLP)\n",
        "        layer2_MLP = keras.layers.Dense(units=embedding_size, activation='relu')(layer1_MLP)\n",
        "        layer2_MLP = keras.layers.Dropout(rate=0.2)(layer2_MLP)\n",
        "        layer3_MLP = keras.layers.Dense(units=embedding_size // 2, activation='relu')(layer2_MLP)\n",
        "        layer3_MLP = keras.layers.Dropout(rate=0.2)(layer3_MLP)\n",
        "\n",
        "    # Concate the two parts together\n",
        "    with tf.name_scope(\"concatenation\"):\n",
        "        concatenation = tf.concat([GMF, layer3_MLP], axis=-1)\n",
        "        outputs = keras.layers.Dense(units=5, activation='softmax')(concatenation)\n",
        "    \n",
        "    model = keras.Model(inputs=[user, item], outputs=outputs)\n",
        "    model.compile(optimizer= \"adam\",\n",
        "                  loss= \"sparse_categorical_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1srWZc5DcHMG"
      },
      "source": [
        "### **Fit with Orca Estimator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqTuXJbYcRj6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fe7e2cdf-3d25-4829-dc36-c820d1f0ff23"
      },
      "source": [
        "batch_size=1280\n",
        "epochs=2\n",
        "model_dir='./'\n",
        "\n",
        "# create an Estimator\n",
        "est = Estimator.from_keras(model_creator=model_creator, workers_per_node=1)\n",
        "\n",
        "stats = est.fit(train_data,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                feature_cols=['user', 'item'],\n",
        "                label_cols=['label'],\n",
        "                steps_per_epoch=800000 // batch_size,\n",
        "                validation_data=test_data,\n",
        "                validation_steps = 200000 // batch_size)\n",
        "\n",
        "checkpoint_path = os.path.join(model_dir, \"NCF.ckpt\")\n",
        "est.save(checkpoint_path)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'node_ip_address': '172.28.0.2', 'raylet_ip_address': '172.28.0.2', 'redis_address': '172.28.0.2:6379', 'object_store_address': '/tmp/ray/session_2022-07-25_14-20-49_649104_58/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-07-25_14-20-49_649104_58/sockets/raylet', 'webui_url': None, 'session_dir': '/tmp/ray/session_2022-07-25_14-20-49_649104_58', 'metrics_export_port': 62123, 'node_id': 'c1d5c21b793dd02bcd3fb6aecb8d969943fe1fa9148a6e78b83feea3'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bigdl/orca/learn/tf2/tf_runner.py:317: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m use distribute.MultiWorkerMirroredStrategy instead\n",
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m 2022-07-25 14:21:00.811115: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-07-25 14:22:14,966\tWARNING worker.py:1245 -- (ip=172.28.0.2) The agent on node df74814a9ab3 failed to be restarted 5 times. There are 3 possible problems if you see this error.\n",
            "  1. The dashboard might not display correct information on this node.\n",
            "  2. Metrics on this node won't be reported.\n",
            "  3. runtime_env APIs won't work.\n",
            "Check out the `dashboard_agent.log` to see the detailed failure messages.\n",
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bigdl/orca/learn/tf2/tf_runner.py:195: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m rename to distribute_datasets_from_function\n",
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m 2022-07-25 14:22:28.765698: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.int32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None,).\n",
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.int32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None,).\n",
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.int32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None,).\n",
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.int32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None,).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m \r  1/625 [..............................] - ETA: 30:38 - loss: 1.6093 - accuracy: 0.2156\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  3/625 [..............................] - ETA: 17s - loss: 1.6083 - accuracy: 0.2529  \n",
            "  8/625 [..............................] - ETA: 16s - loss: 1.6058 - accuracy: 0.2813\n",
            " 11/625 [..............................] - ETA: 14s - loss: 1.6042 - accuracy: 0.2900\n",
            " 16/625 [..............................] - ETA: 14s - loss: 1.6017 - accuracy: 0.2979\n",
            " 22/625 [>.............................] - ETA: 13s - loss: 1.5985 - accuracy: 0.3034\n",
            " 25/625 [>.............................] - ETA: 13s - loss: 1.5969 - accuracy: 0.3070\n",
            " 28/625 [>.............................] - ETA: 13s - loss: 1.5949 - accuracy: 0.3107\n",
            " 31/625 [>.............................] - ETA: 13s - loss: 1.5929 - accuracy: 0.3125\n",
            " 36/625 [>.............................] - ETA: 13s - loss: 1.5889 - accuracy: 0.3151\n",
            " 39/625 [>.............................] - ETA: 13s - loss: 1.5865 - accuracy: 0.3163\n",
            " 44/625 [=>............................] - ETA: 13s - loss: 1.5825 - accuracy: 0.3186\n",
            " 49/625 [=>............................] - ETA: 13s - loss: 1.5788 - accuracy: 0.3191\n",
            " 54/625 [=>............................] - ETA: 13s - loss: 1.5747 - accuracy: 0.3187\n",
            " 57/625 [=>............................] - ETA: 13s - loss: 1.5723 - accuracy: 0.3191\n",
            " 62/625 [=>............................] - ETA: 12s - loss: 1.5681 - accuracy: 0.3199\n",
            " 68/625 [==>...........................] - ETA: 12s - loss: 1.5640 - accuracy: 0.3205\n",
            " 74/625 [==>...........................] - ETA: 12s - loss: 1.5586 - accuracy: 0.3223\n",
            " 78/625 [==>...........................] - ETA: 12s - loss: 1.5551 - accuracy: 0.3228\n",
            " 80/625 [==>...........................] - ETA: 12s - loss: 1.5534 - accuracy: 0.3232\n",
            " 85/625 [===>..........................] - ETA: 12s - loss: 1.5483 - accuracy: 0.3245\n",
            " 88/625 [===>..........................] - ETA: 12s - loss: 1.5454 - accuracy: 0.3251\n",
            " 93/625 [===>..........................] - ETA: 12s - loss: 1.5411 - accuracy: 0.3257\n",
            " 98/625 [===>..........................] - ETA: 12s - loss: 1.5371 - accuracy: 0.3262\n",
            "101/625 [===>..........................] - ETA: 12s - loss: 1.5351 - accuracy: 0.3266\n",
            "105/625 [====>.........................] - ETA: 12s - loss: 1.5319 - accuracy: 0.3272\n",
            "110/625 [====>.........................] - ETA: 12s - loss: 1.5293 - accuracy: 0.3270\n",
            "113/625 [====>.........................] - ETA: 12s - loss: 1.5281 - accuracy: 0.3267\n",
            "118/625 [====>.........................] - ETA: 11s - loss: 1.5250 - accuracy: 0.3266\n",
            "121/625 [====>.........................] - ETA: 11s - loss: 1.5229 - accuracy: 0.3269\n",
            "127/625 [=====>........................] - ETA: 11s - loss: 1.5180 - accuracy: 0.3281\n",
            "131/625 [=====>........................] - ETA: 11s - loss: 1.5154 - accuracy: 0.3287\n",
            "136/625 [=====>........................] - ETA: 11s - loss: 1.5122 - accuracy: 0.3293\n",
            "142/625 [=====>........................] - ETA: 11s - loss: 1.5092 - accuracy: 0.3294\n",
            "145/625 [=====>........................] - ETA: 11s - loss: 1.5076 - accuracy: 0.3296\n",
            "151/625 [======>.......................] - ETA: 11s - loss: 1.5045 - accuracy: 0.3301\n",
            "154/625 [======>.......................] - ETA: 10s - loss: 1.5026 - accuracy: 0.3305\n",
            "160/625 [======>.......................] - ETA: 10s - loss: 1.4990 - accuracy: 0.3315\n",
            "166/625 [======>.......................] - ETA: 10s - loss: 1.4965 - accuracy: 0.3317\n",
            "169/625 [=======>......................] - ETA: 10s - loss: 1.4945 - accuracy: 0.3324\n",
            "175/625 [=======>......................] - ETA: 10s - loss: 1.4908 - accuracy: 0.3332\n",
            "178/625 [=======>......................] - ETA: 10s - loss: 1.4895 - accuracy: 0.3335\n",
            "183/625 [=======>......................] - ETA: 10s - loss: 1.4868 - accuracy: 0.3340\n",
            "188/625 [========>.....................] - ETA: 10s - loss: 1.4838 - accuracy: 0.3348\n",
            "190/625 [========>.....................] - ETA: 10s - loss: 1.4824 - accuracy: 0.3352\n",
            "195/625 [========>.....................] - ETA: 10s - loss: 1.4793 - accuracy: 0.3362\n",
            "197/625 [========>.....................] - ETA: 10s - loss: 1.4782 - accuracy: 0.3365\n",
            "199/625 [========>.....................] - ETA: 10s - loss: 1.4771 - accuracy: 0.3370\n",
            "203/625 [========>.....................] - ETA: 10s - loss: 1.4752 - accuracy: 0.3376\n",
            "208/625 [========>.....................] - ETA: 9s - loss: 1.4727 - accuracy: 0.3385 \n",
            "210/625 [=========>....................] - ETA: 9s - loss: 1.4717 - accuracy: 0.3387\n",
            "213/625 [=========>....................] - ETA: 9s - loss: 1.4703 - accuracy: 0.3392\n",
            "216/625 [=========>....................] - ETA: 9s - loss: 1.4689 - accuracy: 0.3398\n",
            "218/625 [=========>....................] - ETA: 9s - loss: 1.4681 - accuracy: 0.3402\n",
            "222/625 [=========>....................] - ETA: 9s - loss: 1.4666 - accuracy: 0.3407\n",
            "224/625 [=========>....................] - ETA: 9s - loss: 1.4659 - accuracy: 0.3408\n",
            "229/625 [=========>....................] - ETA: 9s - loss: 1.4643 - accuracy: 0.3413\n",
            "232/625 [==========>...................] - ETA: 9s - loss: 1.4630 - accuracy: 0.3417\n",
            "238/625 [==========>...................] - ETA: 9s - loss: 1.4598 - accuracy: 0.3430\n",
            "241/625 [==========>...................] - ETA: 9s - loss: 1.4584 - accuracy: 0.3435\n",
            "246/625 [==========>...................] - ETA: 9s - loss: 1.4557 - accuracy: 0.3447\n",
            "249/625 [==========>...................] - ETA: 9s - loss: 1.4541 - accuracy: 0.3454\n",
            "252/625 [===========>..................] - ETA: 9s - loss: 1.4528 - accuracy: 0.3459\n",
            "255/625 [===========>..................] - ETA: 9s - loss: 1.4515 - accuracy: 0.3465\n",
            "258/625 [===========>..................] - ETA: 8s - loss: 1.4501 - accuracy: 0.3471\n",
            "261/625 [===========>..................] - ETA: 8s - loss: 1.4487 - accuracy: 0.3477\n",
            "264/625 [===========>..................] - ETA: 8s - loss: 1.4475 - accuracy: 0.3481\n",
            "266/625 [===========>..................] - ETA: 8s - loss: 1.4466 - accuracy: 0.3484\n",
            "269/625 [===========>..................] - ETA: 8s - loss: 1.4454 - accuracy: 0.3487\n",
            "275/625 [============>.................] - ETA: 8s - loss: 1.4429 - accuracy: 0.3499\n",
            "281/625 [============>.................] - ETA: 8s - loss: 1.4408 - accuracy: 0.3508\n",
            "284/625 [============>.................] - ETA: 8s - loss: 1.4398 - accuracy: 0.3512\n",
            "290/625 [============>.................] - ETA: 8s - loss: 1.4379 - accuracy: 0.3521\n",
            "293/625 [=============>................] - ETA: 7s - loss: 1.4370 - accuracy: 0.3525\n",
            "299/625 [=============>................] - ETA: 7s - loss: 1.4347 - accuracy: 0.3535\n",
            "305/625 [=============>................] - ETA: 7s - loss: 1.4327 - accuracy: 0.3544\n",
            "308/625 [=============>................] - ETA: 7s - loss: 1.4315 - accuracy: 0.3550\n",
            "313/625 [==============>...............] - ETA: 7s - loss: 1.4297 - accuracy: 0.3558\n",
            "318/625 [==============>...............] - ETA: 7s - loss: 1.4282 - accuracy: 0.3563\n",
            "321/625 [==============>...............] - ETA: 7s - loss: 1.4273 - accuracy: 0.3566\n",
            "324/625 [==============>...............] - ETA: 7s - loss: 1.4264 - accuracy: 0.3570\n",
            "330/625 [==============>...............] - ETA: 7s - loss: 1.4246 - accuracy: 0.3577\n",
            "336/625 [===============>..............] - ETA: 6s - loss: 1.4230 - accuracy: 0.3582\n",
            "339/625 [===============>..............] - ETA: 6s - loss: 1.4222 - accuracy: 0.3586\n",
            "345/625 [===============>..............] - ETA: 6s - loss: 1.4203 - accuracy: 0.3595\n",
            "348/625 [===============>..............] - ETA: 6s - loss: 1.4196 - accuracy: 0.3599\n",
            "353/625 [===============>..............] - ETA: 6s - loss: 1.4185 - accuracy: 0.3604\n",
            "356/625 [================>.............] - ETA: 6s - loss: 1.4177 - accuracy: 0.3607\n",
            "359/625 [================>.............] - ETA: 6s - loss: 1.4171 - accuracy: 0.3610\n",
            "362/625 [================>.............] - ETA: 6s - loss: 1.4167 - accuracy: 0.3612\n",
            "368/625 [================>.............] - ETA: 6s - loss: 1.4155 - accuracy: 0.3618\n",
            "371/625 [================>.............] - ETA: 6s - loss: 1.4149 - accuracy: 0.3623\n",
            "377/625 [=================>............] - ETA: 5s - loss: 1.4134 - accuracy: 0.3630\n",
            "380/625 [=================>............] - ETA: 5s - loss: 1.4126 - accuracy: 0.3633\n",
            "386/625 [=================>............] - ETA: 5s - loss: 1.4112 - accuracy: 0.3639\n",
            "388/625 [=================>............] - ETA: 5s - loss: 1.4109 - accuracy: 0.3641\n",
            "394/625 [=================>............] - ETA: 5s - loss: 1.4099 - accuracy: 0.3645\n",
            "396/625 [==================>...........] - ETA: 5s - loss: 1.4097 - accuracy: 0.3646\n",
            "401/625 [==================>...........] - ETA: 5s - loss: 1.4087 - accuracy: 0.3650\n",
            "407/625 [==================>...........] - ETA: 5s - loss: 1.4076 - accuracy: 0.3655\n",
            "411/625 [==================>...........] - ETA: 5s - loss: 1.4072 - accuracy: 0.3657\n",
            "416/625 [==================>...........] - ETA: 4s - loss: 1.4065 - accuracy: 0.3660\n",
            "419/625 [===================>..........] - ETA: 4s - loss: 1.4059 - accuracy: 0.3663\n",
            "425/625 [===================>..........] - ETA: 4s - loss: 1.4047 - accuracy: 0.3670\n",
            "427/625 [===================>..........] - ETA: 4s - loss: 1.4042 - accuracy: 0.3672\n",
            "433/625 [===================>..........] - ETA: 4s - loss: 1.4029 - accuracy: 0.3679\n",
            "436/625 [===================>..........] - ETA: 4s - loss: 1.4022 - accuracy: 0.3683\n",
            "442/625 [====================>.........] - ETA: 4s - loss: 1.4010 - accuracy: 0.3689\n",
            "448/625 [====================>.........] - ETA: 4s - loss: 1.3998 - accuracy: 0.3694\n",
            "451/625 [====================>.........] - ETA: 4s - loss: 1.3994 - accuracy: 0.3696\n",
            "456/625 [====================>.........] - ETA: 3s - loss: 1.3983 - accuracy: 0.3701\n",
            "460/625 [=====================>........] - ETA: 3s - loss: 1.3976 - accuracy: 0.3703\n",
            "462/625 [=====================>........] - ETA: 3s - loss: 1.3972 - accuracy: 0.3705\n",
            "468/625 [=====================>........] - ETA: 3s - loss: 1.3960 - accuracy: 0.3710\n",
            "474/625 [=====================>........] - ETA: 3s - loss: 1.3950 - accuracy: 0.3715\n",
            "477/625 [=====================>........] - ETA: 3s - loss: 1.3945 - accuracy: 0.3718\n",
            "480/625 [======================>.......] - ETA: 3s - loss: 1.3941 - accuracy: 0.3720\n",
            "483/625 [======================>.......] - ETA: 3s - loss: 1.3938 - accuracy: 0.3721\n",
            "489/625 [======================>.......] - ETA: 3s - loss: 1.3927 - accuracy: 0.3726\n",
            "492/625 [======================>.......] - ETA: 3s - loss: 1.3920 - accuracy: 0.3729\n",
            "497/625 [======================>.......] - ETA: 3s - loss: 1.3910 - accuracy: 0.3733\n",
            "500/625 [=======================>......] - ETA: 2s - loss: 1.3904 - accuracy: 0.3736\n",
            "506/625 [=======================>......] - ETA: 2s - loss: 1.3893 - accuracy: 0.3741\n",
            "512/625 [=======================>......] - ETA: 2s - loss: 1.3882 - accuracy: 0.3746\n",
            "515/625 [=======================>......] - ETA: 2s - loss: 1.3877 - accuracy: 0.3749\n",
            "521/625 [========================>.....] - ETA: 2s - loss: 1.3869 - accuracy: 0.3752\n",
            "527/625 [========================>.....] - ETA: 2s - loss: 1.3861 - accuracy: 0.3755\n",
            "531/625 [========================>.....] - ETA: 2s - loss: 1.3856 - accuracy: 0.3757\n",
            "534/625 [========================>.....] - ETA: 2s - loss: 1.3852 - accuracy: 0.3759\n",
            "540/625 [========================>.....] - ETA: 1s - loss: 1.3845 - accuracy: 0.3760\n",
            "545/625 [=========================>....] - ETA: 1s - loss: 1.3839 - accuracy: 0.3763\n",
            "550/625 [=========================>....] - ETA: 1s - loss: 1.3833 - accuracy: 0.3766\n",
            "553/625 [=========================>....] - ETA: 1s - loss: 1.3829 - accuracy: 0.3768\n",
            "555/625 [=========================>....] - ETA: 1s - loss: 1.3826 - accuracy: 0.3769\n",
            "559/625 [=========================>....] - ETA: 1s - loss: 1.3820 - accuracy: 0.3772\n",
            "563/625 [==========================>...] - ETA: 1s - loss: 1.3814 - accuracy: 0.3775\n",
            "565/625 [==========================>...] - ETA: 1s - loss: 1.3811 - accuracy: 0.3776\n",
            "569/625 [==========================>...] - ETA: 1s - loss: 1.3806 - accuracy: 0.3778\n",
            "572/625 [==========================>...] - ETA: 1s - loss: 1.3803 - accuracy: 0.3779\n",
            "578/625 [==========================>...] - ETA: 1s - loss: 1.3799 - accuracy: 0.3780\n",
            "584/625 [===========================>..] - ETA: 0s - loss: 1.3795 - accuracy: 0.3782\n",
            "590/625 [===========================>..] - ETA: 0s - loss: 1.3788 - accuracy: 0.3785\n",
            "593/625 [===========================>..] - ETA: 0s - loss: 1.3785 - accuracy: 0.3787\n",
            "599/625 [===========================>..] - ETA: 0s - loss: 1.3778 - accuracy: 0.3790\n",
            "605/625 [============================>.] - ETA: 0s - loss: 1.3773 - accuracy: 0.3793\n",
            "608/625 [============================>.] - ETA: 0s - loss: 1.3769 - accuracy: 0.3795\n",
            "614/625 [============================>.] - ETA: 0s - loss: 1.3764 - accuracy: 0.3797\n",
            "620/625 [============================>.] - ETA: 0s - loss: 1.3758 - accuracy: 0.3800\n",
            "623/625 [============================>.] - ETA: 0s - loss: 1.3754 - accuracy: 0.3802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.int32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None,).\n",
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.int32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None,).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r625/625 [==============================] - 21s 29ms/step - loss: 1.3752 - accuracy: 0.3803 - val_loss: 1.2591 - val_accuracy: 0.4365\n",
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m Epoch 2/2\n",
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m \r  1/625 [..............................] - ETA: 8s - loss: 1.2943 - accuracy: 0.3992\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  4/625 [..............................] - ETA: 10s - loss: 1.3038 - accuracy: 0.4145\n",
            "  7/625 [..............................] - ETA: 12s - loss: 1.3046 - accuracy: 0.4190\n",
            " 13/625 [..............................] - ETA: 12s - loss: 1.3055 - accuracy: 0.4180\n",
            " 18/625 [..............................] - ETA: 13s - loss: 1.3032 - accuracy: 0.4137\n",
            " 21/625 [>.............................] - ETA: 13s - loss: 1.3028 - accuracy: 0.4116\n",
            " 27/625 [>.............................] - ETA: 12s - loss: 1.3010 - accuracy: 0.4143\n",
            " 31/625 [>.............................] - ETA: 13s - loss: 1.2980 - accuracy: 0.4158\n",
            " 35/625 [>.............................] - ETA: 13s - loss: 1.2944 - accuracy: 0.4189\n",
            " 40/625 [>.............................] - ETA: 13s - loss: 1.2916 - accuracy: 0.4205\n",
            " 43/625 [=>............................] - ETA: 13s - loss: 1.2914 - accuracy: 0.4209\n",
            " 48/625 [=>............................] - ETA: 13s - loss: 1.2907 - accuracy: 0.4209\n",
            " 53/625 [=>............................] - ETA: 13s - loss: 1.2881 - accuracy: 0.4221\n",
            " 57/625 [=>............................] - ETA: 13s - loss: 1.2881 - accuracy: 0.4218\n",
            " 60/625 [=>............................] - ETA: 13s - loss: 1.2879 - accuracy: 0.4218\n",
            " 64/625 [==>...........................] - ETA: 13s - loss: 1.2866 - accuracy: 0.4224\n",
            " 68/625 [==>...........................] - ETA: 13s - loss: 1.2875 - accuracy: 0.4220\n",
            " 74/625 [==>...........................] - ETA: 13s - loss: 1.2883 - accuracy: 0.4215\n",
            " 76/625 [==>...........................] - ETA: 13s - loss: 1.2876 - accuracy: 0.4218\n",
            " 78/625 [==>...........................] - ETA: 13s - loss: 1.2876 - accuracy: 0.4222\n",
            " 81/625 [==>...........................] - ETA: 12s - loss: 1.2875 - accuracy: 0.4222\n",
            " 87/625 [===>..........................] - ETA: 12s - loss: 1.2863 - accuracy: 0.4221\n",
            " 92/625 [===>..........................] - ETA: 12s - loss: 1.2851 - accuracy: 0.4230\n",
            " 98/625 [===>..........................] - ETA: 12s - loss: 1.2852 - accuracy: 0.4227\n",
            "101/625 [===>..........................] - ETA: 12s - loss: 1.2851 - accuracy: 0.4225\n",
            "107/625 [====>.........................] - ETA: 11s - loss: 1.2844 - accuracy: 0.4232\n",
            "113/625 [====>.........................] - ETA: 11s - loss: 1.2850 - accuracy: 0.4227\n",
            "116/625 [====>.........................] - ETA: 11s - loss: 1.2848 - accuracy: 0.4226\n",
            "122/625 [====>.........................] - ETA: 11s - loss: 1.2843 - accuracy: 0.4228\n",
            "124/625 [====>.........................] - ETA: 11s - loss: 1.2837 - accuracy: 0.4228\n",
            "130/625 [=====>........................] - ETA: 11s - loss: 1.2824 - accuracy: 0.4229\n",
            "135/625 [=====>........................] - ETA: 11s - loss: 1.2826 - accuracy: 0.4229\n",
            "140/625 [=====>........................] - ETA: 11s - loss: 1.2823 - accuracy: 0.4229\n",
            "142/625 [=====>........................] - ETA: 11s - loss: 1.2819 - accuracy: 0.4232\n",
            "149/625 [======>.......................] - ETA: 10s - loss: 1.2813 - accuracy: 0.4231\n",
            "156/625 [======>.......................] - ETA: 10s - loss: 1.2808 - accuracy: 0.4234\n",
            "159/625 [======>.......................] - ETA: 10s - loss: 1.2805 - accuracy: 0.4235\n",
            "165/625 [======>.......................] - ETA: 10s - loss: 1.2801 - accuracy: 0.4236\n",
            "168/625 [=======>......................] - ETA: 10s - loss: 1.2802 - accuracy: 0.4236\n",
            "173/625 [=======>......................] - ETA: 10s - loss: 1.2799 - accuracy: 0.4238\n",
            "179/625 [=======>......................] - ETA: 10s - loss: 1.2791 - accuracy: 0.4240\n",
            "182/625 [=======>......................] - ETA: 9s - loss: 1.2788 - accuracy: 0.4242 \n",
            "188/625 [========>.....................] - ETA: 9s - loss: 1.2784 - accuracy: 0.4245\n",
            "191/625 [========>.....................] - ETA: 9s - loss: 1.2775 - accuracy: 0.4248\n",
            "194/625 [========>.....................] - ETA: 9s - loss: 1.2769 - accuracy: 0.4251\n",
            "197/625 [========>.....................] - ETA: 9s - loss: 1.2765 - accuracy: 0.4253\n",
            "203/625 [========>.....................] - ETA: 9s - loss: 1.2760 - accuracy: 0.4254\n",
            "209/625 [=========>....................] - ETA: 9s - loss: 1.2755 - accuracy: 0.4255\n",
            "212/625 [=========>....................] - ETA: 9s - loss: 1.2756 - accuracy: 0.4254\n",
            "218/625 [=========>....................] - ETA: 9s - loss: 1.2755 - accuracy: 0.4258\n",
            "221/625 [=========>....................] - ETA: 9s - loss: 1.2754 - accuracy: 0.4258\n",
            "227/625 [=========>....................] - ETA: 8s - loss: 1.2753 - accuracy: 0.4260\n",
            "232/625 [==========>...................] - ETA: 8s - loss: 1.2754 - accuracy: 0.4260\n",
            "235/625 [==========>...................] - ETA: 8s - loss: 1.2752 - accuracy: 0.4261\n",
            "240/625 [==========>...................] - ETA: 8s - loss: 1.2746 - accuracy: 0.4264\n",
            "245/625 [==========>...................] - ETA: 8s - loss: 1.2739 - accuracy: 0.4267\n",
            "247/625 [==========>...................] - ETA: 8s - loss: 1.2736 - accuracy: 0.4269\n",
            "253/625 [===========>..................] - ETA: 8s - loss: 1.2733 - accuracy: 0.4270\n",
            "255/625 [===========>..................] - ETA: 8s - loss: 1.2730 - accuracy: 0.4272\n",
            "259/625 [===========>..................] - ETA: 8s - loss: 1.2728 - accuracy: 0.4272\n",
            "264/625 [===========>..................] - ETA: 8s - loss: 1.2723 - accuracy: 0.4274\n",
            "268/625 [===========>..................] - ETA: 8s - loss: 1.2719 - accuracy: 0.4278\n",
            "273/625 [============>.................] - ETA: 7s - loss: 1.2716 - accuracy: 0.4279\n",
            "279/625 [============>.................] - ETA: 7s - loss: 1.2710 - accuracy: 0.4282\n",
            "282/625 [============>.................] - ETA: 7s - loss: 1.2709 - accuracy: 0.4282\n",
            "288/625 [============>.................] - ETA: 7s - loss: 1.2708 - accuracy: 0.4283\n",
            "294/625 [=============>................] - ETA: 7s - loss: 1.2707 - accuracy: 0.4281\n",
            "296/625 [=============>................] - ETA: 7s - loss: 1.2706 - accuracy: 0.4281\n",
            "302/625 [=============>................] - ETA: 7s - loss: 1.2701 - accuracy: 0.4285\n",
            "305/625 [=============>................] - ETA: 7s - loss: 1.2699 - accuracy: 0.4286\n",
            "310/625 [=============>................] - ETA: 7s - loss: 1.2694 - accuracy: 0.4288\n",
            "316/625 [==============>...............] - ETA: 6s - loss: 1.2692 - accuracy: 0.4289\n",
            "319/625 [==============>...............] - ETA: 6s - loss: 1.2689 - accuracy: 0.4291\n",
            "322/625 [==============>...............] - ETA: 6s - loss: 1.2688 - accuracy: 0.4292\n",
            "325/625 [==============>...............] - ETA: 6s - loss: 1.2684 - accuracy: 0.4294\n",
            "328/625 [==============>...............] - ETA: 6s - loss: 1.2683 - accuracy: 0.4295\n",
            "334/625 [===============>..............] - ETA: 6s - loss: 1.2681 - accuracy: 0.4294\n",
            "339/625 [===============>..............] - ETA: 6s - loss: 1.2679 - accuracy: 0.4294\n",
            "342/625 [===============>..............] - ETA: 6s - loss: 1.2679 - accuracy: 0.4295\n",
            "347/625 [===============>..............] - ETA: 6s - loss: 1.2677 - accuracy: 0.4297\n",
            "352/625 [===============>..............] - ETA: 6s - loss: 1.2676 - accuracy: 0.4297\n",
            "357/625 [================>.............] - ETA: 6s - loss: 1.2675 - accuracy: 0.4296\n",
            "359/625 [================>.............] - ETA: 6s - loss: 1.2675 - accuracy: 0.4296\n",
            "365/625 [================>.............] - ETA: 5s - loss: 1.2676 - accuracy: 0.4297\n",
            "370/625 [================>.............] - ETA: 5s - loss: 1.2675 - accuracy: 0.4300\n",
            "373/625 [================>.............] - ETA: 5s - loss: 1.2674 - accuracy: 0.4300\n",
            "375/625 [=================>............] - ETA: 5s - loss: 1.2672 - accuracy: 0.4301\n",
            "378/625 [=================>............] - ETA: 5s - loss: 1.2671 - accuracy: 0.4302\n",
            "380/625 [=================>............] - ETA: 5s - loss: 1.2668 - accuracy: 0.4304\n",
            "384/625 [=================>............] - ETA: 5s - loss: 1.2666 - accuracy: 0.4305\n",
            "388/625 [=================>............] - ETA: 5s - loss: 1.2665 - accuracy: 0.4306\n",
            "392/625 [=================>............] - ETA: 5s - loss: 1.2665 - accuracy: 0.4307\n",
            "398/625 [==================>...........] - ETA: 5s - loss: 1.2662 - accuracy: 0.4307\n",
            "401/625 [==================>...........] - ETA: 5s - loss: 1.2661 - accuracy: 0.4307\n",
            "407/625 [==================>...........] - ETA: 5s - loss: 1.2661 - accuracy: 0.4308\n",
            "413/625 [==================>...........] - ETA: 4s - loss: 1.2666 - accuracy: 0.4307\n",
            "418/625 [===================>..........] - ETA: 4s - loss: 1.2667 - accuracy: 0.4307\n",
            "421/625 [===================>..........] - ETA: 4s - loss: 1.2666 - accuracy: 0.4308\n",
            "427/625 [===================>..........] - ETA: 4s - loss: 1.2665 - accuracy: 0.4309\n",
            "431/625 [===================>..........] - ETA: 4s - loss: 1.2663 - accuracy: 0.4311\n",
            "433/625 [===================>..........] - ETA: 4s - loss: 1.2662 - accuracy: 0.4312\n",
            "438/625 [====================>.........] - ETA: 4s - loss: 1.2658 - accuracy: 0.4313\n",
            "440/625 [====================>.........] - ETA: 4s - loss: 1.2656 - accuracy: 0.4314\n",
            "446/625 [====================>.........] - ETA: 4s - loss: 1.2653 - accuracy: 0.4316\n",
            "452/625 [====================>.........] - ETA: 3s - loss: 1.2650 - accuracy: 0.4318\n",
            "455/625 [====================>.........] - ETA: 3s - loss: 1.2649 - accuracy: 0.4319\n",
            "461/625 [=====================>........] - ETA: 3s - loss: 1.2646 - accuracy: 0.4320\n",
            "464/625 [=====================>........] - ETA: 3s - loss: 1.2643 - accuracy: 0.4320\n",
            "471/625 [=====================>........] - ETA: 3s - loss: 1.2640 - accuracy: 0.4322\n",
            "477/625 [=====================>........] - ETA: 3s - loss: 1.2637 - accuracy: 0.4324\n",
            "480/625 [======================>.......] - ETA: 3s - loss: 1.2637 - accuracy: 0.4324\n",
            "485/625 [======================>.......] - ETA: 3s - loss: 1.2639 - accuracy: 0.4324\n",
            "487/625 [======================>.......] - ETA: 3s - loss: 1.2637 - accuracy: 0.4325\n",
            "492/625 [======================>.......] - ETA: 3s - loss: 1.2632 - accuracy: 0.4327\n",
            "494/625 [======================>.......] - ETA: 3s - loss: 1.2631 - accuracy: 0.4327\n",
            "498/625 [======================>.......] - ETA: 2s - loss: 1.2628 - accuracy: 0.4329\n",
            "503/625 [=======================>......] - ETA: 2s - loss: 1.2622 - accuracy: 0.4332\n",
            "505/625 [=======================>......] - ETA: 2s - loss: 1.2621 - accuracy: 0.4333\n",
            "510/625 [=======================>......] - ETA: 2s - loss: 1.2618 - accuracy: 0.4334\n",
            "516/625 [=======================>......] - ETA: 2s - loss: 1.2614 - accuracy: 0.4335\n",
            "519/625 [=======================>......] - ETA: 2s - loss: 1.2613 - accuracy: 0.4336\n",
            "525/625 [========================>.....] - ETA: 2s - loss: 1.2611 - accuracy: 0.4337\n",
            "527/625 [========================>.....] - ETA: 2s - loss: 1.2611 - accuracy: 0.4338\n",
            "532/625 [========================>.....] - ETA: 2s - loss: 1.2610 - accuracy: 0.4338\n",
            "537/625 [========================>.....] - ETA: 2s - loss: 1.2610 - accuracy: 0.4338\n",
            "543/625 [=========================>....] - ETA: 1s - loss: 1.2611 - accuracy: 0.4338\n",
            "548/625 [=========================>....] - ETA: 1s - loss: 1.2611 - accuracy: 0.4338\n",
            "551/625 [=========================>....] - ETA: 1s - loss: 1.2610 - accuracy: 0.4339\n",
            "558/625 [=========================>....] - ETA: 1s - loss: 1.2609 - accuracy: 0.4341\n",
            "564/625 [==========================>...] - ETA: 1s - loss: 1.2606 - accuracy: 0.4343\n",
            "567/625 [==========================>...] - ETA: 1s - loss: 1.2606 - accuracy: 0.4343\n",
            "570/625 [==========================>...] - ETA: 1s - loss: 1.2604 - accuracy: 0.4343\n",
            "573/625 [==========================>...] - ETA: 1s - loss: 1.2605 - accuracy: 0.4343\n",
            "577/625 [==========================>...] - ETA: 1s - loss: 1.2606 - accuracy: 0.4342\n",
            "583/625 [==========================>...] - ETA: 0s - loss: 1.2607 - accuracy: 0.4342\n",
            "585/625 [===========================>..] - ETA: 0s - loss: 1.2607 - accuracy: 0.4342\n",
            "591/625 [===========================>..] - ETA: 0s - loss: 1.2606 - accuracy: 0.4344\n",
            "595/625 [===========================>..] - ETA: 0s - loss: 1.2607 - accuracy: 0.4344\n",
            "597/625 [===========================>..] - ETA: 0s - loss: 1.2606 - accuracy: 0.4345\n",
            "603/625 [===========================>..] - ETA: 0s - loss: 1.2606 - accuracy: 0.4345\n",
            "606/625 [============================>.] - ETA: 0s - loss: 1.2605 - accuracy: 0.4345\n",
            "612/625 [============================>.] - ETA: 0s - loss: 1.2604 - accuracy: 0.4347\n",
            "618/625 [============================>.] - ETA: 0s - loss: 1.2604 - accuracy: 0.4347\n",
            "623/625 [============================>.] - ETA: 0s - loss: 1.2603 - accuracy: 0.4348\n",
            "625/625 [==============================] - ETA: 0s - loss: 1.2604 - accuracy: 0.4348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m 2022-07-25 14:23:04.196922: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r625/625 [==============================] - 17s 27ms/step - loss: 1.2604 - accuracy: 0.4348 - val_loss: 1.2232 - val_accuracy: 0.4551\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./NCF.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-ikO_Da3qHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "721e1e6f-adac-4fbf-c5b6-9022d8eac33d"
      },
      "source": [
        "# evaluate with Estimator\n",
        "stats = est.evaluate(test_data, \n",
        "                     feature_cols=['user', 'item'],\n",
        "                     label_cols=['label'],\n",
        "                     num_steps=100000 // batch_size)\n",
        "est.shutdown()\n",
        "print(stats)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m 2022-07-25 14:23:41.507638: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=526)\u001b[0m \r 1/78 [..............................] - ETA: 12s - loss: 1.2612 - accuracy: 0.4375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/78 [===>..........................] - ETA: 0s - loss: 1.2173 - accuracy: 0.4886 \n",
            "36/78 [============>.................] - ETA: 0s - loss: 1.2776 - accuracy: 0.4427\n",
            "60/78 [======================>.......] - ETA: 0s - loss: 1.2258 - accuracy: 0.4630\n",
            "78/78 [==============================] - 1s 4ms/step - loss: 1.2419 - accuracy: 0.4555\n",
            "[{'validation_loss': 1.2419430017471313, 'validation_accuracy': 0.4555288553237915}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeJsTahMgFxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25150735-b1d2-43a6-8777-b6ce6683fe71"
      },
      "source": [
        "stop_orca_context()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopping orca context\n"
          ]
        }
      ]
    }
  ]
}