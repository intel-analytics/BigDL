{"cells":[{"cell_type":"code","source":["from __future__ import print_function\nimport os\nimport argparse\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom bigdl.orca import init_orca_context, stop_orca_context\nfrom bigdl.orca.learn.pytorch import Estimator\nfrom bigdl.orca.learn.metrics import Accuracy\nfrom bigdl.orca.learn.trigger import EveryEpoch\n\n\ndef train_data_creator(config={}, batch_size=4, download=True, data_dir='./data'):\n    transform = transforms.Compose(\n        [transforms.ToTensor(),\n         transforms.Normalize((0.5,), (0.5,))])\n\n    trainset = torchvision.datasets.FashionMNIST(root=data_dir,\n                                                 download=download,\n                                                 train=True,\n                                                 transform=transform)\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                              shuffle=True, num_workers=0)\n    return trainloader\n\n\ndef validation_data_creator(config={}, batch_size=4, download=True, data_dir='./data'):\n    transform = transforms.Compose(\n        [transforms.ToTensor(),\n         transforms.Normalize((0.5,), (0.5,))])\n    testset = torchvision.datasets.FashionMNIST(root=data_dir, train=False,\n                                                download=download, transform=transform)\n    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                             shuffle=False, num_workers=0)\n    return testloader\n\n\n# helper function to show an image\ndef matplotlib_imshow(img, one_channel=False):\n    if one_channel:\n        img = img.mean(dim=0)\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    if one_channel:\n        plt.imshow(npimg, cmap=\"Greys\")\n    else:\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\ndef model_creator(config):\n    model = Net()\n    return model\n\n\ndef optimizer_creator(model, config):\n    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n    return optimizer"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df564046-2b59-413f-8979-223e0ec4b664"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["backend = \"ray\" # ray or spark\nbatch_size = 4\nepochs = 2\ndata_dir = \"./data\"\ndownload = True\nmodel_dir = \"/dbfs/FileStore/model/fashion/\"\nsave_path = model_dir + \"fashion.pth\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"570dc478-c341-4a5d-9cd6-009df245783d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["init_orca_context(cluster_mode=\"spark-submit\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5176faf-983c-4bda-83e1-64aea2653386"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# constant for classes\nclasses = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n\n# plot some random training images\ndataiter = iter(train_data_creator(config={}, batch_size=4,\n                                   download=download, data_dir=data_dir))\nimages, labels = dataiter.next()\n\n# create grid of images\nimg_grid = torchvision.utils.make_grid(images)\n\n# show images\nmatplotlib_imshow(img_grid, one_channel=True)\n\n# training loss\ncriterion = nn.CrossEntropyLoss()\n\nestimator = Estimator.from_torch(model=model_creator,\n                                 optimizer=optimizer_creator,\n                                 loss=criterion,\n                                 metrics=[Accuracy()],\n                                 model_dir=model_dir,\n                                 use_tqdm=True,\n                                 backend=backend)\n\nstats = estimator.fit(train_data_creator, epochs=epochs, batch_size=batch_size)\n\nprint(\"Train stats: {}\".format(stats))\nval_stats = estimator.evaluate(validation_data_creator, batch_size=batch_size)\nprint(\"Validation stats: {}\".format(val_stats))\n    \nprint(\"Saving model to: \", save_path)\nestimator.save(save_path)\n    \n# load with estimator.load(save_path)\n# estimator.load(save_path)\n\nestimator.shutdown()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4169fff2-6586-4a9d-a8ba-a3ee18cbd720"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["stop_orca_context()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d40da09c-aa5a-4841-be28-5e2a719346cf"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pytorch_fashion_mnist","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":4465907000545444}},"nbformat":4,"nbformat_minor":0}
