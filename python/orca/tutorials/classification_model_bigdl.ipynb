{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to prepare for this journey .... import modules is e great idea .... :)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from bigdl.orca import init_orca_context, OrcaContext\n",
    "from bigdl.orca.learn.pytorch import Estimator \n",
    "from bigdl.orca.learn.metrics import Accuracy\n",
    "\n",
    "import bigdl.orca.data\n",
    "import bigdl.orca.data.pandas\n",
    "from bigdl.orca.data import SharedValue\n",
    "from bigdl.orca.data import SparkXShards\n",
    "\n",
    "from bigdl.orca.data.transformer import *\n",
    "\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing orca context\n",
      "Current pyspark location is : /home/yansu/miniconda3/envs/env/lib/python3.7/site-packages/pyspark/__init__.py\n",
      "Start to getOrCreate SparkContext\n",
      "pyspark_submit_args is:  --driver-class-path /home/yansu/Desktop/yxy/BigDL/dist/lib/bigdl-dllib-spark_2.4.6-2.1.0-SNAPSHOT-jar-with-dependencies.jar:/home/yansu/Desktop/yxy/BigDL/dist/lib/bigdl-friesian-spark_2.4.6-2.1.0-SNAPSHOT-jar-with-dependencies.jar:/home/yansu/Desktop/yxy/BigDL/dist/lib/bigdl-orca-spark_2.4.6-2.1.0-SNAPSHOT-jar-with-dependencies.jar pyspark-shell \n",
      "Successfully got a SparkContext\n"
     ]
    }
   ],
   "source": [
    "# cluster_mode can be \"local\", \"k8s\" or \"yarn\"\n",
    "sc = init_orca_context(cluster_mode=\"local\", cores=4, memory=\"10g\", num_nodes=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './train.csv'\n",
    "data_shard = bigdl.orca.data.pandas.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shard = data_shard.deduplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelencode y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_func(df):\n",
    "    df = df.rename(columns={'id':'id0'})\n",
    "    return df\n",
    "data_shard = data_shard.transform_shard(trans_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StringIndexer(inputCol='target')\n",
    "transformed_data_shard = scale.fit_transform(data_shard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_func(df):\n",
    "    df['target'] = df['target']-1\n",
    "    return df\n",
    "transformed_data_shard = transformed_data_shard.transform_shard(trans_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2021\n",
    "def split_train_test(data):\n",
    "    train, test = train_test_split(data, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    return train, test\n",
    "\n",
    "shards_train, shards_val = transformed_data_shard.transform_shard(split_train_test).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "for i in range(50):\n",
    "    feature_list.append('feature_' + str(i))\n",
    "scale = MinMaxScaler(inputCol=feature_list, outputCol=\"x_scaled\")\n",
    "shards_train = scale.fit_transform(shards_train)\n",
    "shards_val = scale.transform(shards_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_func(df):\n",
    "    df['x_scaled'] = df['x_scaled'].apply(lambda x:np.array(x,dtype=np.float32))\n",
    "    df['target'] = df['target'].apply(lambda x:np.long(x))\n",
    "    return df\n",
    "shards_train1 = shards_train.transform_shard(trans_func)\n",
    "shards_val1 = shards_val.transform_shard(trans_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 4\n",
    "NUM_EPOCHS = 100\n",
    "NUM_FEATURES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_block(in_features, out_features, p_drop, *args, **kwargs):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p = p_drop)\n",
    "    )\n",
    "\n",
    "class TPS05ClassificationSeq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TPS05ClassificationSeq, self).__init__()\n",
    "        num_feature = NUM_FEATURES\n",
    "        num_class = 4\n",
    "        self.linear = nn.Sequential(\n",
    "            linear_block(num_feature, 100, 0.3),\n",
    "            linear_block(100, 250, 0.3),\n",
    "            linear_block(250, 128, 0.3),\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(128, num_class)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creator(config):\n",
    "    model = TPS05ClassificationSeq()\n",
    "    return model\n",
    "\n",
    "def optim_creator(model, config):\n",
    "    return optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 13:31:14,720\tINFO services.py:1340 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://10.239.44.149:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node_ip_address': '10.239.44.149', 'raylet_ip_address': '10.239.44.149', 'redis_address': '10.239.44.149:6379', 'object_store_address': '/tmp/ray/session_2022-08-19_13-31-12_406382_1621/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-08-19_13-31-12_406382_1621/sockets/raylet', 'webui_url': '10.239.44.149:8265', 'session_dir': '/tmp/ray/session_2022-08-19_13-31-12_406382_1621', 'metrics_export_port': 44343, 'node_id': 'ae49824ef94e8edfe1c96c79a4323856efbd0b302a7e4e8a6bcddd83'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m User settings:\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_AFFINITY=granularity=fine,compact,1,0\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_BLOCKTIME=0\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_DUPLICATE_LIB_OK=True\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_INIT_AT_FORK=FALSE\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_SETTINGS=1\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_NUM_THREADS=1\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m Effective settings:\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_ABORT_DELAY=0\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_ALIGN_ALLOC=64\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_ALL_THREADPRIVATE=128\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_ATOMIC_MODE=2\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_BLOCKTIME=0\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_CPUINFO_FILE: value is not defined\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_DETERMINISTIC_REDUCTION=false\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_DISP_HAND_THREAD=false\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_DISP_NUM_BUFFERS=7\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_DUPLICATE_LIB_OK=true\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_ENABLE_TASK_THROTTLING=true\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_FORCE_MONOTONIC_DYNAMIC_SCHEDULE=false\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_FORCE_REDUCTION: value is not defined\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_FORKJOIN_BARRIER='2,2'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_FORKJOIN_FRAMES=true\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_FORKJOIN_FRAMES_MODE=3\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_GTID_MODE=3\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_HANDLE_SIGNALS=false\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_HOT_TEAMS_MODE=0\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_INIT_AT_FORK=true\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_ITT_PREPARE_DELAY=0\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_LIBRARY=throughput\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_LOCK_KIND=queuing\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_MALLOC_POOL_INCR=1M\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_MWAIT_HINTS=0\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_PLAIN_BARRIER='2,2'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_REDUCTION_BARRIER='1,1'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_SETTINGS=true\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_STACKOFFSET=64\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_STACKPAD=0\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_STACKSIZE=8M\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_STORAGE_MAP=false\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_TASKING=2\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_TASKLOOP_MIN_TASKS=0\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_TASK_STEALING_CONSTRAINT=1\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_TEAMS_THREAD_LIMIT=12\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_TOPOLOGY_METHOD=all\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_USER_LEVEL_MWAIT=false\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_USE_YIELD=1\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_VERSION=false\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_WARNINGS=true\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_CANCELLATION=false\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_DEBUG=disabled\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_DEFAULT_DEVICE=0\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_DISPLAY_AFFINITY=false\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_DISPLAY_ENV=false\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_DYNAMIC=false\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_MAX_ACTIVE_LEVELS=1\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_MAX_TASK_PRIORITY=0\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_NESTED: deprecated; max-active-levels-var=1\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_NUM_TEAMS=0\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_NUM_THREADS='1'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_PLACES='threads'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_PROC_BIND='intel'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_SCHEDULE='static'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_STACKSIZE=8M\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_TARGET_OFFLOAD=DEFAULT\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_TEAMS_THREAD_LIMIT=0\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_THREAD_LIMIT=2147483647\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_TOOL=enabled\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_TOOL_LIBRARIES: value is not defined\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    OMP_WAIT_POLICY=PASSIVE\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m    KMP_AFFINITY='noverbose,warnings,respect,granularity=thread,compact,1,0'\n",
      "\u001b[2m\u001b[36m(pid=15522)\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "est = Estimator.from_torch(model=model_creator, optimizer=optim_creator, loss=criterion, metrics=[Accuracy()], backend=\"ray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m Data size on worker:  79920\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m Data size on worker:  20080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m /home/yansu/miniconda3/envs/env/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py:63: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m   return default_collate([torch.as_tensor(b) for b in batch])\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m /home/yansu/miniconda3/envs/env/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m   allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m [2022-08-19 13:31:33] INFO     Reducer buckets have been rebuilt in this iteration.\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m /home/yansu/miniconda3/envs/env/lib/python3.7/site-packages/torchvision/transforms/functional_pil.py:387: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m   def resize(img, size, interpolation=Image.BILINEAR):\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m /home/yansu/miniconda3/envs/env/lib/python3.7/site-packages/torchvision/transforms/functional_pil.py:545: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m   def perspective(img, perspective_coeffs, interpolation=Image.BICUBIC, fill=None):\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m /home/yansu/miniconda3/envs/env/lib/python3.7/site-packages/torchvision/transforms/functional.py:288: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m   def resize(img: Tensor, size: List[int], interpolation: int = Image.BILINEAR) -> Tensor:\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m /home/yansu/miniconda3/envs/env/lib/python3.7/site-packages/torchvision/transforms/transforms.py:26: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m   Image.NEAREST: 'PIL.Image.NEAREST',\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m /home/yansu/miniconda3/envs/env/lib/python3.7/site-packages/torchvision/transforms/transforms.py:27: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m   Image.BILINEAR: 'PIL.Image.BILINEAR',\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m /home/yansu/miniconda3/envs/env/lib/python3.7/site-packages/torchvision/transforms/transforms.py:28: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m   Image.BICUBIC: 'PIL.Image.BICUBIC',\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m /home/yansu/miniconda3/envs/env/lib/python3.7/site-packages/torchvision/transforms/transforms.py:29: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m   Image.LANCZOS: 'PIL.Image.LANCZOS',\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m /home/yansu/miniconda3/envs/env/lib/python3.7/site-packages/torchvision/transforms/transforms.py:30: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m   Image.HAMMING: 'PIL.Image.HAMMING',\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m /home/yansu/miniconda3/envs/env/lib/python3.7/site-packages/torchvision/transforms/transforms.py:31: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m   Image.BOX: 'PIL.Image.BOX',\n",
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m [2022-08-19 13:31:41] INFO     Finished training epoch 1, stats on rank 0: {'epoch': 1, 'batch_count': 1249, 'num_samples': 79920, 'train_loss': 1.119587504183566, 'last_train_loss': 1.1001675128936768, 'val_accuracy': tensor(0.5718), 'val_loss': 1.1131852335663905, 'val_num_samples': 20080}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'num_samples': 79920,\n",
       "  'epoch': 1,\n",
       "  'batch_count': 1249,\n",
       "  'train_loss': 1.119587504183566,\n",
       "  'last_train_loss': 1.1001675128936768,\n",
       "  'val_accuracy': tensor(0.5718),\n",
       "  'val_loss': 1.1131852335663905,\n",
       "  'val_num_samples': 20080}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.fit(data=shards_train1, feature_cols=['x_scaled'], label_cols=['target'], validation_data=shards_val1, epochs=1, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PytorchRayWorker pid=15522)\u001b[0m Data size on worker:  20080\n"
     ]
    }
   ],
   "source": [
    "result = est.evaluate(data=shards_val1, feature_cols=['x_scaled'], label_cols=['target'], batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples : 20080\n",
      "Accuracy : tensor(0.5718)\n",
      "val_loss : 1.1131852300770848\n"
     ]
    }
   ],
   "source": [
    "for r in result:\n",
    "    print(r, \":\", result[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(xinyi)",
   "language": "python",
   "name": "xinyi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
