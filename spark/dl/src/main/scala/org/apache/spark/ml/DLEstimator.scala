/*
 * Copyright 2016 The BigDL Authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.spark.ml
import com.intel.analytics.bigdl.dataset.Sample
import com.intel.analytics.bigdl.nn.MSECriterion
import com.intel.analytics.bigdl.{Criterion, DataSet, Module}
import com.intel.analytics.bigdl.optim.Optimizer
import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.DataFrame
import org.apache.spark.ml.param.{ParamMap, _}

import scala.reflect.ClassTag

/**
 * A wrapper of Optimizer to support fit() in ML Pipelines as an Estimator
 */

class DLEstimator[M <: org.apache.spark.ml.Model[M]: ClassTag]
  (override val uid: String = "DLEstimator") extends MLEstimator[M]{
  def setModule(m : Module[M]) : this.type = set("module", m)
  def getModule() : Module[M] = get(getParam("module")).asInstanceOf[Module[M]]
  def setDataSet(dataset: RDD[Sample[M]]) : this.type = set("dataSet", dataset)
  def getDataSet() : RDD[Sample[M]] = get(getParam("dataSet")).asInstanceOf[RDD[Sample[M]]]
  def setCriterion(criterion : Criterion[M]): this.type = set("criterion", criterion)
  def getCriterion(): Criterion[M] = get(getParam("criterion")).asInstanceOf[Criterion[M]]
  def setBatchSize(batchSize : Int) : this.type = set("batchSize", batchSize)
  def getBatchSize() : Int = get(getParam("batchSize")).asInstanceOf[Int]
  def setTensorNumric(ev: TensorNumeric[M]) : this.type = set("tensorNumeric", ev)
  def getTensorNumric() : TensorNumeric[M] = get(getParam("tensorNumeric"))
    .asInstanceOf[TensorNumeric[M]]

  def validateParameters(): Unit = {
    require(null != getModule(),
      "DLEstimator: module for estimator must not be null")
    require(null != getDataSet(),
      "DLEstimator: dataset for estimator must not be null")
    require(null != getCriterion(),
      "DLEstimator: criterion must not be null")
    require(0 != getBatchSize(),
      "DLEstimator: batchSize for estimator must not be null")
    require(null != getTensorNumric(),
      "DLEstimator: TensorNumric for estimator must not be null")
  }

  override def process(dataset: DataFrame): M = {
    /*
    * TODO
    * Add transformation from datafram to rdd
     */
    this.validateParameters()
    implicit val tensorNumric : TensorNumeric[M] = getTensorNumric()
    val optimizer = Optimizer(getModule(), getDataSet(), getCriterion(), getBatchSize())
    /*
    *TODO
    *Need to confirm if we can implement like this, all modules generated by this should be of both Model and Module types
     */
    val model = optimizer.optimize()

    val valTrans = new DLClassifier()
      .setInputCol("features")
      .setOutputCol("predict")

    val params = this.extractParamMap()
  }

}

